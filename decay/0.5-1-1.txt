opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=0.5, distill='kd', epochs=240, log_name='0.5-1-1.txt', lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=0.5, distill='kd', epochs=240, log_name='0.5-1-1.txt', lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
Epoch: [1][000/391]	Time 2.4964 Data 0.9408 Loss 4.8249 (4.8249)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)
Epoch: [1][100/391]	Time 0.1882 Data 0.0021 Loss 4.6152 (5.4691)	Acc@1 4.688 (1.532)	Acc@5 11.719 (6.374)
Epoch: [1][200/391]	Time 0.1894 Data 0.0022 Loss 4.8499 (5.0961)	Acc@1 1.562 (1.547)	Acc@5 4.688 (6.821)
Epoch: [1][300/391]	Time 0.1891 Data 0.0019 Loss 4.5302 (4.9937)	Acc@1 1.562 (1.594)	Acc@5 4.688 (6.868)
Testing the models......
Loss: 4.6531, Prec@1: 1.92, Prec@5: 9.42
Epoch time: 84s
Saving models
Epoch: 2  lr: 0.100
Epoch: [2][000/391]	Time 1.1867 Data 1.0063 Loss 4.9466 (4.9466)	Acc@1 1.562 (1.562)	Acc@5 5.469 (5.469)
Epoch: [2][100/391]	Time 0.1916 Data 0.0020 Loss 4.5914 (4.6993)	Acc@1 5.469 (2.220)	Acc@5 13.281 (10.048)
Epoch: [2][200/391]	Time 0.1896 Data 0.0024 Loss 4.5780 (4.6919)	Acc@1 1.562 (2.437)	Acc@5 14.062 (11.101)
Epoch: [2][300/391]	Time 0.1911 Data 0.0024 Loss 4.3638 (4.6552)	Acc@1 3.906 (2.676)	Acc@5 16.406 (12.404)
Testing the models......
Loss: 4.6353, Prec@1: 4.57, Prec@5: 18.06
Epoch time: 82s
Saving models
Epoch: 3  lr: 0.100
Epoch: [3][000/391]	Time 1.1063 Data 0.9024 Loss 4.2253 (4.2253)	Acc@1 3.906 (3.906)	Acc@5 18.750 (18.750)
Epoch: [3][100/391]	Time 0.1902 Data 0.0021 Loss 4.3394 (4.3759)	Acc@1 10.156 (4.881)	Acc@5 18.750 (19.361)
Epoch: [3][200/391]	Time 0.1908 Data 0.0027 Loss 4.2944 (4.3582)	Acc@1 5.469 (5.057)	Acc@5 22.656 (20.285)
Epoch: [3][300/391]	Time 0.1898 Data 0.0020 Loss 6.9506 (4.3312)	Acc@1 7.031 (5.422)	Acc@5 23.438 (21.338)
Testing the models......
Loss: 4.2608, Prec@1: 7.74, Prec@5: 26.61
Epoch time: 82s
Saving models
Epoch: 4  lr: 0.100
Epoch: [4][000/391]	Time 1.1733 Data 0.9443 Loss 3.9299 (3.9299)	Acc@1 9.375 (9.375)	Acc@5 25.781 (25.781)
Epoch: [4][100/391]	Time 0.1964 Data 0.0019 Loss 3.9106 (4.1711)	Acc@1 7.812 (7.039)	Acc@5 28.906 (26.013)
Epoch: [4][200/391]	Time 0.1909 Data 0.0025 Loss 3.9402 (4.1591)	Acc@1 15.625 (7.630)	Acc@5 33.594 (27.099)
Epoch: [4][300/391]	Time 0.1903 Data 0.0022 Loss 3.8023 (4.1388)	Acc@1 12.500 (8.119)	Acc@5 32.031 (27.819)
Testing the models......
Loss: 3.9277, Prec@1: 10.54, Prec@5: 35.04
Epoch time: 82s
Saving models
Epoch: 5  lr: 0.100
Epoch: [5][000/391]	Time 1.3247 Data 1.1347 Loss 4.3191 (4.3191)	Acc@1 12.500 (12.500)	Acc@5 23.438 (23.438)
Epoch: [5][100/391]	Time 0.1900 Data 0.0021 Loss 3.8728 (3.9695)	Acc@1 13.281 (10.241)	Acc@5 36.719 (33.099)
Epoch: [5][200/391]	Time 0.1907 Data 0.0021 Loss 3.8044 (3.9520)	Acc@1 12.500 (11.140)	Acc@5 35.938 (34.118)
Epoch: [5][300/391]	Time 0.1899 Data 0.0020 Loss 3.6603 (3.9306)	Acc@1 15.625 (11.576)	Acc@5 36.719 (34.741)
Testing the models......
Loss: 3.7172, Prec@1: 15.98, Prec@5: 41.38
Epoch time: 82s
Saving models
Epoch: 6  lr: 0.100
Epoch: [6][000/391]	Time 1.3249 Data 1.1246 Loss 3.5103 (3.5103)	Acc@1 15.625 (15.625)	Acc@5 46.094 (46.094)
Epoch: [6][100/391]	Time 0.1904 Data 0.0020 Loss 3.6516 (3.7107)	Acc@1 16.406 (14.604)	Acc@5 48.438 (41.120)
Epoch: [6][200/391]	Time 0.1900 Data 0.0019 Loss 3.6586 (3.7098)	Acc@1 16.406 (15.139)	Acc@5 41.406 (41.453)
Epoch: [6][300/391]	Time 0.1900 Data 0.0019 Loss 3.3425 (3.6632)	Acc@1 19.531 (15.778)	Acc@5 44.531 (42.400)
Testing the models......
Loss: 3.7230, Prec@1: 18.49, Prec@5: 46.66
Epoch time: 82s
Saving models
Epoch: 7  lr: 0.100
Epoch: [7][000/391]	Time 1.3431 Data 1.1823 Loss 3.2986 (3.2986)	Acc@1 21.094 (21.094)	Acc@5 48.438 (48.438)
Epoch: [7][100/391]	Time 0.1922 Data 0.0019 Loss 3.3204 (3.4655)	Acc@1 15.625 (18.750)	Acc@5 47.656 (46.929)
Epoch: [7][200/391]	Time 0.1924 Data 0.0020 Loss 3.4537 (3.4439)	Acc@1 19.531 (19.438)	Acc@5 46.875 (47.450)
Epoch: [7][300/391]	Time 0.1910 Data 0.0022 Loss 3.1449 (3.4108)	Acc@1 26.562 (20.043)	Acc@5 52.344 (48.466)
Testing the models......
Loss: 3.2877, Prec@1: 24.21, Prec@5: 53.26
Epoch time: 82s
Saving models
Epoch: 8  lr: 0.100
Epoch: [8][000/391]	Time 1.4047 Data 1.1718 Loss 3.3420 (3.3420)	Acc@1 24.219 (24.219)	Acc@5 54.688 (54.688)
Epoch: [8][100/391]	Time 0.1893 Data 0.0020 Loss 3.2045 (3.2239)	Acc@1 25.781 (23.747)	Acc@5 57.812 (53.017)
Epoch: [8][200/391]	Time 0.1905 Data 0.0018 Loss 2.8510 (3.1911)	Acc@1 26.562 (24.098)	Acc@5 62.500 (53.483)
Epoch: [8][300/391]	Time 0.1898 Data 0.0019 Loss 3.2012 (3.1705)	Acc@1 17.969 (24.380)	Acc@5 50.781 (54.114)
Testing the models......
Loss: 3.0838, Prec@1: 27.96, Prec@5: 59.35
Epoch time: 82s
Saving models
Epoch: 9  lr: 0.100
Epoch: [9][000/391]	Time 1.3844 Data 1.1802 Loss 3.0281 (3.0281)	Acc@1 30.469 (30.469)	Acc@5 59.375 (59.375)
Epoch: [9][100/391]	Time 0.1892 Data 0.0019 Loss 2.6396 (2.9452)	Acc@1 35.938 (28.697)	Acc@5 64.844 (59.715)
Epoch: [9][200/391]	Time 0.1905 Data 0.0019 Loss 2.6580 (2.9210)	Acc@1 33.594 (29.283)	Acc@5 64.062 (60.148)
Epoch: [9][300/391]	Time 0.1908 Data 0.0019 Loss 2.8213 (2.8940)	Acc@1 33.594 (29.763)	Acc@5 64.844 (60.816)
Testing the models......
Loss: 2.7492, Prec@1: 32.58, Prec@5: 64.21
Epoch time: 82s
Saving models
Epoch: 10  lr: 0.100
Epoch: [10][000/391]	Time 1.3379 Data 1.1384 Loss 2.4725 (2.4725)	Acc@1 34.375 (34.375)	Acc@5 66.406 (66.406)
Epoch: [10][100/391]	Time 0.1899 Data 0.0021 Loss 2.2279 (2.6585)	Acc@1 44.531 (33.981)	Acc@5 70.312 (65.873)
Epoch: [10][200/391]	Time 0.1894 Data 0.0023 Loss 2.7468 (2.6480)	Acc@1 35.938 (33.998)	Acc@5 67.969 (65.897)
Epoch: [10][300/391]	Time 0.1903 Data 0.0019 Loss 2.4192 (2.6213)	Acc@1 36.719 (34.528)	Acc@5 67.188 (66.533)
Testing the models......
Loss: 2.5800, Prec@1: 34.57, Prec@5: 67.26
Epoch time: 82s
Saving models
Epoch: 11  lr: 0.100
Epoch: [11][000/391]	Time 1.3921 Data 1.1972 Loss 2.1827 (2.1827)	Acc@1 42.969 (42.969)	Acc@5 71.875 (71.875)
Epoch: [11][100/391]	Time 0.1905 Data 0.0020 Loss 2.6909 (2.4086)	Acc@1 32.031 (37.964)	Acc@5 67.188 (70.908)
Epoch: [11][200/391]	Time 0.1905 Data 0.0021 Loss 2.3182 (2.4098)	Acc@1 43.750 (38.083)	Acc@5 75.000 (70.950)
Epoch: [11][300/391]	Time 0.1897 Data 0.0019 Loss 2.5027 (2.4074)	Acc@1 35.156 (38.279)	Acc@5 67.969 (70.948)
Testing the models......
Loss: 2.3622, Prec@1: 40.16, Prec@5: 72.63
Epoch time: 82s
Saving models
Epoch: 12  lr: 0.100
Epoch: [12][000/391]	Time 1.3615 Data 1.1273 Loss 2.3295 (2.3295)	Acc@1 39.844 (39.844)	Acc@5 73.438 (73.438)
Epoch: [12][100/391]	Time 0.1899 Data 0.0020 Loss 2.4240 (2.2352)	Acc@1 39.844 (42.420)	Acc@5 71.875 (74.188)
Epoch: [12][200/391]	Time 0.1898 Data 0.0020 Loss 1.9647 (2.2357)	Acc@1 46.875 (42.269)	Acc@5 80.469 (74.475)
Epoch: [12][300/391]	Time 0.1900 Data 0.0020 Loss 2.0726 (2.2171)	Acc@1 41.406 (42.665)	Acc@5 75.781 (74.772)
Testing the models......
Loss: 2.3048, Prec@1: 42.36, Prec@5: 74.50
Epoch time: 82s
Saving models
Epoch: 13  lr: 0.100
Epoch: [13][000/391]	Time 1.4236 Data 1.2291 Loss 2.0004 (2.0004)	Acc@1 45.312 (45.312)	Acc@5 78.906 (78.906)
Epoch: [13][100/391]	Time 0.1912 Data 0.0022 Loss 2.3527 (2.0713)	Acc@1 35.938 (45.738)	Acc@5 71.094 (77.406)
Epoch: [13][200/391]	Time 0.1898 Data 0.0020 Loss 1.8380 (2.0544)	Acc@1 45.312 (45.931)	Acc@5 82.031 (77.845)
Epoch: [13][300/391]	Time 0.1902 Data 0.0019 Loss 2.2971 (2.0491)	Acc@1 39.062 (46.249)	Acc@5 71.094 (77.987)
Testing the models......
Loss: 2.1405, Prec@1: 45.03, Prec@5: 76.47
Epoch time: 82s
Saving models
Epoch: 14  lr: 0.100
Epoch: [14][000/391]	Time 1.3340 Data 1.1564 Loss 1.6960 (1.6960)	Acc@1 54.688 (54.688)	Acc@5 80.469 (80.469)
Epoch: [14][100/391]	Time 0.1911 Data 0.0023 Loss 1.8926 (1.8953)	Acc@1 46.875 (49.397)	Acc@5 76.562 (80.647)
Epoch: [14][200/391]	Time 0.1895 Data 0.0019 Loss 1.8549 (1.9028)	Acc@1 53.906 (49.300)	Acc@5 83.594 (80.325)
Epoch: [14][300/391]	Time 0.1902 Data 0.0021 Loss 1.6987 (1.8967)	Acc@1 53.906 (49.278)	Acc@5 83.594 (80.419)
Testing the models......
Loss: 2.1522, Prec@1: 48.82, Prec@5: 79.95
Epoch time: 82s
Saving models
Epoch: 15  lr: 0.100
Epoch: [15][000/391]	Time 1.3647 Data 1.1797 Loss 1.5532 (1.5532)	Acc@1 60.938 (60.938)	Acc@5 85.938 (85.938)
Epoch: [15][100/391]	Time 0.1894 Data 0.0020 Loss 1.5752 (1.7494)	Acc@1 60.938 (53.140)	Acc@5 85.938 (83.037)
Epoch: [15][200/391]	Time 0.1906 Data 0.0019 Loss 1.7204 (1.7598)	Acc@1 53.906 (52.670)	Acc@5 82.031 (82.828)
Epoch: [15][300/391]	Time 0.1897 Data 0.0019 Loss 2.1254 (1.7553)	Acc@1 50.781 (52.476)	Acc@5 73.438 (82.875)
Testing the models......
Loss: 1.9175, Prec@1: 50.31, Prec@5: 80.92
Epoch time: 82s
Saving models
Epoch: 16  lr: 0.100
Epoch: [16][000/391]	Time 1.3554 Data 1.1234 Loss 1.6312 (1.6312)	Acc@1 56.250 (56.250)	Acc@5 84.375 (84.375)
Epoch: [16][100/391]	Time 0.1896 Data 0.0020 Loss 1.5893 (1.6209)	Acc@1 56.250 (55.453)	Acc@5 85.938 (85.087)
Epoch: [16][200/391]	Time 0.1906 Data 0.0019 Loss 1.5093 (1.6300)	Acc@1 59.375 (55.496)	Acc@5 85.938 (84.935)
Epoch: [16][300/391]	Time 0.1899 Data 0.0019 Loss 1.5898 (1.6327)	Acc@1 55.469 (55.303)	Acc@5 89.062 (84.788)
Testing the models......
Loss: 1.8607, Prec@1: 51.68, Prec@5: 81.39
Epoch time: 82s
Saving models
Epoch: 17  lr: 0.100
Epoch: [17][000/391]	Time 1.4054 Data 1.1794 Loss 1.3394 (1.3394)	Acc@1 61.719 (61.719)	Acc@5 89.062 (89.062)
Epoch: [17][100/391]	Time 0.1900 Data 0.0019 Loss 1.5222 (1.5048)	Acc@1 56.250 (57.797)	Acc@5 85.938 (86.742)
Epoch: [17][200/391]	Time 0.1898 Data 0.0020 Loss 1.7686 (1.5182)	Acc@1 47.656 (57.847)	Acc@5 88.281 (86.614)
Epoch: [17][300/391]	Time 0.1939 Data 0.0020 Loss 1.6529 (1.5295)	Acc@1 59.375 (57.678)	Acc@5 84.375 (86.433)
Testing the models......
Loss: 1.7272, Prec@1: 53.63, Prec@5: 82.82
Epoch time: 82s
Saving models
Epoch: 18  lr: 0.100
Epoch: [18][000/391]	Time 1.4090 Data 1.2237 Loss 1.2234 (1.2234)	Acc@1 65.625 (65.625)	Acc@5 91.406 (91.406)
Epoch: [18][100/391]	Time 0.1896 Data 0.0020 Loss 1.5597 (1.4232)	Acc@1 57.031 (60.156)	Acc@5 87.500 (87.856)
Epoch: [18][200/391]	Time 0.1905 Data 0.0020 Loss 1.6316 (1.4358)	Acc@1 52.344 (59.771)	Acc@5 82.031 (87.963)
Epoch: [18][300/391]	Time 0.1900 Data 0.0021 Loss 1.6282 (1.4426)	Acc@1 58.594 (59.648)	Acc@5 87.500 (87.900)
Testing the models......
Loss: 1.7376, Prec@1: 54.34, Prec@5: 82.93
Epoch time: 82s
Saving models
Epoch: 19  lr: 0.100
Epoch: [19][000/391]	Time 1.3743 Data 1.2177 Loss 1.4323 (1.4323)	Acc@1 59.375 (59.375)	Acc@5 88.281 (88.281)
Epoch: [19][100/391]	Time 0.1898 Data 0.0018 Loss 1.3250 (1.3143)	Acc@1 61.719 (62.740)	Acc@5 85.156 (89.295)
Epoch: [19][200/391]	Time 0.1907 Data 0.0021 Loss 1.5378 (1.3425)	Acc@1 63.281 (61.901)	Acc@5 87.500 (89.136)
Epoch: [19][300/391]	Time 0.1955 Data 0.0020 Loss 1.3066 (1.3452)	Acc@1 57.031 (62.061)	Acc@5 89.844 (89.005)
Testing the models......
Loss: 1.7535, Prec@1: 55.95, Prec@5: 84.87
Epoch time: 82s
Saving models
Epoch: 20  lr: 0.100
Epoch: [20][000/391]	Time 1.3875 Data 1.1583 Loss 1.3416 (1.3416)	Acc@1 64.844 (64.844)	Acc@5 86.719 (86.719)
Epoch: [20][100/391]	Time 0.1898 Data 0.0024 Loss 1.1858 (1.2512)	Acc@1 67.969 (63.815)	Acc@5 90.625 (90.710)
Epoch: [20][200/391]	Time 0.1903 Data 0.0018 Loss 1.3741 (1.2472)	Acc@1 60.156 (64.432)	Acc@5 89.844 (90.532)
Epoch: [20][300/391]	Time 0.1908 Data 0.0021 Loss 1.4113 (1.2621)	Acc@1 55.469 (63.912)	Acc@5 88.281 (90.293)
Testing the models......
Loss: 1.6110, Prec@1: 57.54, Prec@5: 85.93
Epoch time: 82s
Saving models
Epoch: 21  lr: 0.100
Epoch: [21][000/391]	Time 1.3649 Data 1.1757 Loss 1.1582 (1.1582)	Acc@1 64.844 (64.844)	Acc@5 92.969 (92.969)
Epoch: [21][100/391]	Time 0.1901 Data 0.0019 Loss 1.0102 (1.1645)	Acc@1 69.531 (66.368)	Acc@5 93.750 (91.700)
Epoch: [21][200/391]	Time 0.1897 Data 0.0018 Loss 1.2943 (1.1777)	Acc@1 63.281 (65.889)	Acc@5 90.625 (91.480)
Epoch: [21][300/391]	Time 0.1903 Data 0.0019 Loss 1.2253 (1.1963)	Acc@1 66.406 (65.560)	Acc@5 93.750 (91.341)
Testing the models......
Loss: 1.6443, Prec@1: 58.02, Prec@5: 85.42
Epoch time: 82s
Saving models
Epoch: 22  lr: 0.100
Epoch: [22][000/391]	Time 1.3034 Data 1.0718 Loss 1.3196 (1.3196)	Acc@1 58.594 (58.594)	Acc@5 89.844 (89.844)
Epoch: [22][100/391]	Time 0.1900 Data 0.0018 Loss 1.0373 (1.0913)	Acc@1 64.844 (68.139)	Acc@5 93.750 (92.381)
Epoch: [22][200/391]	Time 0.1920 Data 0.0019 Loss 1.2594 (1.1058)	Acc@1 64.062 (67.335)	Acc@5 89.062 (92.292)
Epoch: [22][300/391]	Time 0.1940 Data 0.0020 Loss 1.3479 (1.1219)	Acc@1 60.938 (67.066)	Acc@5 91.406 (92.071)
Testing the models......
Loss: 1.5855, Prec@1: 58.31, Prec@5: 85.45
Epoch time: 82s
Saving models
Epoch: 23  lr: 0.100
Epoch: [23][000/391]	Time 1.3298 Data 1.1002 Loss 0.9400 (0.9400)	Acc@1 72.656 (72.656)	Acc@5 92.188 (92.188)
Epoch: [23][100/391]	Time 0.1900 Data 0.0020 Loss 0.9355 (1.0177)	Acc@1 67.969 (69.415)	Acc@5 93.750 (93.448)
Epoch: [23][200/391]	Time 0.1902 Data 0.0020 Loss 1.0702 (1.0361)	Acc@1 62.500 (69.069)	Acc@5 91.406 (93.148)
Epoch: [23][300/391]	Time 0.1899 Data 0.0019 Loss 1.1753 (1.0598)	Acc@1 65.625 (68.387)	Acc@5 93.750 (92.810)
Testing the models......
Loss: 1.4876, Prec@1: 60.25, Prec@5: 86.93
Epoch time: 82s
Saving models
Epoch: 24  lr: 0.100
Epoch: [24][000/391]	Time 1.3202 Data 1.1255 Loss 0.9095 (0.9095)	Acc@1 69.531 (69.531)	Acc@5 94.531 (94.531)
Epoch: [24][100/391]	Time 0.1897 Data 0.0019 Loss 0.9633 (0.9328)	Acc@1 69.531 (71.976)	Acc@5 94.531 (94.361)
Epoch: [24][200/391]	Time 0.1897 Data 0.0019 Loss 0.8914 (0.9657)	Acc@1 69.531 (71.043)	Acc@5 97.656 (93.801)
Epoch: [24][300/391]	Time 0.1899 Data 0.0019 Loss 0.9644 (0.9896)	Acc@1 70.312 (70.453)	Acc@5 92.969 (93.441)
Testing the models......
Loss: 1.5593, Prec@1: 59.23, Prec@5: 86.28
Epoch time: 82s
Epoch: 25  lr: 0.100
Epoch: [25][000/391]	Time 1.3876 Data 1.2132 Loss 0.7305 (0.7305)	Acc@1 78.906 (78.906)	Acc@5 95.312 (95.312)
Epoch: [25][100/391]	Time 0.1913 Data 0.0020 Loss 0.7458 (0.8964)	Acc@1 76.562 (73.113)	Acc@5 96.875 (94.794)
Epoch: [25][200/391]	Time 0.1948 Data 0.0019 Loss 1.1621 (0.9337)	Acc@1 67.969 (71.879)	Acc@5 91.406 (94.376)
Epoch: [25][300/391]	Time 0.1913 Data 0.0025 Loss 0.7132 (0.9420)	Acc@1 80.469 (71.800)	Acc@5 96.094 (94.209)
Testing the models......
Loss: 1.5006, Prec@1: 60.26, Prec@5: 87.29
Epoch time: 82s
Saving models
Epoch: 26  lr: 0.100
Epoch: [26][000/391]	Time 1.3876 Data 1.1875 Loss 1.0511 (1.0511)	Acc@1 72.656 (72.656)	Acc@5 92.969 (92.969)
Epoch: [26][100/391]	Time 0.1910 Data 0.0021 Loss 0.8893 (0.8508)	Acc@1 71.094 (74.335)	Acc@5 96.094 (95.212)
Epoch: [26][200/391]	Time 0.1903 Data 0.0021 Loss 1.0933 (0.8878)	Acc@1 71.875 (73.239)	Acc@5 94.531 (94.827)
Epoch: [26][300/391]	Time 0.1896 Data 0.0019 Loss 1.0128 (0.9032)	Acc@1 64.844 (72.729)	Acc@5 94.531 (94.713)
Testing the models......
Loss: 1.4967, Prec@1: 60.75, Prec@5: 87.41
Epoch time: 82s
Saving models
Epoch: 27  lr: 0.100
Epoch: [27][000/391]	Time 1.3317 Data 1.1688 Loss 0.7531 (0.7531)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [27][100/391]	Time 0.1903 Data 0.0024 Loss 0.8319 (0.8011)	Acc@1 78.125 (75.340)	Acc@5 96.875 (95.777)
Epoch: [27][200/391]	Time 0.1893 Data 0.0020 Loss 0.7552 (0.8291)	Acc@1 71.875 (74.572)	Acc@5 96.875 (95.421)
Epoch: [27][300/391]	Time 0.1900 Data 0.0019 Loss 0.8060 (0.8526)	Acc@1 75.000 (74.058)	Acc@5 95.312 (95.240)
Testing the models......
Loss: 1.4849, Prec@1: 61.03, Prec@5: 87.49
Epoch time: 82s
Saving models
Epoch: 28  lr: 0.100
Epoch: [28][000/391]	Time 1.3639 Data 1.1697 Loss 0.6746 (0.6746)	Acc@1 78.125 (78.125)	Acc@5 94.531 (94.531)
Epoch: [28][100/391]	Time 0.1911 Data 0.0022 Loss 0.6867 (0.7697)	Acc@1 78.125 (76.013)	Acc@5 99.219 (96.040)
Epoch: [28][200/391]	Time 0.1904 Data 0.0021 Loss 1.1183 (0.8010)	Acc@1 66.406 (75.400)	Acc@5 90.625 (95.686)
Epoch: [28][300/391]	Time 0.1902 Data 0.0019 Loss 1.0669 (0.8210)	Acc@1 67.188 (74.668)	Acc@5 92.188 (95.458)
Testing the models......
Loss: 1.4811, Prec@1: 61.59, Prec@5: 87.22
Epoch time: 82s
Saving models
Epoch: 29  lr: 0.100
Epoch: [29][000/391]	Time 1.3748 Data 1.1001 Loss 0.7783 (0.7783)	Acc@1 73.438 (73.438)	Acc@5 96.094 (96.094)
Epoch: [29][100/391]	Time 0.1899 Data 0.0020 Loss 0.7493 (0.7151)	Acc@1 78.906 (77.638)	Acc@5 95.312 (96.759)
Epoch: [29][200/391]	Time 0.1900 Data 0.0020 Loss 0.7809 (0.7459)	Acc@1 73.438 (76.807)	Acc@5 94.531 (96.300)
Epoch: [29][300/391]	Time 0.1895 Data 0.0019 Loss 0.8197 (0.7715)	Acc@1 75.000 (76.274)	Acc@5 96.875 (96.008)
Testing the models......
Loss: 1.4888, Prec@1: 61.96, Prec@5: 87.81
Epoch time: 82s
Saving models
Epoch: 30  lr: 0.100
Epoch: [30][000/391]	Time 1.3743 Data 1.1799 Loss 0.7586 (0.7586)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
Epoch: [30][100/391]	Time 0.1900 Data 0.0021 Loss 0.7495 (0.7100)	Acc@1 76.562 (78.040)	Acc@5 97.656 (96.635)
Epoch: [30][200/391]	Time 0.1900 Data 0.0020 Loss 0.8132 (0.7317)	Acc@1 76.562 (77.414)	Acc@5 97.656 (96.537)
Epoch: [30][300/391]	Time 0.1901 Data 0.0020 Loss 0.8619 (0.7503)	Acc@1 75.781 (76.954)	Acc@5 95.312 (96.291)
Testing the models......
Loss: 1.4437, Prec@1: 62.99, Prec@5: 87.66
Epoch time: 82s
Saving models
Epoch: 31  lr: 0.100
Epoch: [31][000/391]	Time 1.4456 Data 1.2101 Loss 0.5241 (0.5241)	Acc@1 87.500 (87.500)	Acc@5 97.656 (97.656)
Epoch: [31][100/391]	Time 0.1892 Data 0.0020 Loss 0.9041 (0.6521)	Acc@1 78.125 (79.834)	Acc@5 96.094 (97.262)
Epoch: [31][200/391]	Time 0.1900 Data 0.0020 Loss 0.7408 (0.6855)	Acc@1 74.219 (78.766)	Acc@5 98.438 (96.887)
Epoch: [31][300/391]	Time 0.1899 Data 0.0020 Loss 0.7253 (0.7060)	Acc@1 78.906 (78.141)	Acc@5 96.094 (96.727)
Testing the models......
Loss: 1.4444, Prec@1: 63.42, Prec@5: 87.98
Epoch time: 82s
Saving models
Epoch: 32  lr: 0.100
Epoch: [32][000/391]	Time 1.4213 Data 1.2406 Loss 0.8858 (0.8858)	Acc@1 78.125 (78.125)	Acc@5 92.969 (92.969)
Epoch: [32][100/391]	Time 0.1897 Data 0.0020 Loss 0.7691 (0.6282)	Acc@1 77.344 (80.438)	Acc@5 95.312 (97.324)
Epoch: [32][200/391]	Time 0.1913 Data 0.0020 Loss 0.5550 (0.6489)	Acc@1 84.375 (79.991)	Acc@5 99.219 (97.205)
Epoch: [32][300/391]	Time 0.1896 Data 0.0020 Loss 0.6672 (0.6750)	Acc@1 71.094 (79.163)	Acc@5 97.656 (97.015)
Testing the models......
Loss: 1.4966, Prec@1: 62.17, Prec@5: 87.82
Epoch time: 82s
Epoch: 33  lr: 0.100
Epoch: [33][000/391]	Time 1.3392 Data 1.1544 Loss 0.6191 (0.6191)	Acc@1 80.469 (80.469)	Acc@5 97.656 (97.656)
Epoch: [33][100/391]	Time 0.1893 Data 0.0019 Loss 0.6364 (0.6064)	Acc@1 79.688 (81.142)	Acc@5 98.438 (97.486)
Epoch: [33][200/391]	Time 0.1891 Data 0.0018 Loss 0.6037 (0.6390)	Acc@1 78.906 (80.181)	Acc@5 99.219 (97.295)
Epoch: [33][300/391]	Time 0.1894 Data 0.0018 Loss 0.6571 (0.6674)	Acc@1 77.344 (79.202)	Acc@5 97.656 (97.161)
Testing the models......
Loss: 1.4968, Prec@1: 62.49, Prec@5: 87.75
Epoch time: 82s
Epoch: 34  lr: 0.100
Epoch: [34][000/391]	Time 1.3677 Data 1.2096 Loss 0.5381 (0.5381)	Acc@1 82.031 (82.031)	Acc@5 99.219 (99.219)
Epoch: [34][100/391]	Time 0.1894 Data 0.0019 Loss 0.6484 (0.5856)	Acc@1 78.906 (81.590)	Acc@5 98.438 (97.857)
Epoch: [34][200/391]	Time 0.1896 Data 0.0019 Loss 0.8518 (0.6073)	Acc@1 74.219 (80.885)	Acc@5 92.969 (97.617)
Epoch: [34][300/391]	Time 0.1890 Data 0.0018 Loss 0.8477 (0.6303)	Acc@1 73.438 (80.313)	Acc@5 93.750 (97.386)
Testing the models......
Loss: 1.5057, Prec@1: 62.72, Prec@5: 88.29
Epoch time: 82s
Epoch: 35  lr: 0.100
Epoch: [35][000/391]	Time 1.3618 Data 1.1534 Loss 0.3762 (0.3762)	Acc@1 85.938 (85.938)	Acc@5 99.219 (99.219)
Epoch: [35][100/391]	Time 0.1895 Data 0.0020 Loss 0.4966 (0.5658)	Acc@1 84.375 (81.962)	Acc@5 98.438 (98.074)
Epoch: [35][200/391]	Time 0.1896 Data 0.0021 Loss 0.7059 (0.5894)	Acc@1 77.344 (81.542)	Acc@5 96.875 (97.851)
Epoch: [35][300/391]	Time 0.1896 Data 0.0020 Loss 0.8567 (0.6038)	Acc@1 77.344 (81.162)	Acc@5 96.875 (97.672)
Testing the models......
Loss: 1.4887, Prec@1: 63.47, Prec@5: 87.63
Epoch time: 82s
Saving models
Epoch: 36  lr: 0.100
Epoch: [36][000/391]	Time 1.3003 Data 1.0714 Loss 0.4880 (0.4880)	Acc@1 83.594 (83.594)	Acc@5 97.656 (97.656)
Epoch: [36][100/391]	Time 0.1889 Data 0.0019 Loss 0.4654 (0.5535)	Acc@1 85.938 (83.006)	Acc@5 99.219 (98.028)
Epoch: [36][200/391]	Time 0.1939 Data 0.0021 Loss 0.4364 (0.5615)	Acc@1 87.500 (82.529)	Acc@5 98.438 (97.944)
Epoch: [36][300/391]	Time 0.1889 Data 0.0018 Loss 0.5670 (0.5801)	Acc@1 82.031 (81.953)	Acc@5 98.438 (97.885)
Testing the models......
Loss: 1.5285, Prec@1: 63.52, Prec@5: 87.77
Epoch time: 82s
Saving models
Epoch: 37  lr: 0.100
Epoch: [37][000/391]	Time 1.4173 Data 1.1820 Loss 0.4281 (0.4281)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [37][100/391]	Time 0.1883 Data 0.0021 Loss 0.4559 (0.5087)	Acc@1 85.156 (84.058)	Acc@5 99.219 (98.360)
Epoch: [37][200/391]	Time 0.1909 Data 0.0021 Loss 0.5210 (0.5348)	Acc@1 82.812 (83.186)	Acc@5 97.656 (98.177)
Epoch: [37][300/391]	Time 0.1891 Data 0.0022 Loss 0.6605 (0.5706)	Acc@1 79.688 (82.169)	Acc@5 99.219 (97.856)
Testing the models......
Loss: 1.4732, Prec@1: 63.67, Prec@5: 88.06
Epoch time: 82s
Saving models
Epoch: 38  lr: 0.100
Epoch: [38][000/391]	Time 1.3890 Data 1.1154 Loss 0.8856 (0.8856)	Acc@1 72.656 (72.656)	Acc@5 95.312 (95.312)
Epoch: [38][100/391]	Time 0.1899 Data 0.0018 Loss 0.4694 (0.5146)	Acc@1 84.375 (83.594)	Acc@5 99.219 (98.291)
Epoch: [38][200/391]	Time 0.1902 Data 0.0027 Loss 0.6032 (0.5224)	Acc@1 81.250 (83.302)	Acc@5 97.656 (98.333)
Epoch: [38][300/391]	Time 0.1916 Data 0.0018 Loss 0.6497 (0.5462)	Acc@1 76.562 (82.620)	Acc@5 96.094 (98.173)
Testing the models......
Loss: 1.4807, Prec@1: 64.28, Prec@5: 88.49
Epoch time: 82s
Saving models
Epoch: 39  lr: 0.100
Epoch: [39][000/391]	Time 1.3583 Data 1.1003 Loss 0.5684 (0.5684)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)
Epoch: [39][100/391]	Time 0.1900 Data 0.0021 Loss 0.4839 (0.4834)	Acc@1 88.281 (84.553)	Acc@5 97.656 (98.499)
Epoch: [39][200/391]	Time 0.1900 Data 0.0021 Loss 0.5930 (0.5118)	Acc@1 82.812 (83.745)	Acc@5 96.094 (98.286)
Epoch: [39][300/391]	Time 0.1896 Data 0.0020 Loss 0.4973 (0.5274)	Acc@1 85.938 (83.329)	Acc@5 97.656 (98.219)
Testing the models......
Loss: 1.5014, Prec@1: 62.97, Prec@5: 88.24
Epoch time: 82s
Epoch: 40  lr: 0.100
Epoch: [40][000/391]	Time 1.4008 Data 1.2192 Loss 0.3994 (0.3994)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [40][100/391]	Time 0.1926 Data 0.0022 Loss 0.5014 (0.4627)	Acc@1 88.281 (85.589)	Acc@5 97.656 (98.639)
Epoch: [40][200/391]	Time 0.1897 Data 0.0020 Loss 0.4834 (0.4937)	Acc@1 79.688 (84.511)	Acc@5 100.000 (98.418)
Epoch: [40][300/391]	Time 0.1899 Data 0.0020 Loss 0.6816 (0.5146)	Acc@1 77.344 (83.871)	Acc@5 97.656 (98.271)
Testing the models......
Loss: 1.5202, Prec@1: 63.49, Prec@5: 87.76
Epoch time: 82s
Epoch: 41  lr: 0.100
Epoch: [41][000/391]	Time 1.3783 Data 1.1610 Loss 0.3994 (0.3994)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [41][100/391]	Time 0.1896 Data 0.0018 Loss 0.5704 (0.4510)	Acc@1 82.031 (85.767)	Acc@5 97.656 (98.956)
Epoch: [41][200/391]	Time 0.1897 Data 0.0019 Loss 0.4312 (0.4813)	Acc@1 85.156 (84.791)	Acc@5 99.219 (98.713)
Epoch: [41][300/391]	Time 0.1903 Data 0.0019 Loss 0.7045 (0.5067)	Acc@1 78.906 (83.947)	Acc@5 96.875 (98.536)
Testing the models......
Loss: 1.5734, Prec@1: 63.35, Prec@5: 88.25
Epoch time: 82s
Epoch: 42  lr: 0.100
Epoch: [42][000/391]	Time 1.3771 Data 1.1504 Loss 0.3309 (0.3309)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [42][100/391]	Time 0.1894 Data 0.0021 Loss 0.5687 (0.4395)	Acc@1 84.375 (86.061)	Acc@5 98.438 (98.925)
Epoch: [42][200/391]	Time 0.1900 Data 0.0019 Loss 0.6486 (0.4542)	Acc@1 78.125 (85.650)	Acc@5 97.656 (98.787)
Epoch: [42][300/391]	Time 0.1894 Data 0.0019 Loss 0.5198 (0.4699)	Acc@1 85.156 (85.133)	Acc@5 96.875 (98.674)
Testing the models......
Loss: 1.4400, Prec@1: 65.18, Prec@5: 88.68
Epoch time: 82s
Saving models
Epoch: 43  lr: 0.100
Epoch: [43][000/391]	Time 1.4081 Data 1.1786 Loss 0.4224 (0.4224)	Acc@1 86.719 (86.719)	Acc@5 98.438 (98.438)
Epoch: [43][100/391]	Time 0.1934 Data 0.0019 Loss 0.3956 (0.4222)	Acc@1 87.500 (86.688)	Acc@5 99.219 (99.049)
Epoch: [43][200/391]	Time 0.1898 Data 0.0019 Loss 0.3817 (0.4490)	Acc@1 90.625 (85.852)	Acc@5 98.438 (98.795)
Epoch: [43][300/391]	Time 0.1900 Data 0.0019 Loss 0.6364 (0.4825)	Acc@1 77.344 (84.718)	Acc@5 97.656 (98.575)
Testing the models......
Loss: 1.5462, Prec@1: 63.68, Prec@5: 86.99
Epoch time: 82s
Epoch: 44  lr: 0.100
Epoch: [44][000/391]	Time 1.3954 Data 1.2288 Loss 0.4412 (0.4412)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [44][100/391]	Time 0.1901 Data 0.0022 Loss 0.4143 (0.4253)	Acc@1 86.719 (86.680)	Acc@5 98.438 (98.863)
Epoch: [44][200/391]	Time 0.1904 Data 0.0021 Loss 0.3366 (0.4396)	Acc@1 92.188 (86.132)	Acc@5 99.219 (98.838)
Epoch: [44][300/391]	Time 0.1899 Data 0.0025 Loss 0.4658 (0.4590)	Acc@1 82.812 (85.429)	Acc@5 98.438 (98.723)
Testing the models......
Loss: 1.5003, Prec@1: 64.67, Prec@5: 88.53
Epoch time: 82s
Epoch: 45  lr: 0.100
Epoch: [45][000/391]	Time 1.3887 Data 1.1278 Loss 0.3247 (0.3247)	Acc@1 92.969 (92.969)	Acc@5 97.656 (97.656)
Epoch: [45][100/391]	Time 0.1898 Data 0.0020 Loss 0.4511 (0.4240)	Acc@1 83.594 (86.757)	Acc@5 98.438 (98.925)
Epoch: [45][200/391]	Time 0.1897 Data 0.0019 Loss 0.5378 (0.4296)	Acc@1 82.031 (86.486)	Acc@5 98.438 (98.865)
Epoch: [45][300/391]	Time 0.1909 Data 0.0020 Loss 0.4631 (0.4362)	Acc@1 85.156 (86.285)	Acc@5 99.219 (98.829)
Testing the models......
Loss: 1.4739, Prec@1: 64.84, Prec@5: 88.66
Epoch time: 82s
Epoch: 46  lr: 0.100
Epoch: [46][000/391]	Time 1.2903 Data 1.1338 Loss 0.3815 (0.3815)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [46][100/391]	Time 0.1893 Data 0.0020 Loss 0.4889 (0.3985)	Acc@1 83.594 (87.067)	Acc@5 99.219 (99.172)
Epoch: [46][200/391]	Time 0.1893 Data 0.0020 Loss 0.5033 (0.4083)	Acc@1 84.375 (86.824)	Acc@5 96.875 (99.079)
Epoch: [46][300/391]	Time 0.1901 Data 0.0021 Loss 0.3504 (0.4296)	Acc@1 87.500 (86.244)	Acc@5 100.000 (98.951)
Testing the models......
Loss: 1.5551, Prec@1: 63.33, Prec@5: 87.75
Epoch time: 82s
Epoch: 47  lr: 0.100
Epoch: [47][000/391]	Time 1.3895 Data 1.1787 Loss 0.3448 (0.3448)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [47][100/391]	Time 0.1902 Data 0.0022 Loss 0.3595 (0.3781)	Acc@1 89.062 (88.072)	Acc@5 99.219 (99.203)
Epoch: [47][200/391]	Time 0.1903 Data 0.0021 Loss 0.5113 (0.3964)	Acc@1 83.594 (87.554)	Acc@5 97.656 (99.149)
Epoch: [47][300/391]	Time 0.1897 Data 0.0021 Loss 0.4372 (0.4227)	Acc@1 86.719 (86.643)	Acc@5 98.438 (98.983)
Testing the models......
Loss: 1.5116, Prec@1: 64.25, Prec@5: 87.83
Epoch time: 82s
Epoch: 48  lr: 0.100
Epoch: [48][000/391]	Time 1.3365 Data 1.1105 Loss 0.3949 (0.3949)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [48][100/391]	Time 0.1888 Data 0.0018 Loss 0.3631 (0.3851)	Acc@1 89.844 (87.825)	Acc@5 100.000 (98.971)
Epoch: [48][200/391]	Time 0.1895 Data 0.0018 Loss 0.4270 (0.4015)	Acc@1 85.156 (87.232)	Acc@5 100.000 (99.017)
Epoch: [48][300/391]	Time 0.1898 Data 0.0019 Loss 0.4279 (0.4169)	Acc@1 84.375 (86.804)	Acc@5 100.000 (98.933)
Testing the models......
Loss: 1.6031, Prec@1: 63.57, Prec@5: 87.39
Epoch time: 82s
Epoch: 49  lr: 0.100
Epoch: [49][000/391]	Time 1.3375 Data 1.1141 Loss 0.3962 (0.3962)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [49][100/391]	Time 0.1898 Data 0.0019 Loss 0.2829 (0.3597)	Acc@1 91.406 (88.544)	Acc@5 100.000 (99.412)
Epoch: [49][200/391]	Time 0.1899 Data 0.0021 Loss 0.5228 (0.3824)	Acc@1 85.156 (87.792)	Acc@5 99.219 (99.230)
Epoch: [49][300/391]	Time 0.1898 Data 0.0019 Loss 0.4707 (0.4036)	Acc@1 85.938 (87.191)	Acc@5 97.656 (99.089)
Testing the models......
Loss: 1.6858, Prec@1: 62.28, Prec@5: 87.48
Epoch time: 82s
Epoch: 50  lr: 0.100
Epoch: [50][000/391]	Time 1.3531 Data 1.1372 Loss 0.3050 (0.3050)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [50][100/391]	Time 0.1908 Data 0.0021 Loss 0.2158 (0.3590)	Acc@1 92.969 (88.591)	Acc@5 100.000 (99.110)
Epoch: [50][200/391]	Time 0.1901 Data 0.0025 Loss 0.4420 (0.3742)	Acc@1 86.719 (88.009)	Acc@5 100.000 (99.098)
Epoch: [50][300/391]	Time 0.1902 Data 0.0021 Loss 0.6743 (0.3928)	Acc@1 82.031 (87.471)	Acc@5 96.875 (99.027)
Testing the models......
Loss: 1.5320, Prec@1: 64.46, Prec@5: 88.08
Epoch time: 82s
Epoch: 51  lr: 0.100
Epoch: [51][000/391]	Time 1.3192 Data 1.0984 Loss 0.4119 (0.4119)	Acc@1 89.062 (89.062)	Acc@5 97.656 (97.656)
Epoch: [51][100/391]	Time 0.1901 Data 0.0019 Loss 0.3673 (0.3581)	Acc@1 92.969 (88.784)	Acc@5 98.438 (99.250)
Epoch: [51][200/391]	Time 0.1899 Data 0.0019 Loss 0.4144 (0.3682)	Acc@1 84.375 (88.196)	Acc@5 98.438 (99.230)
Epoch: [51][300/391]	Time 0.1897 Data 0.0019 Loss 0.4169 (0.3922)	Acc@1 85.938 (87.609)	Acc@5 100.000 (99.123)
Testing the models......
Loss: 1.6874, Prec@1: 63.18, Prec@5: 87.20
Epoch time: 82s
Epoch: 52  lr: 0.100
Epoch: [52][000/391]	Time 1.3720 Data 1.1593 Loss 0.3483 (0.3483)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [52][100/391]	Time 0.1903 Data 0.0019 Loss 0.5153 (0.3768)	Acc@1 85.156 (88.111)	Acc@5 98.438 (99.064)
Epoch: [52][200/391]	Time 0.1899 Data 0.0019 Loss 0.3831 (0.3728)	Acc@1 86.719 (88.270)	Acc@5 98.438 (99.184)
Epoch: [52][300/391]	Time 0.1899 Data 0.0020 Loss 0.4310 (0.3920)	Acc@1 85.156 (87.599)	Acc@5 99.219 (99.089)
Testing the models......
Loss: 1.5622, Prec@1: 64.51, Prec@5: 88.15
Epoch time: 82s
Epoch: 53  lr: 0.100
Epoch: [53][000/391]	Time 1.3589 Data 1.1331 Loss 0.3261 (0.3261)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [53][100/391]	Time 0.1891 Data 0.0019 Loss 0.4344 (0.3352)	Acc@1 87.500 (89.588)	Acc@5 100.000 (99.350)
Epoch: [53][200/391]	Time 0.1911 Data 0.0018 Loss 0.3678 (0.3591)	Acc@1 87.500 (88.822)	Acc@5 99.219 (99.223)
Epoch: [53][300/391]	Time 0.1914 Data 0.0018 Loss 0.3452 (0.3756)	Acc@1 91.406 (88.219)	Acc@5 100.000 (99.154)
Testing the models......
Loss: 1.4906, Prec@1: 65.28, Prec@5: 88.61
Epoch time: 82s
Saving models
Epoch: 54  lr: 0.100
Epoch: [54][000/391]	Time 1.3579 Data 1.1239 Loss 0.3721 (0.3721)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [54][100/391]	Time 0.1903 Data 0.0018 Loss 0.4934 (0.3328)	Acc@1 84.375 (89.612)	Acc@5 98.438 (99.466)
Epoch: [54][200/391]	Time 0.1897 Data 0.0019 Loss 0.3312 (0.3404)	Acc@1 88.281 (89.490)	Acc@5 100.000 (99.394)
Epoch: [54][300/391]	Time 0.1895 Data 0.0019 Loss 0.4578 (0.3601)	Acc@1 85.156 (88.748)	Acc@5 99.219 (99.281)
Testing the models......
Loss: 1.5424, Prec@1: 64.75, Prec@5: 87.80
Epoch time: 82s
Epoch: 55  lr: 0.100
Epoch: [55][000/391]	Time 1.3323 Data 1.1358 Loss 0.3697 (0.3697)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [55][100/391]	Time 0.1900 Data 0.0020 Loss 0.3158 (0.3286)	Acc@1 89.062 (89.735)	Acc@5 100.000 (99.343)
Epoch: [55][200/391]	Time 0.1897 Data 0.0021 Loss 0.3915 (0.3549)	Acc@1 89.844 (88.736)	Acc@5 98.438 (99.203)
Epoch: [55][300/391]	Time 0.1908 Data 0.0021 Loss 0.3672 (0.3751)	Acc@1 87.500 (88.058)	Acc@5 100.000 (99.177)
Testing the models......
Loss: 1.6018, Prec@1: 63.81, Prec@5: 87.22
Epoch time: 82s
Epoch: 56  lr: 0.100
Epoch: [56][000/391]	Time 1.3348 Data 1.1385 Loss 0.3820 (0.3820)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [56][100/391]	Time 0.1895 Data 0.0021 Loss 0.3489 (0.3367)	Acc@1 87.500 (89.472)	Acc@5 100.000 (99.381)
Epoch: [56][200/391]	Time 0.1913 Data 0.0025 Loss 0.3787 (0.3524)	Acc@1 88.281 (88.926)	Acc@5 99.219 (99.281)
Epoch: [56][300/391]	Time 0.1897 Data 0.0021 Loss 0.4910 (0.3663)	Acc@1 82.812 (88.364)	Acc@5 98.438 (99.250)
Testing the models......
Loss: 1.6124, Prec@1: 63.11, Prec@5: 87.97
Epoch time: 82s
Epoch: 57  lr: 0.100
Epoch: [57][000/391]	Time 1.3647 Data 1.1373 Loss 0.2754 (0.2754)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [57][100/391]	Time 0.1897 Data 0.0019 Loss 0.3188 (0.3125)	Acc@1 88.281 (90.432)	Acc@5 99.219 (99.505)
Epoch: [57][200/391]	Time 0.1893 Data 0.0020 Loss 0.4207 (0.3428)	Acc@1 86.719 (89.261)	Acc@5 98.438 (99.394)
Epoch: [57][300/391]	Time 0.1896 Data 0.0018 Loss 0.4480 (0.3627)	Acc@1 85.938 (88.543)	Acc@5 99.219 (99.304)
Testing the models......
Loss: 1.5820, Prec@1: 64.89, Prec@5: 87.34
Epoch time: 82s
Epoch: 58  lr: 0.100
Epoch: [58][000/391]	Time 1.3569 Data 1.1469 Loss 0.2774 (0.2774)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [58][100/391]	Time 0.1894 Data 0.0020 Loss 0.4776 (0.3196)	Acc@1 85.156 (90.006)	Acc@5 98.438 (99.343)
Epoch: [58][200/391]	Time 0.1907 Data 0.0024 Loss 0.2898 (0.3192)	Acc@1 92.188 (89.995)	Acc@5 100.000 (99.370)
Epoch: [58][300/391]	Time 0.1903 Data 0.0019 Loss 0.3842 (0.3341)	Acc@1 90.625 (89.553)	Acc@5 99.219 (99.354)
Testing the models......
Loss: 1.6058, Prec@1: 64.73, Prec@5: 87.89
Epoch time: 82s
Epoch: 59  lr: 0.100
Epoch: [59][000/391]	Time 1.3944 Data 1.2445 Loss 0.4271 (0.4271)	Acc@1 88.281 (88.281)	Acc@5 98.438 (98.438)
Epoch: [59][100/391]	Time 0.1903 Data 0.0025 Loss 0.2315 (0.3164)	Acc@1 92.969 (89.968)	Acc@5 99.219 (99.505)
Epoch: [59][200/391]	Time 0.1903 Data 0.0020 Loss 0.3820 (0.3244)	Acc@1 90.625 (89.731)	Acc@5 99.219 (99.464)
Epoch: [59][300/391]	Time 0.1905 Data 0.0022 Loss 0.7062 (0.3458)	Acc@1 79.688 (88.998)	Acc@5 97.656 (99.385)
Testing the models......
Loss: 1.6857, Prec@1: 62.67, Prec@5: 87.41
Epoch time: 82s
Epoch: 60  lr: 0.100
Epoch: [60][000/391]	Time 1.3255 Data 1.1790 Loss 0.3313 (0.3313)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [60][100/391]	Time 0.1896 Data 0.0020 Loss 0.3537 (0.3308)	Acc@1 90.625 (89.751)	Acc@5 100.000 (99.397)
Epoch: [60][200/391]	Time 0.1896 Data 0.0019 Loss 0.3096 (0.3361)	Acc@1 90.625 (89.443)	Acc@5 100.000 (99.421)
Epoch: [60][300/391]	Time 0.1891 Data 0.0018 Loss 0.5364 (0.3489)	Acc@1 85.938 (89.000)	Acc@5 98.438 (99.354)
Testing the models......
Loss: 1.5186, Prec@1: 65.91, Prec@5: 88.19
Epoch time: 82s
Saving models
Epoch: 61  lr: 0.100
Epoch: [61][000/391]	Time 1.4015 Data 1.1359 Loss 0.3818 (0.3818)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [61][100/391]	Time 0.1908 Data 0.0019 Loss 0.2744 (0.2991)	Acc@1 92.969 (90.842)	Acc@5 100.000 (99.366)
Epoch: [61][200/391]	Time 0.1919 Data 0.0020 Loss 0.2955 (0.3146)	Acc@1 86.719 (90.073)	Acc@5 100.000 (99.409)
Epoch: [61][300/391]	Time 0.1935 Data 0.0020 Loss 0.3791 (0.3404)	Acc@1 87.500 (89.236)	Acc@5 100.000 (99.333)
Testing the models......
Loss: 1.5705, Prec@1: 65.41, Prec@5: 87.92
Epoch time: 82s
Epoch: 62  lr: 0.100
Epoch: [62][000/391]	Time 1.3700 Data 1.1414 Loss 0.2342 (0.2342)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [62][100/391]	Time 0.1894 Data 0.0019 Loss 0.2639 (0.2929)	Acc@1 89.062 (90.965)	Acc@5 100.000 (99.528)
Epoch: [62][200/391]	Time 0.1906 Data 0.0022 Loss 0.3512 (0.3149)	Acc@1 85.156 (90.209)	Acc@5 99.219 (99.452)
Epoch: [62][300/391]	Time 0.1901 Data 0.0019 Loss 0.3150 (0.3349)	Acc@1 91.406 (89.587)	Acc@5 99.219 (99.359)
Testing the models......
Loss: 1.6585, Prec@1: 64.36, Prec@5: 87.45
Epoch time: 82s
Epoch: 63  lr: 0.100
Epoch: [63][000/391]	Time 1.3753 Data 1.1543 Loss 0.3444 (0.3444)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [63][100/391]	Time 0.1891 Data 0.0020 Loss 0.2119 (0.3207)	Acc@1 95.312 (90.014)	Acc@5 100.000 (99.459)
Epoch: [63][200/391]	Time 0.1893 Data 0.0019 Loss 0.3492 (0.3222)	Acc@1 88.281 (90.038)	Acc@5 99.219 (99.394)
Epoch: [63][300/391]	Time 0.1906 Data 0.0021 Loss 0.2991 (0.3294)	Acc@1 91.406 (89.711)	Acc@5 100.000 (99.411)
Testing the models......
Loss: 1.6018, Prec@1: 64.99, Prec@5: 87.88
Epoch time: 82s
Epoch: 64  lr: 0.100
Epoch: [64][000/391]	Time 1.3245 Data 1.0673 Loss 0.2313 (0.2313)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [64][100/391]	Time 0.1909 Data 0.0030 Loss 0.2164 (0.2855)	Acc@1 93.750 (91.097)	Acc@5 100.000 (99.466)
Epoch: [64][200/391]	Time 0.1910 Data 0.0033 Loss 0.3545 (0.2976)	Acc@1 90.625 (90.804)	Acc@5 99.219 (99.464)
Epoch: [64][300/391]	Time 0.1908 Data 0.0022 Loss 0.3674 (0.3194)	Acc@1 88.281 (90.062)	Acc@5 99.219 (99.346)
Testing the models......
Loss: 1.6002, Prec@1: 64.44, Prec@5: 88.24
Epoch time: 82s
Epoch: 65  lr: 0.100
Epoch: [65][000/391]	Time 1.3406 Data 1.1262 Loss 0.3220 (0.3220)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [65][100/391]	Time 0.1902 Data 0.0019 Loss 0.3794 (0.2853)	Acc@1 88.281 (91.035)	Acc@5 99.219 (99.582)
Epoch: [65][200/391]	Time 0.1895 Data 0.0019 Loss 0.4687 (0.2984)	Acc@1 81.250 (90.722)	Acc@5 99.219 (99.495)
Epoch: [65][300/391]	Time 0.1900 Data 0.0019 Loss 0.3439 (0.3226)	Acc@1 90.625 (89.932)	Acc@5 100.000 (99.346)
Testing the models......
Loss: 1.5896, Prec@1: 64.45, Prec@5: 87.37
Epoch time: 82s
Epoch: 66  lr: 0.100
Epoch: [66][000/391]	Time 1.3390 Data 1.1445 Loss 0.2928 (0.2928)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [66][100/391]	Time 0.1894 Data 0.0018 Loss 0.4222 (0.3107)	Acc@1 86.719 (89.991)	Acc@5 99.219 (99.520)
Epoch: [66][200/391]	Time 0.1951 Data 0.0019 Loss 0.2908 (0.3127)	Acc@1 90.625 (89.929)	Acc@5 100.000 (99.502)
Epoch: [66][300/391]	Time 0.1898 Data 0.0019 Loss 0.3813 (0.3273)	Acc@1 89.062 (89.553)	Acc@5 99.219 (99.450)
Testing the models......
Loss: 1.7209, Prec@1: 62.86, Prec@5: 86.82
Epoch time: 82s
Epoch: 67  lr: 0.100
Epoch: [67][000/391]	Time 1.3740 Data 1.1130 Loss 0.2246 (0.2246)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [67][100/391]	Time 0.1901 Data 0.0019 Loss 0.2638 (0.3063)	Acc@1 90.625 (90.416)	Acc@5 100.000 (99.520)
Epoch: [67][200/391]	Time 0.1898 Data 0.0019 Loss 0.2298 (0.3107)	Acc@1 89.062 (90.306)	Acc@5 100.000 (99.510)
Epoch: [67][300/391]	Time 0.1898 Data 0.0020 Loss 0.3532 (0.3183)	Acc@1 87.500 (90.018)	Acc@5 99.219 (99.460)
Testing the models......
Loss: 1.5765, Prec@1: 65.10, Prec@5: 87.95
Epoch time: 82s
Epoch: 68  lr: 0.100
Epoch: [68][000/391]	Time 1.3599 Data 1.1459 Loss 0.2404 (0.2404)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [68][100/391]	Time 0.1927 Data 0.0019 Loss 0.3367 (0.2764)	Acc@1 89.062 (91.306)	Acc@5 99.219 (99.598)
Epoch: [68][200/391]	Time 0.1907 Data 0.0019 Loss 0.3450 (0.2892)	Acc@1 87.500 (90.940)	Acc@5 100.000 (99.526)
Epoch: [68][300/391]	Time 0.1907 Data 0.0020 Loss 0.2339 (0.3042)	Acc@1 93.750 (90.524)	Acc@5 100.000 (99.437)
Testing the models......
Loss: 1.7016, Prec@1: 63.51, Prec@5: 86.64
Epoch time: 82s
Epoch: 69  lr: 0.100
Epoch: [69][000/391]	Time 1.3609 Data 1.1048 Loss 0.4750 (0.4750)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [69][100/391]	Time 0.1895 Data 0.0019 Loss 0.1957 (0.2956)	Acc@1 93.750 (90.958)	Acc@5 100.000 (99.451)
Epoch: [69][200/391]	Time 0.1896 Data 0.0019 Loss 0.4248 (0.3046)	Acc@1 88.281 (90.590)	Acc@5 99.219 (99.456)
Epoch: [69][300/391]	Time 0.1901 Data 0.0020 Loss 0.3927 (0.3203)	Acc@1 86.719 (90.080)	Acc@5 98.438 (99.385)
Testing the models......
Loss: 1.6681, Prec@1: 63.83, Prec@5: 87.61
Epoch time: 82s
Epoch: 70  lr: 0.100
Epoch: [70][000/391]	Time 1.4096 Data 1.1492 Loss 0.4221 (0.4221)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [70][100/391]	Time 0.1922 Data 0.0025 Loss 0.3619 (0.2879)	Acc@1 88.281 (90.934)	Acc@5 100.000 (99.691)
Epoch: [70][200/391]	Time 0.1899 Data 0.0018 Loss 0.1751 (0.2942)	Acc@1 93.750 (90.847)	Acc@5 100.000 (99.631)
Epoch: [70][300/391]	Time 0.1902 Data 0.0019 Loss 0.2471 (0.3135)	Acc@1 92.969 (90.189)	Acc@5 97.656 (99.499)
Testing the models......
Loss: 1.6455, Prec@1: 64.22, Prec@5: 87.36
Epoch time: 82s
Epoch: 71  lr: 0.100
Epoch: [71][000/391]	Time 1.3245 Data 1.1097 Loss 0.2352 (0.2352)	Acc@1 94.531 (94.531)	Acc@5 98.438 (98.438)
Epoch: [71][100/391]	Time 0.1935 Data 0.0019 Loss 0.3508 (0.2734)	Acc@1 91.406 (91.499)	Acc@5 99.219 (99.559)
Epoch: [71][200/391]	Time 0.1925 Data 0.0020 Loss 0.1721 (0.2736)	Acc@1 95.312 (91.523)	Acc@5 100.000 (99.604)
Epoch: [71][300/391]	Time 0.1907 Data 0.0025 Loss 0.3286 (0.2929)	Acc@1 88.281 (90.898)	Acc@5 99.219 (99.559)
Testing the models......
Loss: 1.5824, Prec@1: 65.34, Prec@5: 87.74
Epoch time: 82s
Epoch: 72  lr: 0.100
Epoch: [72][000/391]	Time 1.3681 Data 1.1773 Loss 0.2848 (0.2848)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [72][100/391]	Time 0.1936 Data 0.0024 Loss 0.2357 (0.2768)	Acc@1 90.625 (91.259)	Acc@5 100.000 (99.528)
Epoch: [72][200/391]	Time 0.1898 Data 0.0022 Loss 0.2055 (0.2809)	Acc@1 95.312 (91.091)	Acc@5 100.000 (99.553)
Epoch: [72][300/391]	Time 0.1902 Data 0.0021 Loss 0.2885 (0.3039)	Acc@1 91.406 (90.464)	Acc@5 100.000 (99.512)
Testing the models......
Loss: 1.5626, Prec@1: 65.53, Prec@5: 88.85
Epoch time: 82s
Epoch: 73  lr: 0.100
Epoch: [73][000/391]	Time 1.2937 Data 1.1089 Loss 0.2541 (0.2541)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [73][100/391]	Time 0.1894 Data 0.0020 Loss 0.2713 (0.2694)	Acc@1 91.406 (91.491)	Acc@5 100.000 (99.528)
Epoch: [73][200/391]	Time 0.1906 Data 0.0021 Loss 0.3651 (0.2895)	Acc@1 89.062 (90.847)	Acc@5 99.219 (99.561)
Epoch: [73][300/391]	Time 0.1895 Data 0.0019 Loss 0.1903 (0.3084)	Acc@1 93.750 (90.285)	Acc@5 100.000 (99.478)
Testing the models......
Loss: 1.7125, Prec@1: 63.17, Prec@5: 86.66
Epoch time: 82s
Epoch: 74  lr: 0.100
Epoch: [74][000/391]	Time 1.3988 Data 1.1699 Loss 0.2579 (0.2579)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [74][100/391]	Time 0.1935 Data 0.0022 Loss 0.1958 (0.2918)	Acc@1 93.750 (90.857)	Acc@5 100.000 (99.459)
Epoch: [74][200/391]	Time 0.1906 Data 0.0019 Loss 0.2515 (0.2879)	Acc@1 92.969 (91.053)	Acc@5 100.000 (99.491)
Epoch: [74][300/391]	Time 0.1895 Data 0.0019 Loss 0.2859 (0.2957)	Acc@1 91.406 (90.874)	Acc@5 100.000 (99.460)
Testing the models......
Loss: 1.5886, Prec@1: 65.43, Prec@5: 88.06
Epoch time: 82s
Epoch: 75  lr: 0.100
Epoch: [75][000/391]	Time 1.3665 Data 1.1646 Loss 0.2769 (0.2769)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [75][100/391]	Time 0.1892 Data 0.0018 Loss 0.2641 (0.2594)	Acc@1 92.188 (91.754)	Acc@5 100.000 (99.683)
Epoch: [75][200/391]	Time 0.1891 Data 0.0020 Loss 0.3047 (0.2690)	Acc@1 89.062 (91.480)	Acc@5 98.438 (99.635)
Epoch: [75][300/391]	Time 0.1894 Data 0.0020 Loss 0.3025 (0.2778)	Acc@1 92.188 (91.276)	Acc@5 98.438 (99.538)
Testing the models......
Loss: 1.6601, Prec@1: 65.21, Prec@5: 86.98
Epoch time: 82s
Epoch: 76  lr: 0.100
Epoch: [76][000/391]	Time 1.1725 Data 0.9850 Loss 0.2886 (0.2886)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [76][100/391]	Time 0.1898 Data 0.0020 Loss 0.2840 (0.2739)	Acc@1 92.969 (91.414)	Acc@5 100.000 (99.652)
Epoch: [76][200/391]	Time 0.1906 Data 0.0019 Loss 0.2991 (0.2915)	Acc@1 90.625 (90.878)	Acc@5 99.219 (99.572)
Epoch: [76][300/391]	Time 0.1897 Data 0.0024 Loss 0.3791 (0.2985)	Acc@1 89.062 (90.734)	Acc@5 99.219 (99.517)
Testing the models......
Loss: 1.6509, Prec@1: 64.91, Prec@5: 87.97
Epoch time: 82s
Epoch: 77  lr: 0.100
Epoch: [77][000/391]	Time 1.3326 Data 1.1343 Loss 0.2321 (0.2321)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [77][100/391]	Time 0.1955 Data 0.0019 Loss 0.1725 (0.2586)	Acc@1 93.750 (91.824)	Acc@5 100.000 (99.644)
Epoch: [77][200/391]	Time 0.1900 Data 0.0020 Loss 0.3348 (0.2784)	Acc@1 91.406 (91.185)	Acc@5 99.219 (99.596)
Epoch: [77][300/391]	Time 0.1891 Data 0.0018 Loss 0.3207 (0.3062)	Acc@1 89.062 (90.243)	Acc@5 100.000 (99.468)
Testing the models......
Loss: 1.6896, Prec@1: 64.35, Prec@5: 86.96
Epoch time: 82s
Epoch: 78  lr: 0.100
Epoch: [78][000/391]	Time 1.3298 Data 1.1463 Loss 0.3726 (0.3726)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [78][100/391]	Time 0.1892 Data 0.0025 Loss 0.3124 (0.2794)	Acc@1 89.062 (91.484)	Acc@5 97.656 (99.636)
Epoch: [78][200/391]	Time 0.1895 Data 0.0022 Loss 0.4080 (0.2846)	Acc@1 89.062 (91.200)	Acc@5 100.000 (99.607)
Epoch: [78][300/391]	Time 0.1895 Data 0.0020 Loss 0.3368 (0.3050)	Acc@1 91.406 (90.565)	Acc@5 99.219 (99.517)
Testing the models......
Loss: 1.6478, Prec@1: 63.91, Prec@5: 87.20
Epoch time: 82s
Epoch: 79  lr: 0.100
Epoch: [79][000/391]	Time 1.3506 Data 1.1326 Loss 0.2475 (0.2475)	Acc@1 94.531 (94.531)	Acc@5 99.219 (99.219)
Epoch: [79][100/391]	Time 0.1894 Data 0.0021 Loss 0.3600 (0.2654)	Acc@1 86.719 (91.662)	Acc@5 100.000 (99.559)
Epoch: [79][200/391]	Time 0.1891 Data 0.0020 Loss 0.3713 (0.2799)	Acc@1 87.500 (91.321)	Acc@5 99.219 (99.522)
Epoch: [79][300/391]	Time 0.1899 Data 0.0019 Loss 0.4190 (0.2958)	Acc@1 85.938 (90.789)	Acc@5 99.219 (99.465)
Testing the models......
Loss: 1.5259, Prec@1: 66.22, Prec@5: 88.69
Epoch time: 82s
Saving models
Epoch: 80  lr: 0.100
Epoch: [80][000/391]	Time 1.3954 Data 1.2098 Loss 0.2267 (0.2267)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [80][100/391]	Time 0.1891 Data 0.0018 Loss 0.3308 (0.2608)	Acc@1 89.062 (91.793)	Acc@5 100.000 (99.551)
Epoch: [80][200/391]	Time 0.1899 Data 0.0020 Loss 0.2971 (0.2695)	Acc@1 90.625 (91.519)	Acc@5 100.000 (99.592)
Epoch: [80][300/391]	Time 0.1896 Data 0.0020 Loss 0.2270 (0.2874)	Acc@1 93.750 (90.970)	Acc@5 99.219 (99.528)
Testing the models......
Loss: 1.5767, Prec@1: 65.71, Prec@5: 87.69
Epoch time: 82s
Epoch: 81  lr: 0.100
Epoch: [81][000/391]	Time 1.3670 Data 1.1553 Loss 0.2055 (0.2055)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [81][100/391]	Time 0.1892 Data 0.0020 Loss 0.1804 (0.2330)	Acc@1 96.094 (92.969)	Acc@5 99.219 (99.683)
Epoch: [81][200/391]	Time 0.1892 Data 0.0020 Loss 0.2325 (0.2456)	Acc@1 91.406 (92.526)	Acc@5 99.219 (99.666)
Epoch: [81][300/391]	Time 0.1900 Data 0.0026 Loss 0.3499 (0.2602)	Acc@1 89.844 (91.956)	Acc@5 100.000 (99.618)
Testing the models......
Loss: 1.5245, Prec@1: 66.41, Prec@5: 88.08
Epoch time: 82s
Saving models
Epoch: 82  lr: 0.100
Epoch: [82][000/391]	Time 1.3725 Data 1.1371 Loss 0.2396 (0.2396)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [82][100/391]	Time 0.1897 Data 0.0021 Loss 0.3480 (0.2630)	Acc@1 87.500 (91.692)	Acc@5 100.000 (99.629)
Epoch: [82][200/391]	Time 0.1897 Data 0.0019 Loss 0.2372 (0.2722)	Acc@1 90.625 (91.426)	Acc@5 100.000 (99.600)
Epoch: [82][300/391]	Time 0.1894 Data 0.0022 Loss 0.3078 (0.2888)	Acc@1 89.844 (90.864)	Acc@5 100.000 (99.533)
Testing the models......
Loss: 1.6870, Prec@1: 63.48, Prec@5: 86.86
Epoch time: 82s
Epoch: 83  lr: 0.100
Epoch: [83][000/391]	Time 1.3364 Data 1.1368 Loss 0.4384 (0.4384)	Acc@1 86.719 (86.719)	Acc@5 100.000 (100.000)
Epoch: [83][100/391]	Time 0.1902 Data 0.0019 Loss 0.3475 (0.2563)	Acc@1 89.844 (92.087)	Acc@5 100.000 (99.652)
Epoch: [83][200/391]	Time 0.1900 Data 0.0021 Loss 0.2966 (0.2657)	Acc@1 87.500 (91.810)	Acc@5 100.000 (99.588)
Epoch: [83][300/391]	Time 0.1908 Data 0.0019 Loss 0.3959 (0.2796)	Acc@1 87.500 (91.448)	Acc@5 100.000 (99.533)
Testing the models......
Loss: 1.5750, Prec@1: 65.10, Prec@5: 88.00
Epoch time: 82s
Epoch: 84  lr: 0.100
Epoch: [84][000/391]	Time 1.3576 Data 1.1366 Loss 0.2292 (0.2292)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [84][100/391]	Time 0.1897 Data 0.0018 Loss 0.3113 (0.2557)	Acc@1 91.406 (92.180)	Acc@5 99.219 (99.675)
Epoch: [84][200/391]	Time 0.1889 Data 0.0019 Loss 0.4086 (0.2594)	Acc@1 87.500 (92.075)	Acc@5 98.438 (99.619)
Epoch: [84][300/391]	Time 0.1899 Data 0.0019 Loss 0.3630 (0.2661)	Acc@1 89.844 (91.837)	Acc@5 99.219 (99.616)
Testing the models......
Loss: 1.6651, Prec@1: 64.00, Prec@5: 86.53
Epoch time: 82s
Epoch: 85  lr: 0.100
Epoch: [85][000/391]	Time 1.3291 Data 1.1023 Loss 0.1832 (0.1832)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [85][100/391]	Time 0.1962 Data 0.0018 Loss 0.3155 (0.2524)	Acc@1 90.625 (92.025)	Acc@5 99.219 (99.660)
Epoch: [85][200/391]	Time 0.1900 Data 0.0023 Loss 0.2695 (0.2580)	Acc@1 90.625 (92.102)	Acc@5 99.219 (99.654)
Epoch: [85][300/391]	Time 0.1892 Data 0.0020 Loss 0.2755 (0.2737)	Acc@1 92.188 (91.507)	Acc@5 99.219 (99.551)
Testing the models......
Loss: 1.6049, Prec@1: 65.13, Prec@5: 87.79
Epoch time: 82s
Epoch: 86  lr: 0.100
Epoch: [86][000/391]	Time 1.3208 Data 1.1324 Loss 0.1271 (0.1271)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [86][100/391]	Time 0.1902 Data 0.0020 Loss 0.2484 (0.2613)	Acc@1 92.969 (92.234)	Acc@5 99.219 (99.621)
Epoch: [86][200/391]	Time 0.1898 Data 0.0021 Loss 0.3377 (0.2601)	Acc@1 90.625 (92.219)	Acc@5 100.000 (99.596)
Epoch: [86][300/391]	Time 0.1910 Data 0.0020 Loss 0.3257 (0.2807)	Acc@1 89.844 (91.458)	Acc@5 99.219 (99.517)
Testing the models......
Loss: 1.7472, Prec@1: 62.82, Prec@5: 86.61
Epoch time: 82s
Epoch: 87  lr: 0.100
Epoch: [87][000/391]	Time 1.4232 Data 1.1637 Loss 0.4020 (0.4020)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [87][100/391]	Time 0.1905 Data 0.0019 Loss 0.3508 (0.2503)	Acc@1 84.375 (92.048)	Acc@5 100.000 (99.675)
Epoch: [87][200/391]	Time 0.1920 Data 0.0019 Loss 0.3301 (0.2627)	Acc@1 92.188 (91.822)	Acc@5 100.000 (99.611)
Epoch: [87][300/391]	Time 0.1903 Data 0.0018 Loss 0.3593 (0.2775)	Acc@1 89.844 (91.375)	Acc@5 98.438 (99.535)
Testing the models......
Loss: 1.5451, Prec@1: 66.33, Prec@5: 88.64
Epoch time: 82s
Epoch: 88  lr: 0.100
Epoch: [88][000/391]	Time 1.3394 Data 1.1394 Loss 0.1915 (0.1915)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [88][100/391]	Time 0.1893 Data 0.0018 Loss 0.3788 (0.2473)	Acc@1 89.062 (92.025)	Acc@5 99.219 (99.768)
Epoch: [88][200/391]	Time 0.1894 Data 0.0019 Loss 0.2596 (0.2618)	Acc@1 91.406 (91.581)	Acc@5 100.000 (99.654)
Epoch: [88][300/391]	Time 0.1893 Data 0.0019 Loss 0.2981 (0.2823)	Acc@1 89.844 (91.035)	Acc@5 99.219 (99.556)
Testing the models......
Loss: 1.7148, Prec@1: 64.09, Prec@5: 87.14
Epoch time: 82s
Epoch: 89  lr: 0.100
Epoch: [89][000/391]	Time 1.3103 Data 1.1201 Loss 0.2526 (0.2526)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [89][100/391]	Time 0.1895 Data 0.0019 Loss 0.2544 (0.2495)	Acc@1 92.188 (92.342)	Acc@5 100.000 (99.706)
Epoch: [89][200/391]	Time 0.1896 Data 0.0024 Loss 0.3444 (0.2607)	Acc@1 89.062 (91.900)	Acc@5 99.219 (99.658)
Epoch: [89][300/391]	Time 0.1896 Data 0.0019 Loss 0.2700 (0.2784)	Acc@1 92.188 (91.365)	Acc@5 99.219 (99.561)
Testing the models......
Loss: 1.6451, Prec@1: 65.01, Prec@5: 87.09
Epoch time: 82s
Epoch: 90  lr: 0.100
Epoch: [90][000/391]	Time 1.3400 Data 1.0832 Loss 0.2841 (0.2841)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [90][100/391]	Time 0.1896 Data 0.0021 Loss 0.2910 (0.2705)	Acc@1 91.406 (91.754)	Acc@5 100.000 (99.559)
Epoch: [90][200/391]	Time 0.1895 Data 0.0020 Loss 0.1597 (0.2588)	Acc@1 94.531 (91.989)	Acc@5 100.000 (99.572)
Epoch: [90][300/391]	Time 0.1901 Data 0.0020 Loss 0.3154 (0.2728)	Acc@1 92.188 (91.585)	Acc@5 99.219 (99.538)
Testing the models......
Loss: 1.6017, Prec@1: 65.34, Prec@5: 87.67
Epoch time: 82s
Epoch: 91  lr: 0.100
Epoch: [91][000/391]	Time 1.3147 Data 1.1166 Loss 0.3380 (0.3380)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [91][100/391]	Time 0.1955 Data 0.0018 Loss 0.1930 (0.2377)	Acc@1 94.531 (92.512)	Acc@5 100.000 (99.567)
Epoch: [91][200/391]	Time 0.1956 Data 0.0018 Loss 0.3508 (0.2483)	Acc@1 89.062 (92.261)	Acc@5 100.000 (99.561)
Epoch: [91][300/391]	Time 0.1902 Data 0.0018 Loss 0.2511 (0.2653)	Acc@1 90.625 (91.741)	Acc@5 100.000 (99.548)
Testing the models......
Loss: 1.5966, Prec@1: 65.17, Prec@5: 88.27
Epoch time: 82s
Epoch: 92  lr: 0.100
Epoch: [92][000/391]	Time 1.3208 Data 1.1324 Loss 0.2731 (0.2731)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [92][100/391]	Time 0.1894 Data 0.0018 Loss 0.2712 (0.2649)	Acc@1 90.625 (91.770)	Acc@5 100.000 (99.652)
Epoch: [92][200/391]	Time 0.1895 Data 0.0020 Loss 0.2961 (0.2670)	Acc@1 90.625 (91.814)	Acc@5 100.000 (99.619)
Epoch: [92][300/391]	Time 0.1892 Data 0.0019 Loss 0.3214 (0.2748)	Acc@1 90.625 (91.583)	Acc@5 100.000 (99.592)
Testing the models......
Loss: 1.7261, Prec@1: 63.74, Prec@5: 87.52
Epoch time: 82s
Epoch: 93  lr: 0.100
Epoch: [93][000/391]	Time 1.0818 Data 0.8584 Loss 0.1733 (0.1733)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [93][100/391]	Time 0.1924 Data 0.0020 Loss 0.2074 (0.2571)	Acc@1 93.750 (92.164)	Acc@5 100.000 (99.644)
Epoch: [93][200/391]	Time 0.1947 Data 0.0020 Loss 0.3347 (0.2595)	Acc@1 89.844 (92.094)	Acc@5 100.000 (99.635)
Epoch: [93][300/391]	Time 0.1891 Data 0.0018 Loss 0.3742 (0.2702)	Acc@1 89.062 (91.684)	Acc@5 99.219 (99.556)
Testing the models......
Loss: 1.6367, Prec@1: 65.08, Prec@5: 87.86
Epoch time: 82s
Epoch: 94  lr: 0.100
Epoch: [94][000/391]	Time 1.3297 Data 1.1341 Loss 0.2614 (0.2614)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [94][100/391]	Time 0.1899 Data 0.0019 Loss 0.1365 (0.2366)	Acc@1 96.094 (92.899)	Acc@5 100.000 (99.629)
Epoch: [94][200/391]	Time 0.1895 Data 0.0019 Loss 0.2293 (0.2510)	Acc@1 92.969 (92.180)	Acc@5 99.219 (99.674)
Epoch: [94][300/391]	Time 0.1898 Data 0.0021 Loss 0.2730 (0.2717)	Acc@1 89.844 (91.544)	Acc@5 100.000 (99.603)
Testing the models......
Loss: 1.5435, Prec@1: 65.87, Prec@5: 88.51
Epoch time: 82s
Epoch: 95  lr: 0.100
Epoch: [95][000/391]	Time 1.3675 Data 1.0921 Loss 0.1864 (0.1864)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [95][100/391]	Time 0.1914 Data 0.0020 Loss 0.1809 (0.2350)	Acc@1 94.531 (93.007)	Acc@5 100.000 (99.722)
Epoch: [95][200/391]	Time 0.1935 Data 0.0021 Loss 0.2856 (0.2487)	Acc@1 88.281 (92.483)	Acc@5 100.000 (99.693)
Epoch: [95][300/391]	Time 0.1919 Data 0.0021 Loss 0.3876 (0.2618)	Acc@1 89.062 (91.962)	Acc@5 100.000 (99.600)
Testing the models......
Loss: 1.6416, Prec@1: 64.85, Prec@5: 87.29
Epoch time: 82s
Epoch: 96  lr: 0.100
Epoch: [96][000/391]	Time 1.3209 Data 1.1174 Loss 0.2846 (0.2846)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [96][100/391]	Time 0.1944 Data 0.0020 Loss 0.1972 (0.2558)	Acc@1 93.750 (92.327)	Acc@5 99.219 (99.536)
Epoch: [96][200/391]	Time 0.1897 Data 0.0018 Loss 0.2279 (0.2635)	Acc@1 91.406 (91.896)	Acc@5 100.000 (99.584)
Epoch: [96][300/391]	Time 0.1895 Data 0.0019 Loss 0.3110 (0.2740)	Acc@1 90.625 (91.497)	Acc@5 99.219 (99.535)
Testing the models......
Loss: 1.6850, Prec@1: 63.23, Prec@5: 87.40
Epoch time: 82s
Epoch: 97  lr: 0.100
Epoch: [97][000/391]	Time 1.3519 Data 1.1265 Loss 0.2878 (0.2878)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [97][100/391]	Time 0.1903 Data 0.0020 Loss 0.2419 (0.2547)	Acc@1 91.406 (91.940)	Acc@5 100.000 (99.706)
Epoch: [97][200/391]	Time 0.1923 Data 0.0019 Loss 0.2853 (0.2533)	Acc@1 90.625 (92.071)	Acc@5 100.000 (99.681)
Epoch: [97][300/391]	Time 0.1904 Data 0.0019 Loss 0.2684 (0.2681)	Acc@1 95.312 (91.629)	Acc@5 100.000 (99.613)
Testing the models......
Loss: 1.6178, Prec@1: 65.27, Prec@5: 87.78
Epoch time: 82s
Epoch: 98  lr: 0.100
Epoch: [98][000/391]	Time 1.2994 Data 1.1012 Loss 0.0938 (0.0938)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [98][100/391]	Time 0.1898 Data 0.0020 Loss 0.2691 (0.2814)	Acc@1 92.188 (91.445)	Acc@5 99.219 (99.613)
Epoch: [98][200/391]	Time 0.1898 Data 0.0020 Loss 0.3945 (0.2735)	Acc@1 91.406 (91.647)	Acc@5 98.438 (99.584)
Epoch: [98][300/391]	Time 0.1904 Data 0.0020 Loss 0.3136 (0.2827)	Acc@1 88.281 (91.261)	Acc@5 99.219 (99.528)
Testing the models......
Loss: 1.6286, Prec@1: 64.20, Prec@5: 87.62
Epoch time: 82s
Epoch: 99  lr: 0.100
Epoch: [99][000/391]	Time 1.3237 Data 1.1326 Loss 0.1750 (0.1750)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [99][100/391]	Time 0.1894 Data 0.0020 Loss 0.2850 (0.2389)	Acc@1 92.969 (92.644)	Acc@5 98.438 (99.667)
Epoch: [99][200/391]	Time 0.1907 Data 0.0021 Loss 0.2945 (0.2470)	Acc@1 92.188 (92.394)	Acc@5 99.219 (99.658)
Epoch: [99][300/391]	Time 0.1898 Data 0.0020 Loss 0.2272 (0.2592)	Acc@1 93.750 (92.034)	Acc@5 100.000 (99.569)
Testing the models......
Loss: 1.5934, Prec@1: 65.75, Prec@5: 87.75
Epoch time: 82s
Epoch: 100  lr: 0.010
Epoch: [100][000/391]	Time 1.3994 Data 1.2042 Loss 0.2886 (0.2886)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [100][100/391]	Time 0.1924 Data 0.0018 Loss 0.1408 (0.1425)	Acc@1 96.875 (95.993)	Acc@5 100.000 (99.861)
Epoch: [100][200/391]	Time 0.1916 Data 0.0021 Loss 0.0974 (0.1140)	Acc@1 97.656 (97.093)	Acc@5 100.000 (99.922)
Epoch: [100][300/391]	Time 0.1908 Data 0.0021 Loss 0.0848 (0.1000)	Acc@1 96.875 (97.547)	Acc@5 100.000 (99.945)
Testing the models......
Loss: 1.0893, Prec@1: 73.40, Prec@5: 92.02
Epoch time: 82s
Saving models
Epoch: 101  lr: 0.010
Epoch: [101][000/391]	Time 1.3997 Data 1.2054 Loss 0.0591 (0.0591)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [101][100/391]	Time 0.1893 Data 0.0019 Loss 0.0506 (0.0547)	Acc@1 99.219 (99.064)	Acc@5 100.000 (100.000)
Epoch: [101][200/391]	Time 0.1896 Data 0.0018 Loss 0.0865 (0.0526)	Acc@1 99.219 (99.137)	Acc@5 100.000 (100.000)
Epoch: [101][300/391]	Time 0.1893 Data 0.0019 Loss 0.0707 (0.0532)	Acc@1 99.219 (99.125)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0544, Prec@1: 73.85, Prec@5: 92.35
Epoch time: 82s
Saving models
Epoch: 102  lr: 0.010
Epoch: [102][000/391]	Time 1.3454 Data 1.0869 Loss 0.0396 (0.0396)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [102][100/391]	Time 0.1895 Data 0.0020 Loss 0.0347 (0.0451)	Acc@1 100.000 (99.428)	Acc@5 100.000 (99.992)
Epoch: [102][200/391]	Time 0.1892 Data 0.0021 Loss 0.0522 (0.0442)	Acc@1 98.438 (99.429)	Acc@5 100.000 (99.996)
Epoch: [102][300/391]	Time 0.1938 Data 0.0019 Loss 0.0290 (0.0442)	Acc@1 99.219 (99.421)	Acc@5 100.000 (99.997)
Testing the models......
Loss: 1.0349, Prec@1: 74.09, Prec@5: 92.25
Epoch time: 82s
Saving models
Epoch: 103  lr: 0.010
Epoch: [103][000/391]	Time 1.3787 Data 1.1076 Loss 0.0336 (0.0336)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [103][100/391]	Time 0.1910 Data 0.0019 Loss 0.0357 (0.0390)	Acc@1 100.000 (99.606)	Acc@5 100.000 (100.000)
Epoch: [103][200/391]	Time 0.1907 Data 0.0021 Loss 0.0286 (0.0390)	Acc@1 100.000 (99.584)	Acc@5 100.000 (100.000)
Epoch: [103][300/391]	Time 0.1917 Data 0.0018 Loss 0.0489 (0.0388)	Acc@1 99.219 (99.590)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0203, Prec@1: 74.35, Prec@5: 92.55
Epoch time: 82s
Saving models
Epoch: 104  lr: 0.010
Epoch: [104][000/391]	Time 1.3531 Data 1.1210 Loss 0.0200 (0.0200)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [104][100/391]	Time 0.1896 Data 0.0018 Loss 0.0494 (0.0364)	Acc@1 99.219 (99.636)	Acc@5 100.000 (100.000)
Epoch: [104][200/391]	Time 0.1892 Data 0.0019 Loss 0.0476 (0.0364)	Acc@1 98.438 (99.642)	Acc@5 100.000 (100.000)
Epoch: [104][300/391]	Time 0.1923 Data 0.0018 Loss 0.0476 (0.0357)	Acc@1 98.438 (99.670)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0100, Prec@1: 74.69, Prec@5: 92.55
Epoch time: 82s
Saving models
Epoch: 105  lr: 0.010
Epoch: [105][000/391]	Time 1.3642 Data 1.1697 Loss 0.0418 (0.0418)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [105][100/391]	Time 0.1920 Data 0.0019 Loss 0.0299 (0.0317)	Acc@1 100.000 (99.776)	Acc@5 100.000 (100.000)
Epoch: [105][200/391]	Time 0.1923 Data 0.0019 Loss 0.0324 (0.0320)	Acc@1 100.000 (99.790)	Acc@5 100.000 (100.000)
Epoch: [105][300/391]	Time 0.1945 Data 0.0018 Loss 0.0208 (0.0323)	Acc@1 100.000 (99.787)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0103, Prec@1: 74.70, Prec@5: 92.43
Epoch time: 82s
Saving models
Epoch: 106  lr: 0.010
Epoch: [106][000/391]	Time 1.3316 Data 1.0737 Loss 0.0333 (0.0333)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [106][100/391]	Time 0.1901 Data 0.0018 Loss 0.0276 (0.0303)	Acc@1 100.000 (99.722)	Acc@5 100.000 (100.000)
Epoch: [106][200/391]	Time 0.1897 Data 0.0019 Loss 0.0223 (0.0300)	Acc@1 100.000 (99.794)	Acc@5 100.000 (100.000)
Epoch: [106][300/391]	Time 0.1895 Data 0.0018 Loss 0.0233 (0.0307)	Acc@1 99.219 (99.769)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0051, Prec@1: 74.92, Prec@5: 92.44
Epoch time: 82s
Saving models
Epoch: 107  lr: 0.010
Epoch: [107][000/391]	Time 1.3944 Data 1.1258 Loss 0.0374 (0.0374)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [107][100/391]	Time 0.1908 Data 0.0020 Loss 0.0320 (0.0290)	Acc@1 100.000 (99.791)	Acc@5 100.000 (100.000)
Epoch: [107][200/391]	Time 0.1907 Data 0.0022 Loss 0.0187 (0.0287)	Acc@1 100.000 (99.821)	Acc@5 100.000 (100.000)
Epoch: [107][300/391]	Time 0.1896 Data 0.0019 Loss 0.0308 (0.0291)	Acc@1 100.000 (99.818)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0048, Prec@1: 74.80, Prec@5: 92.44
Epoch time: 82s
Epoch: 108  lr: 0.010
Epoch: [108][000/391]	Time 1.3270 Data 1.0613 Loss 0.0223 (0.0223)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [108][100/391]	Time 0.1890 Data 0.0018 Loss 0.0230 (0.0278)	Acc@1 100.000 (99.799)	Acc@5 100.000 (100.000)
Epoch: [108][200/391]	Time 0.1898 Data 0.0020 Loss 0.0378 (0.0284)	Acc@1 98.438 (99.817)	Acc@5 100.000 (100.000)
Epoch: [108][300/391]	Time 0.1899 Data 0.0021 Loss 0.0186 (0.0285)	Acc@1 100.000 (99.826)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9956, Prec@1: 75.12, Prec@5: 92.51
Epoch time: 82s
Saving models
Epoch: 109  lr: 0.010
Epoch: [109][000/391]	Time 1.4031 Data 1.1719 Loss 0.0229 (0.0229)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [109][100/391]	Time 0.1900 Data 0.0021 Loss 0.0276 (0.0260)	Acc@1 100.000 (99.861)	Acc@5 100.000 (100.000)
Epoch: [109][200/391]	Time 0.1899 Data 0.0020 Loss 0.0229 (0.0272)	Acc@1 100.000 (99.868)	Acc@5 100.000 (100.000)
Epoch: [109][300/391]	Time 0.1902 Data 0.0021 Loss 0.0477 (0.0273)	Acc@1 99.219 (99.865)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9968, Prec@1: 74.88, Prec@5: 92.51
Epoch time: 82s
Epoch: 110  lr: 0.010
Epoch: [110][000/391]	Time 1.3206 Data 1.1300 Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [110][100/391]	Time 0.1896 Data 0.0018 Loss 0.0423 (0.0266)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [110][200/391]	Time 0.1901 Data 0.0020 Loss 0.0235 (0.0269)	Acc@1 100.000 (99.872)	Acc@5 100.000 (100.000)
Epoch: [110][300/391]	Time 0.1902 Data 0.0020 Loss 0.0265 (0.0268)	Acc@1 100.000 (99.875)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9915, Prec@1: 75.19, Prec@5: 92.48
Epoch time: 82s
Saving models
Epoch: 111  lr: 0.010
Epoch: [111][000/391]	Time 1.3244 Data 1.1355 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [111][100/391]	Time 0.1897 Data 0.0024 Loss 0.0224 (0.0252)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [111][200/391]	Time 0.1909 Data 0.0023 Loss 0.0297 (0.0252)	Acc@1 99.219 (99.868)	Acc@5 100.000 (100.000)
Epoch: [111][300/391]	Time 0.1908 Data 0.0021 Loss 0.0195 (0.0254)	Acc@1 100.000 (99.868)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9875, Prec@1: 75.25, Prec@5: 92.50
Epoch time: 82s
Saving models
Epoch: 112  lr: 0.010
Epoch: [112][000/391]	Time 1.4472 Data 1.1843 Loss 0.0213 (0.0213)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [112][100/391]	Time 0.1894 Data 0.0019 Loss 0.0250 (0.0242)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [112][200/391]	Time 0.1899 Data 0.0019 Loss 0.0237 (0.0245)	Acc@1 100.000 (99.895)	Acc@5 100.000 (100.000)
Epoch: [112][300/391]	Time 0.1897 Data 0.0019 Loss 0.0263 (0.0247)	Acc@1 100.000 (99.899)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9897, Prec@1: 75.24, Prec@5: 92.45
Epoch time: 82s
Epoch: 113  lr: 0.010
Epoch: [113][000/391]	Time 1.3913 Data 1.1982 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [113][100/391]	Time 0.1907 Data 0.0020 Loss 0.0221 (0.0240)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [113][200/391]	Time 0.1917 Data 0.0017 Loss 0.0270 (0.0242)	Acc@1 100.000 (99.918)	Acc@5 100.000 (100.000)
Epoch: [113][300/391]	Time 0.1896 Data 0.0019 Loss 0.0218 (0.0247)	Acc@1 100.000 (99.904)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9826, Prec@1: 75.42, Prec@5: 92.46
Epoch time: 82s
Saving models
Epoch: 114  lr: 0.010
Epoch: [114][000/391]	Time 1.4319 Data 1.2543 Loss 0.0504 (0.0504)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [114][100/391]	Time 0.1890 Data 0.0019 Loss 0.0484 (0.0235)	Acc@1 99.219 (99.892)	Acc@5 100.000 (100.000)
Epoch: [114][200/391]	Time 0.1904 Data 0.0018 Loss 0.0191 (0.0236)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [114][300/391]	Time 0.1899 Data 0.0019 Loss 0.0180 (0.0236)	Acc@1 100.000 (99.914)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9840, Prec@1: 75.35, Prec@5: 92.55
Epoch time: 82s
Epoch: 115  lr: 0.010
Epoch: [115][000/391]	Time 1.4450 Data 1.2282 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [115][100/391]	Time 0.1896 Data 0.0020 Loss 0.0254 (0.0241)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [115][200/391]	Time 0.1899 Data 0.0018 Loss 0.0248 (0.0237)	Acc@1 100.000 (99.914)	Acc@5 100.000 (100.000)
Epoch: [115][300/391]	Time 0.1898 Data 0.0019 Loss 0.0169 (0.0236)	Acc@1 100.000 (99.920)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9847, Prec@1: 75.27, Prec@5: 92.48
Epoch time: 82s
Epoch: 116  lr: 0.010
Epoch: [116][000/391]	Time 1.1998 Data 1.0014 Loss 0.0312 (0.0312)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [116][100/391]	Time 0.1896 Data 0.0019 Loss 0.0193 (0.0225)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [116][200/391]	Time 0.1897 Data 0.0019 Loss 0.0317 (0.0224)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [116][300/391]	Time 0.1895 Data 0.0018 Loss 0.0185 (0.0225)	Acc@1 100.000 (99.935)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9859, Prec@1: 75.15, Prec@5: 92.38
Epoch time: 82s
Epoch: 117  lr: 0.010
Epoch: [117][000/391]	Time 1.3367 Data 1.1388 Loss 0.0281 (0.0281)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [117][100/391]	Time 0.1899 Data 0.0020 Loss 0.0273 (0.0214)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [117][200/391]	Time 0.1897 Data 0.0020 Loss 0.0161 (0.0221)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Epoch: [117][300/391]	Time 0.1897 Data 0.0019 Loss 0.0178 (0.0221)	Acc@1 100.000 (99.925)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9823, Prec@1: 75.37, Prec@5: 92.49
Epoch time: 82s
Epoch: 118  lr: 0.010
Epoch: [118][000/391]	Time 1.3605 Data 1.1365 Loss 0.0233 (0.0233)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [118][100/391]	Time 0.1903 Data 0.0019 Loss 0.0207 (0.0222)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [118][200/391]	Time 0.1898 Data 0.0019 Loss 0.0209 (0.0223)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [118][300/391]	Time 0.1899 Data 0.0020 Loss 0.0349 (0.0224)	Acc@1 99.219 (99.927)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9753, Prec@1: 75.48, Prec@5: 92.58
Epoch time: 82s
Saving models
Epoch: 119  lr: 0.010
Epoch: [119][000/391]	Time 1.3475 Data 1.1453 Loss 0.0174 (0.0174)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [119][100/391]	Time 0.1949 Data 0.0029 Loss 0.0175 (0.0215)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [119][200/391]	Time 0.1904 Data 0.0020 Loss 0.0181 (0.0215)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [119][300/391]	Time 0.1906 Data 0.0024 Loss 0.0267 (0.0220)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9799, Prec@1: 75.39, Prec@5: 92.39
Epoch time: 82s
Epoch: 120  lr: 0.010
Epoch: [120][000/391]	Time 1.2847 Data 1.0700 Loss 0.0226 (0.0226)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [120][100/391]	Time 0.1899 Data 0.0019 Loss 0.0204 (0.0208)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [120][200/391]	Time 0.1896 Data 0.0018 Loss 0.0185 (0.0208)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [120][300/391]	Time 0.1903 Data 0.0020 Loss 0.0226 (0.0215)	Acc@1 100.000 (99.925)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9771, Prec@1: 75.50, Prec@5: 92.36
Epoch time: 82s
Saving models
Epoch: 121  lr: 0.010
Epoch: [121][000/391]	Time 1.4323 Data 1.2337 Loss 0.0164 (0.0164)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [121][100/391]	Time 0.1905 Data 0.0020 Loss 0.0326 (0.0224)	Acc@1 100.000 (99.876)	Acc@5 100.000 (100.000)
Epoch: [121][200/391]	Time 0.1906 Data 0.0019 Loss 0.0384 (0.0222)	Acc@1 99.219 (99.895)	Acc@5 100.000 (100.000)
Epoch: [121][300/391]	Time 0.1905 Data 0.0020 Loss 0.0157 (0.0217)	Acc@1 100.000 (99.901)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9761, Prec@1: 75.60, Prec@5: 92.42
Epoch time: 82s
Saving models
Epoch: 122  lr: 0.010
Epoch: [122][000/391]	Time 1.3422 Data 1.1428 Loss 0.0195 (0.0195)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [122][100/391]	Time 0.1898 Data 0.0020 Loss 0.0144 (0.0208)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [122][200/391]	Time 0.1905 Data 0.0020 Loss 0.0306 (0.0213)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [122][300/391]	Time 0.1901 Data 0.0020 Loss 0.0159 (0.0214)	Acc@1 100.000 (99.917)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9749, Prec@1: 75.68, Prec@5: 92.55
Epoch time: 82s
Saving models
Epoch: 123  lr: 0.010
Epoch: [123][000/391]	Time 1.3899 Data 1.1351 Loss 0.0192 (0.0192)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [123][100/391]	Time 0.1903 Data 0.0021 Loss 0.0187 (0.0200)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [123][200/391]	Time 0.1911 Data 0.0032 Loss 0.0205 (0.0201)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [123][300/391]	Time 0.1905 Data 0.0021 Loss 0.0202 (0.0205)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9799, Prec@1: 75.25, Prec@5: 92.45
Epoch time: 82s
Epoch: 124  lr: 0.010
Epoch: [124][000/391]	Time 1.3241 Data 1.1067 Loss 0.0269 (0.0269)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [124][100/391]	Time 0.1898 Data 0.0018 Loss 0.0240 (0.0206)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [124][200/391]	Time 0.1892 Data 0.0019 Loss 0.0185 (0.0205)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [124][300/391]	Time 0.1896 Data 0.0018 Loss 0.0186 (0.0205)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9778, Prec@1: 75.46, Prec@5: 92.44
Epoch time: 82s
Epoch: 125  lr: 0.010
Epoch: [125][000/391]	Time 1.2784 Data 1.0827 Loss 0.0276 (0.0276)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [125][100/391]	Time 0.1896 Data 0.0020 Loss 0.0157 (0.0199)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [125][200/391]	Time 0.1900 Data 0.0019 Loss 0.0249 (0.0201)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [125][300/391]	Time 0.1895 Data 0.0019 Loss 0.0285 (0.0203)	Acc@1 98.438 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9761, Prec@1: 75.43, Prec@5: 92.38
Epoch time: 82s
Epoch: 126  lr: 0.010
Epoch: [126][000/391]	Time 1.4414 Data 1.2191 Loss 0.0198 (0.0198)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [126][100/391]	Time 0.1903 Data 0.0020 Loss 0.0165 (0.0201)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [126][200/391]	Time 0.1903 Data 0.0020 Loss 0.0121 (0.0204)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Epoch: [126][300/391]	Time 0.1901 Data 0.0019 Loss 0.0213 (0.0203)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9777, Prec@1: 75.38, Prec@5: 92.21
Epoch time: 82s
Epoch: 127  lr: 0.010
Epoch: [127][000/391]	Time 1.3137 Data 1.1143 Loss 0.0174 (0.0174)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [127][100/391]	Time 0.1913 Data 0.0018 Loss 0.0166 (0.0200)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [127][200/391]	Time 0.1909 Data 0.0019 Loss 0.0162 (0.0202)	Acc@1 100.000 (99.911)	Acc@5 100.000 (100.000)
Epoch: [127][300/391]	Time 0.1896 Data 0.0019 Loss 0.0155 (0.0200)	Acc@1 100.000 (99.933)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9745, Prec@1: 75.37, Prec@5: 92.44
Epoch time: 82s
Epoch: 128  lr: 0.010
Epoch: [128][000/391]	Time 1.3783 Data 1.1813 Loss 0.0158 (0.0158)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [128][100/391]	Time 0.1899 Data 0.0018 Loss 0.0205 (0.0192)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [128][200/391]	Time 0.1896 Data 0.0019 Loss 0.0141 (0.0192)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [128][300/391]	Time 0.1902 Data 0.0030 Loss 0.0252 (0.0195)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9732, Prec@1: 75.55, Prec@5: 92.32
Epoch time: 82s
Epoch: 129  lr: 0.010
Epoch: [129][000/391]	Time 1.3718 Data 1.1116 Loss 0.0221 (0.0221)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [129][100/391]	Time 0.1899 Data 0.0022 Loss 0.0176 (0.0190)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [129][200/391]	Time 0.1909 Data 0.0023 Loss 0.0252 (0.0190)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [129][300/391]	Time 0.1900 Data 0.0021 Loss 0.0250 (0.0192)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9718, Prec@1: 75.35, Prec@5: 92.38
Epoch time: 82s
Epoch: 130  lr: 0.010
Epoch: [130][000/391]	Time 1.3914 Data 1.2366 Loss 0.0143 (0.0143)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [130][100/391]	Time 0.1918 Data 0.0018 Loss 0.0171 (0.0189)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [130][200/391]	Time 0.1939 Data 0.0019 Loss 0.0230 (0.0192)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [130][300/391]	Time 0.1926 Data 0.0018 Loss 0.0226 (0.0193)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9746, Prec@1: 75.46, Prec@5: 92.36
Epoch time: 82s
Epoch: 131  lr: 0.010
Epoch: [131][000/391]	Time 1.3345 Data 1.1079 Loss 0.0162 (0.0162)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [131][100/391]	Time 0.1896 Data 0.0018 Loss 0.0174 (0.0190)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [131][200/391]	Time 0.1900 Data 0.0019 Loss 0.0181 (0.0189)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [131][300/391]	Time 0.1901 Data 0.0018 Loss 0.0149 (0.0192)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9717, Prec@1: 75.33, Prec@5: 92.38
Epoch time: 82s
Epoch: 132  lr: 0.010
Epoch: [132][000/391]	Time 1.2765 Data 1.0585 Loss 0.0192 (0.0192)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [132][100/391]	Time 0.1896 Data 0.0020 Loss 0.0207 (0.0189)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [132][200/391]	Time 0.1899 Data 0.0021 Loss 0.0281 (0.0188)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [132][300/391]	Time 0.1893 Data 0.0019 Loss 0.0203 (0.0191)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9729, Prec@1: 75.27, Prec@5: 92.45
Epoch time: 82s
Epoch: 133  lr: 0.010
Epoch: [133][000/391]	Time 1.3286 Data 1.1552 Loss 0.0136 (0.0136)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [133][100/391]	Time 0.1889 Data 0.0019 Loss 0.0149 (0.0190)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [133][200/391]	Time 0.1903 Data 0.0018 Loss 0.0252 (0.0193)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [133][300/391]	Time 0.1911 Data 0.0018 Loss 0.0161 (0.0191)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9712, Prec@1: 75.41, Prec@5: 92.34
Epoch time: 82s
Epoch: 134  lr: 0.010
Epoch: [134][000/391]	Time 1.3564 Data 1.0918 Loss 0.0148 (0.0148)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [134][100/391]	Time 0.1929 Data 0.0020 Loss 0.0180 (0.0180)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [134][200/391]	Time 0.1897 Data 0.0022 Loss 0.0148 (0.0182)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [134][300/391]	Time 0.1940 Data 0.0025 Loss 0.0209 (0.0184)	Acc@1 99.219 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9697, Prec@1: 75.52, Prec@5: 92.55
Epoch time: 82s
Epoch: 135  lr: 0.010
Epoch: [135][000/391]	Time 1.3864 Data 1.1550 Loss 0.0176 (0.0176)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [135][100/391]	Time 0.1889 Data 0.0020 Loss 0.0160 (0.0177)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [135][200/391]	Time 0.1895 Data 0.0023 Loss 0.0195 (0.0179)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [135][300/391]	Time 0.1892 Data 0.0018 Loss 0.0130 (0.0186)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9696, Prec@1: 75.61, Prec@5: 92.52
Epoch time: 82s
Epoch: 136  lr: 0.010
Epoch: [136][000/391]	Time 1.2754 Data 1.0627 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [136][100/391]	Time 0.1899 Data 0.0021 Loss 0.0209 (0.0191)	Acc@1 100.000 (99.923)	Acc@5 100.000 (100.000)
Epoch: [136][200/391]	Time 0.1893 Data 0.0019 Loss 0.0183 (0.0185)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [136][300/391]	Time 0.1891 Data 0.0018 Loss 0.0238 (0.0188)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9709, Prec@1: 75.53, Prec@5: 92.47
Epoch time: 82s
Epoch: 137  lr: 0.010
Epoch: [137][000/391]	Time 1.3457 Data 1.0810 Loss 0.0182 (0.0182)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [137][100/391]	Time 0.1922 Data 0.0019 Loss 0.0196 (0.0182)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [137][200/391]	Time 0.1896 Data 0.0019 Loss 0.0140 (0.0185)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [137][300/391]	Time 0.1896 Data 0.0019 Loss 0.0252 (0.0186)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9708, Prec@1: 75.52, Prec@5: 92.34
Epoch time: 82s
Epoch: 138  lr: 0.010
Epoch: [138][000/391]	Time 1.3334 Data 1.0619 Loss 0.0204 (0.0204)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [138][100/391]	Time 0.1896 Data 0.0025 Loss 0.0250 (0.0183)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [138][200/391]	Time 0.1952 Data 0.0021 Loss 0.0227 (0.0186)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [138][300/391]	Time 0.1906 Data 0.0020 Loss 0.0219 (0.0185)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9715, Prec@1: 75.53, Prec@5: 92.42
Epoch time: 81s
Epoch: 139  lr: 0.010
Epoch: [139][000/391]	Time 1.3470 Data 1.1564 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [139][100/391]	Time 0.1894 Data 0.0021 Loss 0.0172 (0.0173)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [139][200/391]	Time 0.1894 Data 0.0019 Loss 0.0150 (0.0178)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [139][300/391]	Time 0.1892 Data 0.0019 Loss 0.0162 (0.0180)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9695, Prec@1: 75.44, Prec@5: 92.51
Epoch time: 82s
Epoch: 140  lr: 0.010
Epoch: [140][000/391]	Time 1.3123 Data 1.1250 Loss 0.0202 (0.0202)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [140][100/391]	Time 0.1892 Data 0.0019 Loss 0.0168 (0.0175)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [140][200/391]	Time 0.1899 Data 0.0021 Loss 0.0147 (0.0178)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [140][300/391]	Time 0.1936 Data 0.0019 Loss 0.0254 (0.0180)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9679, Prec@1: 75.38, Prec@5: 92.45
Epoch time: 82s
Epoch: 141  lr: 0.010
Epoch: [141][000/391]	Time 1.3796 Data 1.2130 Loss 0.0120 (0.0120)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [141][100/391]	Time 0.1898 Data 0.0019 Loss 0.0247 (0.0173)	Acc@1 99.219 (99.985)	Acc@5 100.000 (100.000)
Epoch: [141][200/391]	Time 0.1889 Data 0.0019 Loss 0.0180 (0.0174)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [141][300/391]	Time 0.1893 Data 0.0020 Loss 0.0264 (0.0178)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9692, Prec@1: 75.43, Prec@5: 92.41
Epoch time: 82s
Epoch: 142  lr: 0.010
Epoch: [142][000/391]	Time 1.3143 Data 1.0440 Loss 0.0171 (0.0171)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [142][100/391]	Time 0.1895 Data 0.0019 Loss 0.0237 (0.0171)	Acc@1 99.219 (99.938)	Acc@5 100.000 (100.000)
Epoch: [142][200/391]	Time 0.1890 Data 0.0018 Loss 0.0195 (0.0178)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [142][300/391]	Time 0.1937 Data 0.0019 Loss 0.0218 (0.0178)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9717, Prec@1: 75.57, Prec@5: 92.54
Epoch time: 82s
Epoch: 143  lr: 0.010
Epoch: [143][000/391]	Time 1.3763 Data 1.1626 Loss 0.0091 (0.0091)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [143][100/391]	Time 0.1897 Data 0.0021 Loss 0.0156 (0.0174)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [143][200/391]	Time 0.1900 Data 0.0020 Loss 0.0173 (0.0175)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [143][300/391]	Time 0.1901 Data 0.0020 Loss 0.0180 (0.0176)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9656, Prec@1: 75.72, Prec@5: 92.46
Epoch time: 82s
Saving models
Epoch: 144  lr: 0.010
Epoch: [144][000/391]	Time 1.3167 Data 1.0895 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [144][100/391]	Time 0.1892 Data 0.0019 Loss 0.0142 (0.0175)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [144][200/391]	Time 0.1909 Data 0.0021 Loss 0.0208 (0.0178)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [144][300/391]	Time 0.1894 Data 0.0019 Loss 0.0145 (0.0179)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9680, Prec@1: 75.56, Prec@5: 92.48
Epoch time: 82s
Epoch: 145  lr: 0.010
Epoch: [145][000/391]	Time 1.2591 Data 1.0435 Loss 0.0110 (0.0110)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [145][100/391]	Time 0.1906 Data 0.0019 Loss 0.0220 (0.0172)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [145][200/391]	Time 0.1904 Data 0.0018 Loss 0.0174 (0.0173)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [145][300/391]	Time 0.1904 Data 0.0018 Loss 0.0178 (0.0175)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9653, Prec@1: 75.86, Prec@5: 92.46
Epoch time: 82s
Saving models
Epoch: 146  lr: 0.010
Epoch: [146][000/391]	Time 1.3159 Data 1.1513 Loss 0.0207 (0.0207)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [146][100/391]	Time 0.1892 Data 0.0019 Loss 0.0171 (0.0172)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [146][200/391]	Time 0.1907 Data 0.0019 Loss 0.0145 (0.0178)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [146][300/391]	Time 0.1904 Data 0.0020 Loss 0.0179 (0.0178)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9661, Prec@1: 75.85, Prec@5: 92.50
Epoch time: 82s
Epoch: 147  lr: 0.010
Epoch: [147][000/391]	Time 1.2419 Data 1.0368 Loss 0.0166 (0.0166)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [147][100/391]	Time 0.1904 Data 0.0020 Loss 0.0179 (0.0172)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [147][200/391]	Time 0.1897 Data 0.0021 Loss 0.0175 (0.0172)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [147][300/391]	Time 0.1905 Data 0.0021 Loss 0.0237 (0.0176)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.70, Prec@5: 92.46
Epoch time: 82s
Epoch: 148  lr: 0.010
Epoch: [148][000/391]	Time 1.2994 Data 1.1148 Loss 0.0123 (0.0123)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [148][100/391]	Time 0.1896 Data 0.0019 Loss 0.0136 (0.0179)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [148][200/391]	Time 0.1892 Data 0.0019 Loss 0.0194 (0.0178)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Epoch: [148][300/391]	Time 0.1896 Data 0.0018 Loss 0.0275 (0.0176)	Acc@1 99.219 (99.940)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9676, Prec@1: 75.65, Prec@5: 92.35
Epoch time: 82s
Epoch: 149  lr: 0.010
Epoch: [149][000/391]	Time 1.3156 Data 1.1270 Loss 0.0172 (0.0172)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [149][100/391]	Time 0.1905 Data 0.0020 Loss 0.0146 (0.0168)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [149][200/391]	Time 0.1896 Data 0.0020 Loss 0.0187 (0.0172)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [149][300/391]	Time 0.1895 Data 0.0019 Loss 0.0230 (0.0171)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.81, Prec@5: 92.50
Epoch time: 82s
Epoch: 150  lr: 0.001
Epoch: [150][000/391]	Time 1.3517 Data 1.1269 Loss 0.0149 (0.0149)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [150][100/391]	Time 0.1893 Data 0.0019 Loss 0.0161 (0.0161)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [150][200/391]	Time 0.1897 Data 0.0020 Loss 0.0108 (0.0166)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [150][300/391]	Time 0.1907 Data 0.0021 Loss 0.0161 (0.0168)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9678, Prec@1: 75.62, Prec@5: 92.30
Epoch time: 82s
Epoch: 151  lr: 0.001
Epoch: [151][000/391]	Time 1.3511 Data 1.1196 Loss 0.0163 (0.0163)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [151][100/391]	Time 0.1901 Data 0.0019 Loss 0.0128 (0.0168)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [151][200/391]	Time 0.1900 Data 0.0020 Loss 0.0185 (0.0168)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [151][300/391]	Time 0.1893 Data 0.0019 Loss 0.0303 (0.0168)	Acc@1 99.219 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9637, Prec@1: 75.68, Prec@5: 92.37
Epoch time: 82s
Epoch: 152  lr: 0.001
Epoch: [152][000/391]	Time 1.3127 Data 1.1217 Loss 0.0157 (0.0157)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [152][100/391]	Time 0.1914 Data 0.0019 Loss 0.0144 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [152][200/391]	Time 0.1943 Data 0.0019 Loss 0.0146 (0.0165)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [152][300/391]	Time 0.1908 Data 0.0022 Loss 0.0161 (0.0167)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9641, Prec@1: 75.70, Prec@5: 92.30
Epoch time: 82s
Epoch: 153  lr: 0.001
Epoch: [153][000/391]	Time 1.3596 Data 1.2071 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [153][100/391]	Time 0.1908 Data 0.0018 Loss 0.0187 (0.0173)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [153][200/391]	Time 0.1908 Data 0.0019 Loss 0.0130 (0.0172)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [153][300/391]	Time 0.1896 Data 0.0020 Loss 0.0255 (0.0171)	Acc@1 99.219 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9652, Prec@1: 75.85, Prec@5: 92.38
Epoch time: 82s
Epoch: 154  lr: 0.001
Epoch: [154][000/391]	Time 1.3418 Data 1.1535 Loss 0.0195 (0.0195)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [154][100/391]	Time 0.1895 Data 0.0019 Loss 0.0239 (0.0170)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [154][200/391]	Time 0.1888 Data 0.0019 Loss 0.0155 (0.0168)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [154][300/391]	Time 0.1893 Data 0.0018 Loss 0.0136 (0.0167)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9663, Prec@1: 75.64, Prec@5: 92.46
Epoch time: 82s
Epoch: 155  lr: 0.001
Epoch: [155][000/391]	Time 1.3600 Data 1.1629 Loss 0.0140 (0.0140)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [155][100/391]	Time 0.1958 Data 0.0023 Loss 0.0170 (0.0165)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [155][200/391]	Time 0.1923 Data 0.0021 Loss 0.0135 (0.0165)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [155][300/391]	Time 0.1931 Data 0.0019 Loss 0.0175 (0.0167)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.76, Prec@5: 92.37
Epoch time: 82s
Epoch: 156  lr: 0.001
Epoch: [156][000/391]	Time 1.2796 Data 1.0811 Loss 0.0263 (0.0263)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][100/391]	Time 0.1894 Data 0.0018 Loss 0.0128 (0.0168)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [156][200/391]	Time 0.1897 Data 0.0022 Loss 0.0158 (0.0167)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [156][300/391]	Time 0.1898 Data 0.0018 Loss 0.0120 (0.0168)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9674, Prec@1: 75.84, Prec@5: 92.31
Epoch time: 82s
Epoch: 157  lr: 0.001
Epoch: [157][000/391]	Time 1.2934 Data 1.0751 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [157][100/391]	Time 0.1910 Data 0.0019 Loss 0.0200 (0.0169)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [157][200/391]	Time 0.1907 Data 0.0025 Loss 0.0144 (0.0167)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [157][300/391]	Time 0.1905 Data 0.0020 Loss 0.0167 (0.0164)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9661, Prec@1: 75.75, Prec@5: 92.46
Epoch time: 82s
Epoch: 158  lr: 0.001
Epoch: [158][000/391]	Time 1.2924 Data 1.1059 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [158][100/391]	Time 0.1897 Data 0.0019 Loss 0.0167 (0.0169)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [158][200/391]	Time 0.1898 Data 0.0020 Loss 0.0164 (0.0171)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [158][300/391]	Time 0.1895 Data 0.0019 Loss 0.0128 (0.0170)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9638, Prec@1: 75.81, Prec@5: 92.51
Epoch time: 82s
Epoch: 159  lr: 0.001
Epoch: [159][000/391]	Time 1.4130 Data 1.1499 Loss 0.0188 (0.0188)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [159][100/391]	Time 0.1891 Data 0.0019 Loss 0.0156 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [159][200/391]	Time 0.1907 Data 0.0019 Loss 0.0168 (0.0165)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [159][300/391]	Time 0.1905 Data 0.0020 Loss 0.0194 (0.0167)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.91, Prec@5: 92.41
Epoch time: 82s
Saving models
Epoch: 160  lr: 0.001
Epoch: [160][000/391]	Time 1.4313 Data 1.2275 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [160][100/391]	Time 0.1897 Data 0.0021 Loss 0.0178 (0.0169)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [160][200/391]	Time 0.1930 Data 0.0019 Loss 0.0173 (0.0169)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [160][300/391]	Time 0.1903 Data 0.0021 Loss 0.0151 (0.0168)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.69, Prec@5: 92.41
Epoch time: 82s
Epoch: 161  lr: 0.001
Epoch: [161][000/391]	Time 1.3276 Data 1.1419 Loss 0.0198 (0.0198)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [161][100/391]	Time 0.1897 Data 0.0019 Loss 0.0142 (0.0167)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [161][200/391]	Time 0.1900 Data 0.0021 Loss 0.0110 (0.0167)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [161][300/391]	Time 0.1898 Data 0.0018 Loss 0.0146 (0.0168)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9645, Prec@1: 75.71, Prec@5: 92.41
Epoch time: 82s
Epoch: 162  lr: 0.001
Epoch: [162][000/391]	Time 1.2866 Data 1.0911 Loss 0.0089 (0.0089)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][100/391]	Time 0.1899 Data 0.0019 Loss 0.0111 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [162][200/391]	Time 0.1892 Data 0.0019 Loss 0.0136 (0.0167)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [162][300/391]	Time 0.1896 Data 0.0019 Loss 0.0162 (0.0166)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9641, Prec@1: 75.82, Prec@5: 92.49
Epoch time: 82s
Epoch: 163  lr: 0.001
Epoch: [163][000/391]	Time 1.3119 Data 1.1023 Loss 0.0155 (0.0155)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [163][100/391]	Time 0.1894 Data 0.0018 Loss 0.0177 (0.0170)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [163][200/391]	Time 0.1899 Data 0.0018 Loss 0.0145 (0.0168)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [163][300/391]	Time 0.1899 Data 0.0019 Loss 0.0258 (0.0169)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9646, Prec@1: 75.70, Prec@5: 92.44
Epoch time: 82s
Epoch: 164  lr: 0.001
Epoch: [164][000/391]	Time 1.2878 Data 1.0714 Loss 0.0284 (0.0284)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [164][100/391]	Time 0.1899 Data 0.0018 Loss 0.0276 (0.0167)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [164][200/391]	Time 0.1927 Data 0.0019 Loss 0.0199 (0.0166)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [164][300/391]	Time 0.1896 Data 0.0019 Loss 0.0169 (0.0166)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9658, Prec@1: 75.74, Prec@5: 92.45
Epoch time: 82s
Epoch: 165  lr: 0.001
Epoch: [165][000/391]	Time 1.3517 Data 1.1321 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][100/391]	Time 0.1906 Data 0.0031 Loss 0.0133 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [165][200/391]	Time 0.1915 Data 0.0024 Loss 0.0183 (0.0165)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [165][300/391]	Time 0.1911 Data 0.0022 Loss 0.0178 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9630, Prec@1: 75.80, Prec@5: 92.38
Epoch time: 82s
Epoch: 166  lr: 0.001
Epoch: [166][000/391]	Time 1.2939 Data 1.1007 Loss 0.0132 (0.0132)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [166][100/391]	Time 0.1892 Data 0.0019 Loss 0.0168 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [166][200/391]	Time 0.1896 Data 0.0019 Loss 0.0147 (0.0163)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [166][300/391]	Time 0.1902 Data 0.0020 Loss 0.0180 (0.0166)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9679, Prec@1: 75.78, Prec@5: 92.41
Epoch time: 82s
Epoch: 167  lr: 0.001
Epoch: [167][000/391]	Time 1.4200 Data 1.2273 Loss 0.0129 (0.0129)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][100/391]	Time 0.1897 Data 0.0019 Loss 0.0157 (0.0168)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [167][200/391]	Time 0.1893 Data 0.0019 Loss 0.0146 (0.0165)	Acc@1 100.000 (99.988)	Acc@5 100.000 (100.000)
Epoch: [167][300/391]	Time 0.1896 Data 0.0019 Loss 0.0137 (0.0166)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9675, Prec@1: 75.74, Prec@5: 92.26
Epoch time: 82s
Epoch: 168  lr: 0.001
Epoch: [168][000/391]	Time 1.3326 Data 1.1847 Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][100/391]	Time 0.1895 Data 0.0019 Loss 0.0154 (0.0172)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [168][200/391]	Time 0.1897 Data 0.0021 Loss 0.0170 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [168][300/391]	Time 0.1898 Data 0.0018 Loss 0.0183 (0.0165)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.73, Prec@5: 92.40
Epoch time: 82s
Epoch: 169  lr: 0.001
Epoch: [169][000/391]	Time 1.3158 Data 1.1175 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][100/391]	Time 0.1900 Data 0.0020 Loss 0.0173 (0.0163)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [169][200/391]	Time 0.1905 Data 0.0018 Loss 0.0182 (0.0167)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [169][300/391]	Time 0.1904 Data 0.0019 Loss 0.0167 (0.0165)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9667, Prec@1: 75.72, Prec@5: 92.32
Epoch time: 82s
Epoch: 170  lr: 0.001
Epoch: [170][000/391]	Time 1.3245 Data 1.1198 Loss 0.0101 (0.0101)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [170][100/391]	Time 0.1897 Data 0.0020 Loss 0.0155 (0.0166)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [170][200/391]	Time 0.1898 Data 0.0020 Loss 0.0185 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [170][300/391]	Time 0.1900 Data 0.0020 Loss 0.0131 (0.0165)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.62, Prec@5: 92.45
Epoch time: 82s
Epoch: 171  lr: 0.001
Epoch: [171][000/391]	Time 1.3265 Data 1.1056 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [171][100/391]	Time 0.1904 Data 0.0020 Loss 0.0160 (0.0165)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [171][200/391]	Time 0.1889 Data 0.0019 Loss 0.0203 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [171][300/391]	Time 0.1890 Data 0.0019 Loss 0.0188 (0.0164)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.71, Prec@5: 92.41
Epoch time: 82s
Epoch: 172  lr: 0.001
Epoch: [172][000/391]	Time 1.3952 Data 1.1738 Loss 0.0162 (0.0162)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][100/391]	Time 0.1896 Data 0.0018 Loss 0.0166 (0.0171)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [172][200/391]	Time 0.1888 Data 0.0019 Loss 0.0149 (0.0169)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [172][300/391]	Time 0.1896 Data 0.0019 Loss 0.0222 (0.0165)	Acc@1 99.219 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.76, Prec@5: 92.44
Epoch time: 82s
Epoch: 173  lr: 0.001
Epoch: [173][000/391]	Time 1.2792 Data 1.0648 Loss 0.0210 (0.0210)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][100/391]	Time 0.1901 Data 0.0021 Loss 0.0195 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [173][200/391]	Time 0.1897 Data 0.0019 Loss 0.0167 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [173][300/391]	Time 0.1892 Data 0.0019 Loss 0.0127 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.62, Prec@5: 92.45
Epoch time: 82s
Epoch: 174  lr: 0.001
Epoch: [174][000/391]	Time 1.3270 Data 1.1297 Loss 0.0214 (0.0214)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][100/391]	Time 0.1902 Data 0.0029 Loss 0.0181 (0.0163)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [174][200/391]	Time 0.1901 Data 0.0021 Loss 0.0173 (0.0162)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [174][300/391]	Time 0.1911 Data 0.0020 Loss 0.0176 (0.0163)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9635, Prec@1: 75.81, Prec@5: 92.38
Epoch time: 82s
Epoch: 175  lr: 0.001
Epoch: [175][000/391]	Time 1.3326 Data 1.1417 Loss 0.0116 (0.0116)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][100/391]	Time 0.1895 Data 0.0018 Loss 0.0133 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [175][200/391]	Time 0.1914 Data 0.0019 Loss 0.0141 (0.0164)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [175][300/391]	Time 0.1897 Data 0.0020 Loss 0.0280 (0.0166)	Acc@1 99.219 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9611, Prec@1: 75.75, Prec@5: 92.35
Epoch time: 82s
Epoch: 176  lr: 0.001
Epoch: [176][000/391]	Time 1.3787 Data 1.1620 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][100/391]	Time 0.1890 Data 0.0019 Loss 0.0146 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [176][200/391]	Time 0.1896 Data 0.0019 Loss 0.0145 (0.0164)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [176][300/391]	Time 0.1892 Data 0.0018 Loss 0.0144 (0.0163)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9641, Prec@1: 75.67, Prec@5: 92.47
Epoch time: 82s
Epoch: 177  lr: 0.001
Epoch: [177][000/391]	Time 1.3470 Data 1.0879 Loss 0.0158 (0.0158)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [177][100/391]	Time 0.1889 Data 0.0020 Loss 0.0152 (0.0168)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [177][200/391]	Time 0.1888 Data 0.0020 Loss 0.0121 (0.0167)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [177][300/391]	Time 0.1898 Data 0.0019 Loss 0.0121 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9666, Prec@1: 75.64, Prec@5: 92.40
Epoch time: 82s
Epoch: 178  lr: 0.001
Epoch: [178][000/391]	Time 1.2975 Data 1.1018 Loss 0.0173 (0.0173)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][100/391]	Time 0.1897 Data 0.0021 Loss 0.0121 (0.0163)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [178][200/391]	Time 0.1901 Data 0.0021 Loss 0.0199 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [178][300/391]	Time 0.1891 Data 0.0019 Loss 0.0117 (0.0166)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9657, Prec@1: 75.51, Prec@5: 92.48
Epoch time: 82s
Epoch: 179  lr: 0.001
Epoch: [179][000/391]	Time 1.3520 Data 1.0919 Loss 0.0140 (0.0140)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][100/391]	Time 0.1937 Data 0.0020 Loss 0.0211 (0.0168)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [179][200/391]	Time 0.1897 Data 0.0019 Loss 0.0145 (0.0165)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [179][300/391]	Time 0.1891 Data 0.0019 Loss 0.0123 (0.0166)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9639, Prec@1: 75.74, Prec@5: 92.50
Epoch time: 82s
Epoch: 180  lr: 0.001
Epoch: [180][000/391]	Time 1.3382 Data 1.1252 Loss 0.0173 (0.0173)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][100/391]	Time 0.1897 Data 0.0018 Loss 0.0120 (0.0167)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [180][200/391]	Time 0.1892 Data 0.0019 Loss 0.0163 (0.0165)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [180][300/391]	Time 0.1894 Data 0.0019 Loss 0.0168 (0.0164)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9652, Prec@1: 75.66, Prec@5: 92.44
Epoch time: 82s
Epoch: 181  lr: 0.001
Epoch: [181][000/391]	Time 1.2946 Data 1.0760 Loss 0.0177 (0.0177)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [181][100/391]	Time 0.1898 Data 0.0019 Loss 0.0149 (0.0157)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [181][200/391]	Time 0.1895 Data 0.0020 Loss 0.0175 (0.0164)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [181][300/391]	Time 0.1899 Data 0.0019 Loss 0.0200 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9632, Prec@1: 75.74, Prec@5: 92.37
Epoch time: 82s
Epoch: 182  lr: 0.001
Epoch: [182][000/391]	Time 1.3203 Data 1.1247 Loss 0.0150 (0.0150)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [182][100/391]	Time 0.1901 Data 0.0019 Loss 0.0159 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [182][200/391]	Time 0.1904 Data 0.0020 Loss 0.0163 (0.0162)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [182][300/391]	Time 0.1900 Data 0.0018 Loss 0.0154 (0.0164)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.68, Prec@5: 92.41
Epoch time: 82s
Epoch: 183  lr: 0.001
Epoch: [183][000/391]	Time 1.3595 Data 1.1966 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [183][100/391]	Time 0.1927 Data 0.0021 Loss 0.0265 (0.0167)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [183][200/391]	Time 0.1909 Data 0.0027 Loss 0.0155 (0.0165)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [183][300/391]	Time 0.1904 Data 0.0023 Loss 0.0157 (0.0165)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9652, Prec@1: 75.60, Prec@5: 92.40
Epoch time: 82s
Epoch: 184  lr: 0.001
Epoch: [184][000/391]	Time 1.3544 Data 1.1495 Loss 0.0299 (0.0299)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [184][100/391]	Time 0.1898 Data 0.0019 Loss 0.0178 (0.0164)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [184][200/391]	Time 0.1899 Data 0.0019 Loss 0.0243 (0.0165)	Acc@1 99.219 (99.953)	Acc@5 100.000 (100.000)
Epoch: [184][300/391]	Time 0.1901 Data 0.0022 Loss 0.0139 (0.0164)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.68, Prec@5: 92.46
Epoch time: 82s
Epoch: 185  lr: 0.001
Epoch: [185][000/391]	Time 1.3673 Data 1.1580 Loss 0.0220 (0.0220)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [185][100/391]	Time 0.1910 Data 0.0020 Loss 0.0116 (0.0165)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [185][200/391]	Time 0.1897 Data 0.0019 Loss 0.0123 (0.0169)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [185][300/391]	Time 0.1893 Data 0.0020 Loss 0.0143 (0.0166)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9641, Prec@1: 75.69, Prec@5: 92.38
Epoch time: 82s
Epoch: 186  lr: 0.001
Epoch: [186][000/391]	Time 1.3377 Data 1.1396 Loss 0.0192 (0.0192)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [186][100/391]	Time 0.1901 Data 0.0019 Loss 0.0189 (0.0168)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [186][200/391]	Time 0.1896 Data 0.0019 Loss 0.0123 (0.0165)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [186][300/391]	Time 0.1902 Data 0.0021 Loss 0.0147 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9633, Prec@1: 75.67, Prec@5: 92.37
Epoch time: 82s
Epoch: 187  lr: 0.001
Epoch: [187][000/391]	Time 1.3939 Data 1.2350 Loss 0.0198 (0.0198)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [187][100/391]	Time 0.1903 Data 0.0019 Loss 0.0118 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [187][200/391]	Time 0.1903 Data 0.0021 Loss 0.0159 (0.0163)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [187][300/391]	Time 0.1890 Data 0.0019 Loss 0.0196 (0.0165)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9624, Prec@1: 75.76, Prec@5: 92.47
Epoch time: 82s
Epoch: 188  lr: 0.001
Epoch: [188][000/391]	Time 1.4082 Data 1.2231 Loss 0.0122 (0.0122)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [188][100/391]	Time 0.1894 Data 0.0019 Loss 0.0126 (0.0163)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [188][200/391]	Time 0.1896 Data 0.0020 Loss 0.0142 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [188][300/391]	Time 0.1901 Data 0.0020 Loss 0.0182 (0.0165)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.70, Prec@5: 92.46
Epoch time: 82s
Epoch: 189  lr: 0.001
Epoch: [189][000/391]	Time 1.3606 Data 1.1381 Loss 0.0157 (0.0157)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [189][100/391]	Time 0.1905 Data 0.0021 Loss 0.0185 (0.0160)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [189][200/391]	Time 0.1901 Data 0.0021 Loss 0.0209 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [189][300/391]	Time 0.1907 Data 0.0020 Loss 0.0151 (0.0164)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9625, Prec@1: 75.76, Prec@5: 92.57
Epoch time: 82s
Epoch: 190  lr: 0.001
Epoch: [190][000/391]	Time 1.2881 Data 1.0736 Loss 0.0180 (0.0180)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [190][100/391]	Time 0.1895 Data 0.0019 Loss 0.0252 (0.0172)	Acc@1 99.219 (99.946)	Acc@5 100.000 (100.000)
Epoch: [190][200/391]	Time 0.1907 Data 0.0018 Loss 0.0142 (0.0168)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [190][300/391]	Time 0.1909 Data 0.0019 Loss 0.0153 (0.0168)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.80, Prec@5: 92.34
Epoch time: 82s
Epoch: 191  lr: 0.001
Epoch: [191][000/391]	Time 1.2904 Data 1.0688 Loss 0.0188 (0.0188)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [191][100/391]	Time 0.1895 Data 0.0024 Loss 0.0202 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [191][200/391]	Time 0.1895 Data 0.0019 Loss 0.0152 (0.0159)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [191][300/391]	Time 0.1893 Data 0.0019 Loss 0.0181 (0.0162)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9614, Prec@1: 75.68, Prec@5: 92.47
Epoch time: 82s
Epoch: 192  lr: 0.001
Epoch: [192][000/391]	Time 1.3435 Data 1.1278 Loss 0.0146 (0.0146)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [192][100/391]	Time 0.1892 Data 0.0020 Loss 0.0150 (0.0160)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [192][200/391]	Time 0.1889 Data 0.0018 Loss 0.0136 (0.0158)	Acc@1 100.000 (99.996)	Acc@5 100.000 (100.000)
Epoch: [192][300/391]	Time 0.1896 Data 0.0019 Loss 0.0206 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9637, Prec@1: 75.72, Prec@5: 92.40
Epoch time: 82s
Epoch: 193  lr: 0.001
Epoch: [193][000/391]	Time 1.3247 Data 1.1240 Loss 0.0145 (0.0145)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [193][100/391]	Time 0.1893 Data 0.0020 Loss 0.0180 (0.0167)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [193][200/391]	Time 0.1895 Data 0.0020 Loss 0.0193 (0.0165)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [193][300/391]	Time 0.1896 Data 0.0020 Loss 0.0243 (0.0165)	Acc@1 99.219 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9632, Prec@1: 75.84, Prec@5: 92.39
Epoch time: 82s
Epoch: 194  lr: 0.001
Epoch: [194][000/391]	Time 1.3331 Data 1.1390 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [194][100/391]	Time 0.1897 Data 0.0018 Loss 0.0160 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [194][200/391]	Time 0.1876 Data 0.0019 Loss 0.0198 (0.0163)	Acc@1 99.219 (99.946)	Acc@5 100.000 (100.000)
Epoch: [194][300/391]	Time 0.1893 Data 0.0018 Loss 0.0133 (0.0165)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9667, Prec@1: 75.63, Prec@5: 92.36
Epoch time: 82s
Epoch: 195  lr: 0.001
Epoch: [195][000/391]	Time 1.4449 Data 1.2180 Loss 0.0147 (0.0147)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [195][100/391]	Time 0.1891 Data 0.0019 Loss 0.0234 (0.0165)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [195][200/391]	Time 0.1891 Data 0.0019 Loss 0.0150 (0.0163)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [195][300/391]	Time 0.1897 Data 0.0019 Loss 0.0151 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.81, Prec@5: 92.44
Epoch time: 82s
Epoch: 196  lr: 0.001
Epoch: [196][000/391]	Time 1.3794 Data 1.1548 Loss 0.0155 (0.0155)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [196][100/391]	Time 0.1897 Data 0.0019 Loss 0.0158 (0.0168)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [196][200/391]	Time 0.1894 Data 0.0021 Loss 0.0180 (0.0168)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [196][300/391]	Time 0.1897 Data 0.0018 Loss 0.0185 (0.0166)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9661, Prec@1: 75.58, Prec@5: 92.35
Epoch time: 82s
Epoch: 197  lr: 0.001
Epoch: [197][000/391]	Time 1.2842 Data 1.1273 Loss 0.0269 (0.0269)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [197][100/391]	Time 0.1888 Data 0.0019 Loss 0.0228 (0.0163)	Acc@1 99.219 (99.930)	Acc@5 100.000 (100.000)
Epoch: [197][200/391]	Time 0.1896 Data 0.0021 Loss 0.0176 (0.0166)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [197][300/391]	Time 0.1896 Data 0.0021 Loss 0.0145 (0.0166)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9635, Prec@1: 75.50, Prec@5: 92.52
Epoch time: 82s
Epoch: 198  lr: 0.001
Epoch: [198][000/391]	Time 1.3443 Data 1.1335 Loss 0.0135 (0.0135)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [198][100/391]	Time 0.1887 Data 0.0018 Loss 0.0144 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [198][200/391]	Time 0.1898 Data 0.0018 Loss 0.0264 (0.0164)	Acc@1 99.219 (99.969)	Acc@5 100.000 (100.000)
Epoch: [198][300/391]	Time 0.1896 Data 0.0019 Loss 0.0147 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9611, Prec@1: 75.73, Prec@5: 92.39
Epoch time: 82s
Epoch: 199  lr: 0.001
Epoch: [199][000/391]	Time 1.4688 Data 1.2601 Loss 0.0143 (0.0143)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [199][100/391]	Time 0.1912 Data 0.0020 Loss 0.0167 (0.0165)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [199][200/391]	Time 0.1891 Data 0.0019 Loss 0.0149 (0.0162)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [199][300/391]	Time 0.1899 Data 0.0019 Loss 0.0121 (0.0165)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9653, Prec@1: 75.71, Prec@5: 92.37
Epoch time: 82s
Epoch: 200  lr: 0.001
Epoch: [200][000/391]	Time 1.3709 Data 1.2125 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [200][100/391]	Time 0.1917 Data 0.0018 Loss 0.0130 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [200][200/391]	Time 0.1919 Data 0.0019 Loss 0.0145 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [200][300/391]	Time 0.1920 Data 0.0023 Loss 0.0151 (0.0162)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9620, Prec@1: 75.73, Prec@5: 92.41
Epoch time: 82s
Epoch: 201  lr: 0.001
Epoch: [201][000/391]	Time 1.3522 Data 1.1236 Loss 0.0153 (0.0153)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [201][100/391]	Time 0.1898 Data 0.0018 Loss 0.0165 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [201][200/391]	Time 0.1901 Data 0.0018 Loss 0.0146 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [201][300/391]	Time 0.1910 Data 0.0019 Loss 0.0141 (0.0166)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9657, Prec@1: 75.68, Prec@5: 92.40
Epoch time: 82s
Epoch: 202  lr: 0.001
Epoch: [202][000/391]	Time 1.3782 Data 1.2314 Loss 0.0147 (0.0147)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [202][100/391]	Time 0.1895 Data 0.0020 Loss 0.0205 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [202][200/391]	Time 0.1897 Data 0.0018 Loss 0.0171 (0.0166)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [202][300/391]	Time 0.1900 Data 0.0020 Loss 0.0177 (0.0167)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9672, Prec@1: 75.65, Prec@5: 92.38
Epoch time: 82s
Epoch: 203  lr: 0.001
Epoch: [203][000/391]	Time 1.2485 Data 1.0410 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [203][100/391]	Time 0.1910 Data 0.0026 Loss 0.0162 (0.0162)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [203][200/391]	Time 0.1911 Data 0.0022 Loss 0.0110 (0.0161)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [203][300/391]	Time 0.1901 Data 0.0020 Loss 0.0125 (0.0162)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9659, Prec@1: 75.72, Prec@5: 92.32
Epoch time: 82s
Epoch: 204  lr: 0.001
Epoch: [204][000/391]	Time 1.3378 Data 1.1254 Loss 0.0180 (0.0180)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [204][100/391]	Time 0.1890 Data 0.0018 Loss 0.0120 (0.0165)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [204][200/391]	Time 0.1902 Data 0.0018 Loss 0.0126 (0.0161)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [204][300/391]	Time 0.1894 Data 0.0019 Loss 0.0176 (0.0164)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9626, Prec@1: 75.82, Prec@5: 92.44
Epoch time: 82s
Epoch: 205  lr: 0.001
Epoch: [205][000/391]	Time 1.3734 Data 1.1559 Loss 0.0138 (0.0138)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [205][100/391]	Time 0.1896 Data 0.0019 Loss 0.0151 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [205][200/391]	Time 0.1896 Data 0.0019 Loss 0.0129 (0.0160)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [205][300/391]	Time 0.1891 Data 0.0019 Loss 0.0155 (0.0160)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9594, Prec@1: 75.87, Prec@5: 92.58
Epoch time: 82s
Epoch: 206  lr: 0.001
Epoch: [206][000/391]	Time 1.3098 Data 1.1113 Loss 0.0103 (0.0103)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [206][100/391]	Time 0.1899 Data 0.0021 Loss 0.0218 (0.0164)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [206][200/391]	Time 0.1897 Data 0.0019 Loss 0.0131 (0.0165)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [206][300/391]	Time 0.1896 Data 0.0019 Loss 0.0169 (0.0165)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9652, Prec@1: 75.81, Prec@5: 92.36
Epoch time: 82s
Epoch: 207  lr: 0.001
Epoch: [207][000/391]	Time 1.3446 Data 1.1615 Loss 0.0204 (0.0204)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [207][100/391]	Time 0.1892 Data 0.0019 Loss 0.0147 (0.0165)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [207][200/391]	Time 0.1900 Data 0.0019 Loss 0.0154 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [207][300/391]	Time 0.1901 Data 0.0031 Loss 0.0176 (0.0164)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9617, Prec@1: 75.86, Prec@5: 92.37
Epoch time: 82s
Epoch: 208  lr: 0.001
Epoch: [208][000/391]	Time 1.3722 Data 1.0925 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [208][100/391]	Time 0.1938 Data 0.0020 Loss 0.0133 (0.0162)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [208][200/391]	Time 0.1969 Data 0.0023 Loss 0.0146 (0.0161)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [208][300/391]	Time 0.1911 Data 0.0028 Loss 0.0144 (0.0162)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9617, Prec@1: 75.64, Prec@5: 92.49
Epoch time: 82s
Epoch: 209  lr: 0.001
Epoch: [209][000/391]	Time 1.2029 Data 1.0388 Loss 0.0181 (0.0181)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [209][100/391]	Time 0.1907 Data 0.0020 Loss 0.0173 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [209][200/391]	Time 0.1895 Data 0.0020 Loss 0.0215 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [209][300/391]	Time 0.1935 Data 0.0019 Loss 0.0158 (0.0163)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9648, Prec@1: 75.73, Prec@5: 92.48
Epoch time: 82s
Epoch: 210  lr: 0.001
Epoch: [210][000/391]	Time 1.1816 Data 0.9896 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [210][100/391]	Time 0.1946 Data 0.0020 Loss 0.0194 (0.0162)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [210][200/391]	Time 0.1915 Data 0.0021 Loss 0.0153 (0.0162)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [210][300/391]	Time 0.1941 Data 0.0019 Loss 0.0164 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9625, Prec@1: 75.65, Prec@5: 92.45
Epoch time: 82s
Epoch: 211  lr: 0.001
Epoch: [211][000/391]	Time 1.3535 Data 1.1310 Loss 0.0189 (0.0189)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [211][100/391]	Time 0.1900 Data 0.0023 Loss 0.0197 (0.0166)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [211][200/391]	Time 0.1896 Data 0.0020 Loss 0.0152 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [211][300/391]	Time 0.1896 Data 0.0018 Loss 0.0129 (0.0161)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9654, Prec@1: 75.69, Prec@5: 92.35
Epoch time: 82s
Epoch: 212  lr: 0.001
Epoch: [212][000/391]	Time 1.3515 Data 1.1293 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [212][100/391]	Time 0.1928 Data 0.0023 Loss 0.0168 (0.0167)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [212][200/391]	Time 0.1894 Data 0.0019 Loss 0.0155 (0.0164)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [212][300/391]	Time 0.1901 Data 0.0023 Loss 0.0190 (0.0164)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9640, Prec@1: 75.56, Prec@5: 92.33
Epoch time: 82s
Epoch: 213  lr: 0.001
Epoch: [213][000/391]	Time 1.1553 Data 0.9610 Loss 0.0109 (0.0109)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [213][100/391]	Time 0.1907 Data 0.0022 Loss 0.0156 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [213][200/391]	Time 0.1902 Data 0.0020 Loss 0.0208 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [213][300/391]	Time 0.1904 Data 0.0023 Loss 0.0135 (0.0164)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9665, Prec@1: 75.41, Prec@5: 92.40
Epoch time: 82s
Epoch: 214  lr: 0.001
Epoch: [214][000/391]	Time 1.4335 Data 1.2335 Loss 0.0133 (0.0133)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [214][100/391]	Time 0.1933 Data 0.0023 Loss 0.0111 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [214][200/391]	Time 0.1896 Data 0.0020 Loss 0.0195 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [214][300/391]	Time 0.1897 Data 0.0020 Loss 0.0136 (0.0163)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9638, Prec@1: 75.73, Prec@5: 92.42
Epoch time: 82s
Epoch: 215  lr: 0.001
Epoch: [215][000/391]	Time 1.1272 Data 0.9016 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [215][100/391]	Time 0.1908 Data 0.0023 Loss 0.0147 (0.0165)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [215][200/391]	Time 0.1901 Data 0.0020 Loss 0.0230 (0.0162)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [215][300/391]	Time 0.1895 Data 0.0020 Loss 0.0190 (0.0163)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9727, Prec@1: 75.57, Prec@5: 92.23
Epoch time: 82s
Epoch: 216  lr: 0.001
Epoch: [216][000/391]	Time 1.3633 Data 1.1754 Loss 0.0109 (0.0109)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [216][100/391]	Time 0.1902 Data 0.0024 Loss 0.0130 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [216][200/391]	Time 0.1898 Data 0.0020 Loss 0.0187 (0.0159)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [216][300/391]	Time 0.1902 Data 0.0020 Loss 0.0146 (0.0159)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9636, Prec@1: 75.74, Prec@5: 92.53
Epoch time: 82s
Epoch: 217  lr: 0.001
Epoch: [217][000/391]	Time 1.1358 Data 0.9864 Loss 0.0230 (0.0230)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [217][100/391]	Time 0.1930 Data 0.0029 Loss 0.0113 (0.0157)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [217][200/391]	Time 0.1905 Data 0.0020 Loss 0.0125 (0.0158)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [217][300/391]	Time 0.1904 Data 0.0026 Loss 0.0167 (0.0159)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9631, Prec@1: 75.63, Prec@5: 92.47
Epoch time: 82s
Epoch: 218  lr: 0.001
Epoch: [218][000/391]	Time 1.4314 Data 1.2315 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [218][100/391]	Time 0.1897 Data 0.0019 Loss 0.0177 (0.0165)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [218][200/391]	Time 0.1902 Data 0.0019 Loss 0.0174 (0.0165)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [218][300/391]	Time 0.1903 Data 0.0021 Loss 0.0169 (0.0164)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9693, Prec@1: 75.63, Prec@5: 92.26
Epoch time: 82s
Epoch: 219  lr: 0.001
Epoch: [219][000/391]	Time 1.1742 Data 0.9166 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [219][100/391]	Time 0.1897 Data 0.0020 Loss 0.0109 (0.0167)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [219][200/391]	Time 0.1897 Data 0.0023 Loss 0.0149 (0.0164)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [219][300/391]	Time 0.1898 Data 0.0019 Loss 0.0156 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9613, Prec@1: 75.81, Prec@5: 92.48
Epoch time: 82s
Epoch: 220  lr: 0.001
Epoch: [220][000/391]	Time 1.3139 Data 1.0331 Loss 0.0158 (0.0158)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [220][100/391]	Time 0.1957 Data 0.0021 Loss 0.0146 (0.0169)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [220][200/391]	Time 0.1919 Data 0.0025 Loss 0.0149 (0.0167)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [220][300/391]	Time 0.1887 Data 0.0028 Loss 0.0170 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9635, Prec@1: 75.72, Prec@5: 92.42
Epoch time: 82s
Epoch: 221  lr: 0.001
Epoch: [221][000/391]	Time 1.3093 Data 1.0881 Loss 0.0148 (0.0148)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [221][100/391]	Time 0.1898 Data 0.0021 Loss 0.0200 (0.0164)	Acc@1 99.219 (99.954)	Acc@5 100.000 (100.000)
Epoch: [221][200/391]	Time 0.1897 Data 0.0019 Loss 0.0161 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [221][300/391]	Time 0.1930 Data 0.0022 Loss 0.0166 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.73, Prec@5: 92.34
Epoch time: 82s
Epoch: 222  lr: 0.001
Epoch: [222][000/391]	Time 1.1536 Data 0.9413 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [222][100/391]	Time 0.1904 Data 0.0020 Loss 0.0140 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [222][200/391]	Time 0.1899 Data 0.0019 Loss 0.0151 (0.0159)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [222][300/391]	Time 0.1896 Data 0.0021 Loss 0.0144 (0.0160)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9657, Prec@1: 75.80, Prec@5: 92.37
Epoch time: 82s
Epoch: 223  lr: 0.001
Epoch: [223][000/391]	Time 1.3770 Data 1.1703 Loss 0.0107 (0.0107)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [223][100/391]	Time 0.1903 Data 0.0021 Loss 0.0188 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [223][200/391]	Time 0.1894 Data 0.0019 Loss 0.0129 (0.0162)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [223][300/391]	Time 0.1895 Data 0.0019 Loss 0.0169 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9622, Prec@1: 75.77, Prec@5: 92.34
Epoch time: 82s
Epoch: 224  lr: 0.001
Epoch: [224][000/391]	Time 1.1844 Data 0.9733 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [224][100/391]	Time 0.1931 Data 0.0031 Loss 0.0190 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [224][200/391]	Time 0.1897 Data 0.0028 Loss 0.0212 (0.0167)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [224][300/391]	Time 0.1894 Data 0.0021 Loss 0.0316 (0.0165)	Acc@1 99.219 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9642, Prec@1: 75.83, Prec@5: 92.46
Epoch time: 82s
Epoch: 225  lr: 0.001
Epoch: [225][000/391]	Time 1.2390 Data 1.1042 Loss 0.0183 (0.0183)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [225][100/391]	Time 0.1891 Data 0.0019 Loss 0.0139 (0.0159)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [225][200/391]	Time 0.1903 Data 0.0022 Loss 0.0131 (0.0158)	Acc@1 100.000 (99.988)	Acc@5 100.000 (100.000)
Epoch: [225][300/391]	Time 0.1901 Data 0.0021 Loss 0.0120 (0.0159)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9670, Prec@1: 75.62, Prec@5: 92.34
Epoch time: 82s
Epoch: 226  lr: 0.001
Epoch: [226][000/391]	Time 1.1476 Data 0.9919 Loss 0.0148 (0.0148)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [226][100/391]	Time 0.1892 Data 0.0022 Loss 0.0176 (0.0159)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [226][200/391]	Time 0.1895 Data 0.0020 Loss 0.0132 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [226][300/391]	Time 0.1932 Data 0.0023 Loss 0.0139 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9637, Prec@1: 75.69, Prec@5: 92.42
Epoch time: 82s
Epoch: 227  lr: 0.001
Epoch: [227][000/391]	Time 1.1309 Data 0.9032 Loss 0.0136 (0.0136)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [227][100/391]	Time 0.1931 Data 0.0022 Loss 0.0143 (0.0155)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [227][200/391]	Time 0.1894 Data 0.0020 Loss 0.0143 (0.0162)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [227][300/391]	Time 0.1905 Data 0.0021 Loss 0.0183 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9650, Prec@1: 75.75, Prec@5: 92.38
Epoch time: 82s
Epoch: 228  lr: 0.001
Epoch: [228][000/391]	Time 1.2708 Data 1.0530 Loss 0.0126 (0.0126)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [228][100/391]	Time 0.1895 Data 0.0020 Loss 0.0112 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [228][200/391]	Time 0.1895 Data 0.0019 Loss 0.0133 (0.0161)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [228][300/391]	Time 0.1895 Data 0.0025 Loss 0.0237 (0.0163)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9635, Prec@1: 75.70, Prec@5: 92.42
Epoch time: 82s
Epoch: 229  lr: 0.001
Epoch: [229][000/391]	Time 1.4144 Data 1.2151 Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [229][100/391]	Time 0.1899 Data 0.0020 Loss 0.0137 (0.0158)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [229][200/391]	Time 0.1927 Data 0.0024 Loss 0.0141 (0.0159)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [229][300/391]	Time 0.1899 Data 0.0020 Loss 0.0130 (0.0162)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9643, Prec@1: 75.69, Prec@5: 92.32
Epoch time: 82s
Epoch: 230  lr: 0.001
Epoch: [230][000/391]	Time 1.4445 Data 1.2826 Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [230][100/391]	Time 0.1925 Data 0.0025 Loss 0.0126 (0.0160)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [230][200/391]	Time 0.1930 Data 0.0019 Loss 0.0165 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [230][300/391]	Time 0.1901 Data 0.0019 Loss 0.0112 (0.0160)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9626, Prec@1: 75.70, Prec@5: 92.43
Epoch time: 82s
Epoch: 231  lr: 0.001
Epoch: [231][000/391]	Time 1.4496 Data 1.2390 Loss 0.0208 (0.0208)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [231][100/391]	Time 0.1903 Data 0.0023 Loss 0.0223 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [231][200/391]	Time 0.1901 Data 0.0021 Loss 0.0113 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [231][300/391]	Time 0.1909 Data 0.0020 Loss 0.0178 (0.0158)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9647, Prec@1: 75.70, Prec@5: 92.43
Epoch time: 83s
Epoch: 232  lr: 0.001
Epoch: [232][000/391]	Time 1.4077 Data 1.2073 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [232][100/391]	Time 0.1901 Data 0.0019 Loss 0.0191 (0.0165)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [232][200/391]	Time 0.1896 Data 0.0019 Loss 0.0187 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [232][300/391]	Time 0.1895 Data 0.0019 Loss 0.0228 (0.0163)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9616, Prec@1: 75.79, Prec@5: 92.44
Epoch time: 82s
Epoch: 233  lr: 0.001
Epoch: [233][000/391]	Time 1.3606 Data 1.1469 Loss 0.0135 (0.0135)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [233][100/391]	Time 0.1899 Data 0.0019 Loss 0.0161 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [233][200/391]	Time 0.1897 Data 0.0020 Loss 0.0164 (0.0164)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [233][300/391]	Time 0.1896 Data 0.0020 Loss 0.0157 (0.0161)	Acc@1 100.000 (99.987)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9655, Prec@1: 75.64, Prec@5: 92.31
Epoch time: 82s
Epoch: 234  lr: 0.001
Epoch: [234][000/391]	Time 1.3858 Data 1.1646 Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [234][100/391]	Time 0.1896 Data 0.0021 Loss 0.0123 (0.0163)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [234][200/391]	Time 0.1899 Data 0.0020 Loss 0.0118 (0.0160)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [234][300/391]	Time 0.1911 Data 0.0020 Loss 0.0151 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9622, Prec@1: 75.83, Prec@5: 92.44
Epoch time: 82s
Epoch: 235  lr: 0.001
Epoch: [235][000/391]	Time 1.3098 Data 1.1108 Loss 0.0152 (0.0152)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [235][100/391]	Time 0.1897 Data 0.0020 Loss 0.0172 (0.0159)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [235][200/391]	Time 0.1901 Data 0.0020 Loss 0.0139 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [235][300/391]	Time 0.1902 Data 0.0020 Loss 0.0171 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9679, Prec@1: 75.67, Prec@5: 92.25
Epoch time: 82s
Epoch: 236  lr: 0.001
Epoch: [236][000/391]	Time 1.2051 Data 0.9976 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [236][100/391]	Time 0.1916 Data 0.0025 Loss 0.0170 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [236][200/391]	Time 0.1905 Data 0.0029 Loss 0.0154 (0.0164)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [236][300/391]	Time 0.1922 Data 0.0020 Loss 0.0112 (0.0165)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9621, Prec@1: 75.76, Prec@5: 92.37
Epoch time: 82s
Epoch: 237  lr: 0.001
Epoch: [237][000/391]	Time 1.2318 Data 1.0104 Loss 0.0124 (0.0124)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [237][100/391]	Time 0.1899 Data 0.0020 Loss 0.0199 (0.0159)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [237][200/391]	Time 0.1897 Data 0.0020 Loss 0.0119 (0.0161)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [237][300/391]	Time 0.1895 Data 0.0020 Loss 0.0143 (0.0161)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9633, Prec@1: 75.66, Prec@5: 92.45
Epoch time: 82s
Epoch: 238  lr: 0.001
Epoch: [238][000/391]	Time 1.3657 Data 1.1585 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [238][100/391]	Time 0.1890 Data 0.0021 Loss 0.0126 (0.0156)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [238][200/391]	Time 0.1898 Data 0.0024 Loss 0.0124 (0.0158)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [238][300/391]	Time 0.1888 Data 0.0020 Loss 0.0160 (0.0158)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9623, Prec@1: 75.80, Prec@5: 92.43
Epoch time: 82s
Epoch: 239  lr: 0.001
Epoch: [239][000/391]	Time 1.4332 Data 1.1728 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [239][100/391]	Time 0.1900 Data 0.0029 Loss 0.0143 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [239][200/391]	Time 0.1931 Data 0.0020 Loss 0.0162 (0.0166)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [239][300/391]	Time 0.1914 Data 0.0024 Loss 0.0182 (0.0165)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9647, Prec@1: 75.65, Prec@5: 92.47
Epoch time: 82s
Epoch: 240  lr: 0.001
Epoch: [240][000/391]	Time 1.3430 Data 1.1257 Loss 0.0119 (0.0119)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [240][100/391]	Time 0.1897 Data 0.0022 Loss 0.0166 (0.0162)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [240][200/391]	Time 0.1903 Data 0.0021 Loss 0.0166 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [240][300/391]	Time 0.1916 Data 0.0022 Loss 0.0152 (0.0161)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9636, Prec@1: 75.89, Prec@5: 92.27
Epoch time: 82s

opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=0.9, distill='kd', epochs=110, lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=0.9, distill='kd', epochs=110, lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
Epoch: [1][000/391]	Time 2.5562 Data 0.9386 Loss 4.8249 (4.8249)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)
Epoch: [1][100/391]	Time 0.1875 Data 0.0020 Loss 4.5536 (5.3927)	Acc@1 3.906 (1.245)	Acc@5 9.375 (6.119)
Epoch: [1][200/391]	Time 0.1908 Data 0.0021 Loss 4.5850 (5.0354)	Acc@1 0.000 (1.403)	Acc@5 4.688 (6.456)
Epoch: [1][300/391]	Time 0.1892 Data 0.0023 Loss 4.5119 (4.9024)	Acc@1 4.688 (1.570)	Acc@5 10.156 (6.870)
Testing the models......
Loss: 4.4853, Prec@1: 2.78, Prec@5: 12.21
Epoch time: 84s
Saving models
Epoch: 2  lr: 0.100
Epoch: [2][000/391]	Time 1.2082 Data 1.0136 Loss 4.5971 (4.5971)	Acc@1 0.781 (0.781)	Acc@5 7.031 (7.031)
Epoch: [2][100/391]	Time 0.1891 Data 0.0021 Loss 4.3858 (4.5230)	Acc@1 7.812 (2.939)	Acc@5 21.094 (12.840)
Epoch: [2][200/391]	Time 0.1892 Data 0.0020 Loss 4.4315 (4.4984)	Acc@1 5.469 (3.335)	Acc@5 13.281 (14.249)
Epoch: [2][300/391]	Time 0.1903 Data 0.0019 Loss 4.1823 (4.4493)	Acc@1 5.469 (3.449)	Acc@5 19.531 (15.103)
Testing the models......
Loss: 4.4568, Prec@1: 4.50, Prec@5: 19.41
Epoch time: 82s
Saving models
Epoch: 3  lr: 0.100
Epoch: [3][000/391]	Time 1.2434 Data 0.9786 Loss 4.1736 (4.1736)	Acc@1 4.688 (4.688)	Acc@5 14.844 (14.844)
Epoch: [3][100/391]	Time 0.1916 Data 0.0023 Loss 4.2283 (4.3241)	Acc@1 7.031 (5.229)	Acc@5 18.750 (20.568)
Epoch: [3][200/391]	Time 0.1898 Data 0.0021 Loss 4.1363 (4.2985)	Acc@1 4.688 (5.667)	Acc@5 18.750 (21.572)
Epoch: [3][300/391]	Time 0.1891 Data 0.0020 Loss 3.9449 (4.2747)	Acc@1 10.156 (6.281)	Acc@5 27.344 (22.918)
Testing the models......
Loss: 4.2938, Prec@1: 8.79, Prec@5: 28.58
Epoch time: 82s
Saving models
Epoch: 4  lr: 0.100
Epoch: [4][000/391]	Time 1.1452 Data 0.9082 Loss 3.9279 (3.9279)	Acc@1 9.375 (9.375)	Acc@5 25.781 (25.781)
Epoch: [4][100/391]	Time 0.1915 Data 0.0021 Loss 3.9741 (4.0573)	Acc@1 9.375 (8.447)	Acc@5 32.031 (28.852)
Epoch: [4][200/391]	Time 0.1940 Data 0.0020 Loss 3.9139 (4.0863)	Acc@1 17.188 (8.862)	Acc@5 34.375 (29.182)
Epoch: [4][300/391]	Time 0.1902 Data 0.0020 Loss 3.6968 (4.0697)	Acc@1 14.062 (9.287)	Acc@5 39.844 (29.960)
Testing the models......
Loss: 3.7449, Prec@1: 12.46, Prec@5: 36.66
Epoch time: 82s
Saving models
Epoch: 5  lr: 0.100
Epoch: [5][000/391]	Time 1.1157 Data 0.9242 Loss 4.3421 (4.3421)	Acc@1 14.062 (14.062)	Acc@5 34.375 (34.375)
Epoch: [5][100/391]	Time 0.1918 Data 0.0020 Loss 3.7426 (3.8675)	Acc@1 14.844 (12.353)	Acc@5 37.500 (36.448)
Epoch: [5][200/391]	Time 0.1910 Data 0.0020 Loss 3.6450 (3.8394)	Acc@1 15.625 (13.188)	Acc@5 45.312 (37.586)
Epoch: [5][300/391]	Time 0.1900 Data 0.0020 Loss 3.7146 (3.8160)	Acc@1 17.188 (13.798)	Acc@5 43.750 (38.463)
Testing the models......
Loss: 3.7398, Prec@1: 18.49, Prec@5: 44.21
Epoch time: 82s
Saving models
Epoch: 6  lr: 0.100
Epoch: [6][000/391]	Time 1.1061 Data 0.8868 Loss 3.6488 (3.6488)	Acc@1 15.625 (15.625)	Acc@5 46.875 (46.875)
Epoch: [6][100/391]	Time 0.1917 Data 0.0021 Loss 3.4241 (3.5642)	Acc@1 19.531 (17.559)	Acc@5 53.125 (45.011)
Epoch: [6][200/391]	Time 0.1903 Data 0.0021 Loss 3.2961 (3.5347)	Acc@1 21.094 (18.093)	Acc@5 52.344 (45.892)
Epoch: [6][300/391]	Time 0.1952 Data 0.0020 Loss 3.2923 (3.4917)	Acc@1 25.000 (18.916)	Acc@5 46.094 (47.062)
Testing the models......
Loss: 3.3480, Prec@1: 24.29, Prec@5: 52.18
Epoch time: 82s
Saving models
Epoch: 7  lr: 0.100
Epoch: [7][000/391]	Time 1.2371 Data 1.0060 Loss 3.1478 (3.1478)	Acc@1 25.781 (25.781)	Acc@5 51.562 (51.562)
Epoch: [7][100/391]	Time 0.1917 Data 0.0021 Loss 3.3030 (3.2740)	Acc@1 21.094 (22.540)	Acc@5 52.344 (51.679)
Epoch: [7][200/391]	Time 0.1894 Data 0.0020 Loss 3.1127 (3.2489)	Acc@1 28.125 (23.224)	Acc@5 54.688 (52.433)
Epoch: [7][300/391]	Time 0.1886 Data 0.0020 Loss 2.9185 (3.2102)	Acc@1 35.156 (24.001)	Acc@5 61.719 (53.532)
Testing the models......
Loss: 3.0810, Prec@1: 27.56, Prec@5: 57.28
Epoch time: 82s
Saving models
Epoch: 8  lr: 0.100
Epoch: [8][000/391]	Time 1.2089 Data 0.9474 Loss 2.9806 (2.9806)	Acc@1 25.000 (25.000)	Acc@5 57.812 (57.812)
Epoch: [8][100/391]	Time 0.1924 Data 0.0026 Loss 3.1536 (3.0049)	Acc@1 28.906 (27.916)	Acc@5 56.250 (58.493)
Epoch: [8][200/391]	Time 0.1902 Data 0.0020 Loss 2.9064 (2.9790)	Acc@1 34.375 (28.113)	Acc@5 60.156 (58.986)
Epoch: [8][300/391]	Time 0.1919 Data 0.0021 Loss 2.8070 (2.9583)	Acc@1 23.438 (28.577)	Acc@5 59.375 (59.567)
Testing the models......
Loss: 2.9762, Prec@1: 30.78, Prec@5: 62.45
Epoch time: 82s
Saving models
Epoch: 9  lr: 0.100
Epoch: [9][000/391]	Time 1.1252 Data 0.9171 Loss 2.9863 (2.9863)	Acc@1 32.812 (32.812)	Acc@5 65.625 (65.625)
Epoch: [9][100/391]	Time 0.1902 Data 0.0021 Loss 2.3308 (2.7151)	Acc@1 40.625 (33.424)	Acc@5 70.312 (64.712)
Epoch: [9][200/391]	Time 0.1897 Data 0.0019 Loss 2.5789 (2.7014)	Acc@1 35.938 (33.275)	Acc@5 64.844 (64.852)
Epoch: [9][300/391]	Time 0.1900 Data 0.0020 Loss 2.3658 (2.6793)	Acc@1 38.281 (33.708)	Acc@5 69.531 (65.241)
Testing the models......
Loss: 2.4711, Prec@1: 37.47, Prec@5: 68.53
Epoch time: 82s
Saving models
Epoch: 10  lr: 0.100
Epoch: [10][000/391]	Time 1.1706 Data 0.9468 Loss 2.4037 (2.4037)	Acc@1 39.844 (39.844)	Acc@5 71.094 (71.094)
Epoch: [10][100/391]	Time 0.1891 Data 0.0021 Loss 2.1090 (2.4513)	Acc@1 42.969 (37.314)	Acc@5 77.344 (69.756)
Epoch: [10][200/391]	Time 0.1898 Data 0.0021 Loss 2.4344 (2.4282)	Acc@1 39.062 (37.632)	Acc@5 70.312 (69.640)
Epoch: [10][300/391]	Time 0.1894 Data 0.0020 Loss 2.3583 (2.4001)	Acc@1 37.500 (38.219)	Acc@5 70.312 (70.089)
Testing the models......
Loss: 2.3584, Prec@1: 38.31, Prec@5: 71.63
Epoch time: 82s
Saving models
Epoch: 11  lr: 0.100
Epoch: [11][000/391]	Time 1.2239 Data 0.9963 Loss 2.0193 (2.0193)	Acc@1 42.969 (42.969)	Acc@5 78.906 (78.906)
Epoch: [11][100/391]	Time 0.1917 Data 0.0020 Loss 2.5246 (2.1669)	Acc@1 32.031 (42.342)	Acc@5 70.312 (74.660)
Epoch: [11][200/391]	Time 0.1933 Data 0.0024 Loss 1.9572 (2.1622)	Acc@1 51.562 (42.417)	Acc@5 82.031 (74.732)
Epoch: [11][300/391]	Time 0.1892 Data 0.0019 Loss 2.1849 (2.1592)	Acc@1 44.531 (42.496)	Acc@5 76.562 (74.663)
Testing the models......
Loss: 2.1026, Prec@1: 43.60, Prec@5: 75.51
Epoch time: 82s
Saving models
Epoch: 12  lr: 0.100
Epoch: [12][000/391]	Time 1.1424 Data 0.9176 Loss 2.0185 (2.0185)	Acc@1 46.875 (46.875)	Acc@5 79.688 (79.688)
Epoch: [12][100/391]	Time 0.1896 Data 0.0020 Loss 2.1141 (1.9886)	Acc@1 39.844 (46.457)	Acc@5 73.438 (77.452)
Epoch: [12][200/391]	Time 0.1898 Data 0.0021 Loss 1.9494 (1.9876)	Acc@1 45.312 (46.210)	Acc@5 77.344 (77.919)
Epoch: [12][300/391]	Time 0.1896 Data 0.0019 Loss 1.9888 (1.9717)	Acc@1 46.094 (46.693)	Acc@5 75.000 (78.304)
Testing the models......
Loss: 2.2015, Prec@1: 43.17, Prec@5: 75.78
Epoch time: 82s
Epoch: 13  lr: 0.100
Epoch: [13][000/391]	Time 1.1849 Data 0.9910 Loss 2.0423 (2.0423)	Acc@1 44.531 (44.531)	Acc@5 73.438 (73.438)
Epoch: [13][100/391]	Time 0.1900 Data 0.0021 Loss 2.1649 (1.8359)	Acc@1 40.625 (50.286)	Acc@5 73.438 (80.213)
Epoch: [13][200/391]	Time 0.1905 Data 0.0019 Loss 1.5956 (1.8206)	Acc@1 54.688 (50.132)	Acc@5 86.719 (80.822)
Epoch: [13][300/391]	Time 0.1943 Data 0.0020 Loss 2.0391 (1.8178)	Acc@1 40.625 (50.138)	Acc@5 73.438 (80.944)
Testing the models......
Loss: 1.9694, Prec@1: 48.01, Prec@5: 79.10
Epoch time: 82s
Saving models
Epoch: 14  lr: 0.100
Epoch: [14][000/391]	Time 1.1704 Data 0.9332 Loss 1.7035 (1.7035)	Acc@1 52.344 (52.344)	Acc@5 79.688 (79.688)
Epoch: [14][100/391]	Time 0.1901 Data 0.0020 Loss 1.7081 (1.6693)	Acc@1 51.562 (53.465)	Acc@5 80.469 (83.594)
Epoch: [14][200/391]	Time 0.1902 Data 0.0020 Loss 1.6770 (1.6898)	Acc@1 52.344 (53.098)	Acc@5 82.812 (83.209)
Epoch: [14][300/391]	Time 0.1893 Data 0.0020 Loss 1.6219 (1.6853)	Acc@1 57.031 (53.247)	Acc@5 81.250 (83.272)
Testing the models......
Loss: 1.8072, Prec@1: 52.06, Prec@5: 80.91
Epoch time: 82s
Saving models
Epoch: 15  lr: 0.100
Epoch: [15][000/391]	Time 1.2178 Data 1.0235 Loss 1.5832 (1.5832)	Acc@1 58.594 (58.594)	Acc@5 84.375 (84.375)
Epoch: [15][100/391]	Time 0.1915 Data 0.0020 Loss 1.4266 (1.5440)	Acc@1 60.156 (56.993)	Acc@5 89.844 (85.636)
Epoch: [15][200/391]	Time 0.1892 Data 0.0019 Loss 1.5410 (1.5600)	Acc@1 59.375 (56.367)	Acc@5 85.938 (85.463)
Epoch: [15][300/391]	Time 0.1896 Data 0.0020 Loss 2.1059 (1.5634)	Acc@1 45.312 (56.234)	Acc@5 78.906 (85.359)
Testing the models......
Loss: 1.7166, Prec@1: 53.24, Prec@5: 83.43
Epoch time: 82s
Saving models
Epoch: 16  lr: 0.100
Epoch: [16][000/391]	Time 1.1588 Data 0.9179 Loss 1.3572 (1.3572)	Acc@1 64.844 (64.844)	Acc@5 85.938 (85.938)
Epoch: [16][100/391]	Time 0.1896 Data 0.0021 Loss 1.4745 (1.4377)	Acc@1 60.156 (58.710)	Acc@5 91.406 (87.585)
Epoch: [16][200/391]	Time 0.1896 Data 0.0021 Loss 1.4034 (1.4509)	Acc@1 59.375 (58.796)	Acc@5 90.625 (87.228)
Epoch: [16][300/391]	Time 0.1899 Data 0.0025 Loss 1.3852 (1.4562)	Acc@1 60.938 (58.703)	Acc@5 89.062 (87.020)
Testing the models......
Loss: 1.8011, Prec@1: 52.59, Prec@5: 81.97
Epoch time: 82s
Epoch: 17  lr: 0.100
Epoch: [17][000/391]	Time 1.1307 Data 0.9125 Loss 1.3015 (1.3015)	Acc@1 60.156 (60.156)	Acc@5 92.969 (92.969)
Epoch: [17][100/391]	Time 0.1897 Data 0.0020 Loss 1.3546 (1.3610)	Acc@1 64.844 (60.868)	Acc@5 88.281 (88.451)
Epoch: [17][200/391]	Time 0.1893 Data 0.0020 Loss 1.5204 (1.3755)	Acc@1 48.438 (60.440)	Acc@5 86.719 (88.421)
Epoch: [17][300/391]	Time 0.1905 Data 0.0020 Loss 1.5329 (1.3842)	Acc@1 54.688 (60.416)	Acc@5 86.719 (88.219)
Testing the models......
Loss: 1.6712, Prec@1: 54.62, Prec@5: 83.29
Epoch time: 82s
Saving models
Epoch: 18  lr: 0.100
Epoch: [18][000/391]	Time 1.1742 Data 1.0060 Loss 1.1707 (1.1707)	Acc@1 66.406 (66.406)	Acc@5 89.062 (89.062)
Epoch: [18][100/391]	Time 0.1891 Data 0.0020 Loss 1.1617 (1.2799)	Acc@1 66.406 (62.995)	Acc@5 90.625 (89.442)
Epoch: [18][200/391]	Time 0.1905 Data 0.0021 Loss 1.4174 (1.2937)	Acc@1 58.594 (62.551)	Acc@5 91.406 (89.315)
Epoch: [18][300/391]	Time 0.1902 Data 0.0021 Loss 1.2858 (1.3005)	Acc@1 63.281 (62.396)	Acc@5 88.281 (89.268)
Testing the models......
Loss: 1.6601, Prec@1: 54.94, Prec@5: 83.99
Epoch time: 82s
Saving models
Epoch: 19  lr: 0.100
Epoch: [19][000/391]	Time 1.1493 Data 0.9356 Loss 1.1648 (1.1648)	Acc@1 68.750 (68.750)	Acc@5 92.188 (92.188)
Epoch: [19][100/391]	Time 0.1959 Data 0.0020 Loss 1.1471 (1.2018)	Acc@1 64.844 (65.408)	Acc@5 89.844 (90.857)
Epoch: [19][200/391]	Time 0.1911 Data 0.0021 Loss 1.4211 (1.2232)	Acc@1 60.156 (64.618)	Acc@5 88.281 (90.559)
Epoch: [19][300/391]	Time 0.1903 Data 0.0020 Loss 1.2063 (1.2356)	Acc@1 63.281 (64.364)	Acc@5 91.406 (90.314)
Testing the models......
Loss: 1.5915, Prec@1: 56.75, Prec@5: 85.19
Epoch time: 82s
Saving models
Epoch: 20  lr: 0.100
Epoch: [20][000/391]	Time 1.2154 Data 0.9844 Loss 1.2494 (1.2494)	Acc@1 62.500 (62.500)	Acc@5 92.969 (92.969)
Epoch: [20][100/391]	Time 0.1890 Data 0.0019 Loss 1.1389 (1.1398)	Acc@1 67.969 (66.298)	Acc@5 89.062 (92.002)
Epoch: [20][200/391]	Time 0.1889 Data 0.0020 Loss 1.1645 (1.1388)	Acc@1 66.406 (66.562)	Acc@5 94.531 (91.807)
Epoch: [20][300/391]	Time 0.1893 Data 0.0021 Loss 1.3139 (1.1547)	Acc@1 62.500 (65.978)	Acc@5 88.281 (91.593)
Testing the models......
Loss: 1.5007, Prec@1: 58.97, Prec@5: 86.36
Epoch time: 82s
Saving models
Epoch: 21  lr: 0.100
Epoch: [21][000/391]	Time 1.1888 Data 0.9985 Loss 0.9199 (0.9199)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Epoch: [21][100/391]	Time 0.1895 Data 0.0025 Loss 0.9138 (1.0661)	Acc@1 71.094 (68.820)	Acc@5 93.750 (92.505)
Epoch: [21][200/391]	Time 0.1894 Data 0.0022 Loss 1.1443 (1.0958)	Acc@1 67.188 (67.910)	Acc@5 90.625 (92.125)
Epoch: [21][300/391]	Time 0.1900 Data 0.0021 Loss 1.0418 (1.1052)	Acc@1 71.875 (67.631)	Acc@5 96.094 (92.091)
Testing the models......
Loss: 1.5785, Prec@1: 59.18, Prec@5: 85.39
Epoch time: 81s
Saving models
Epoch: 22  lr: 0.100
Epoch: [22][000/391]	Time 1.2140 Data 1.0382 Loss 1.1420 (1.1420)	Acc@1 67.969 (67.969)	Acc@5 93.750 (93.750)
Epoch: [22][100/391]	Time 0.1893 Data 0.0021 Loss 0.9389 (1.0080)	Acc@1 69.531 (69.872)	Acc@5 93.750 (93.147)
Epoch: [22][200/391]	Time 0.1910 Data 0.0022 Loss 1.1151 (1.0299)	Acc@1 63.281 (69.290)	Acc@5 91.406 (93.031)
Epoch: [22][300/391]	Time 0.1894 Data 0.0032 Loss 1.1529 (1.0458)	Acc@1 67.969 (69.023)	Acc@5 89.062 (92.784)
Testing the models......
Loss: 1.5164, Prec@1: 59.24, Prec@5: 86.56
Epoch time: 81s
Saving models
Epoch: 23  lr: 0.100
Epoch: [23][000/391]	Time 1.1607 Data 0.9288 Loss 0.8844 (0.8844)	Acc@1 75.000 (75.000)	Acc@5 95.312 (95.312)
Epoch: [23][100/391]	Time 0.1891 Data 0.0021 Loss 0.9403 (0.9525)	Acc@1 67.969 (71.720)	Acc@5 93.750 (94.129)
Epoch: [23][200/391]	Time 0.1890 Data 0.0020 Loss 1.0487 (0.9791)	Acc@1 67.188 (70.868)	Acc@5 92.969 (93.731)
Epoch: [23][300/391]	Time 0.1903 Data 0.0021 Loss 1.1976 (1.0055)	Acc@1 57.812 (70.001)	Acc@5 95.312 (93.363)
Testing the models......
Loss: 1.5150, Prec@1: 59.67, Prec@5: 86.92
Epoch time: 81s
Saving models
Epoch: 24  lr: 0.100
Epoch: [24][000/391]	Time 1.1882 Data 0.9223 Loss 0.8598 (0.8598)	Acc@1 71.094 (71.094)	Acc@5 92.188 (92.188)
Epoch: [24][100/391]	Time 0.1885 Data 0.0020 Loss 1.1007 (0.8872)	Acc@1 66.406 (73.244)	Acc@5 92.969 (94.524)
Epoch: [24][200/391]	Time 0.1894 Data 0.0020 Loss 0.9807 (0.9226)	Acc@1 70.312 (72.474)	Acc@5 92.969 (94.251)
Epoch: [24][300/391]	Time 0.1892 Data 0.0026 Loss 0.7977 (0.9453)	Acc@1 74.219 (71.714)	Acc@5 96.094 (94.093)
Testing the models......
Loss: 1.4994, Prec@1: 60.13, Prec@5: 86.72
Epoch time: 81s
Saving models
Epoch: 25  lr: 0.100
Epoch: [25][000/391]	Time 1.1513 Data 0.9315 Loss 0.7566 (0.7566)	Acc@1 76.562 (76.562)	Acc@5 94.531 (94.531)
Epoch: [25][100/391]	Time 0.1908 Data 0.0019 Loss 0.7802 (0.8513)	Acc@1 78.125 (74.575)	Acc@5 94.531 (95.181)
Epoch: [25][200/391]	Time 0.1906 Data 0.0022 Loss 1.1311 (0.8896)	Acc@1 70.312 (73.554)	Acc@5 89.062 (94.586)
Epoch: [25][300/391]	Time 0.1891 Data 0.0020 Loss 0.6689 (0.8992)	Acc@1 79.688 (73.048)	Acc@5 96.875 (94.570)
Testing the models......
Loss: 1.4828, Prec@1: 60.83, Prec@5: 87.71
Epoch time: 81s
Saving models
Epoch: 26  lr: 0.100
Epoch: [26][000/391]	Time 1.2085 Data 1.0084 Loss 0.9025 (0.9025)	Acc@1 69.531 (69.531)	Acc@5 96.875 (96.875)
Epoch: [26][100/391]	Time 0.1887 Data 0.0020 Loss 0.8751 (0.8144)	Acc@1 71.875 (75.565)	Acc@5 94.531 (95.653)
Epoch: [26][200/391]	Time 0.1903 Data 0.0026 Loss 1.1411 (0.8508)	Acc@1 64.844 (74.347)	Acc@5 94.531 (95.192)
Epoch: [26][300/391]	Time 0.1915 Data 0.0021 Loss 1.0016 (0.8676)	Acc@1 73.438 (73.757)	Acc@5 92.969 (95.014)
Testing the models......
Loss: 1.3915, Prec@1: 63.01, Prec@5: 88.48
Epoch time: 81s
Saving models
Epoch: 27  lr: 0.100
Epoch: [27][000/391]	Time 1.2269 Data 1.0639 Loss 0.6764 (0.6764)	Acc@1 78.906 (78.906)	Acc@5 97.656 (97.656)
Epoch: [27][100/391]	Time 0.1892 Data 0.0021 Loss 0.8150 (0.7705)	Acc@1 75.000 (76.779)	Acc@5 93.750 (96.187)
Epoch: [27][200/391]	Time 0.1892 Data 0.0020 Loss 0.7647 (0.8012)	Acc@1 78.125 (75.812)	Acc@5 95.312 (95.744)
Epoch: [27][300/391]	Time 0.1890 Data 0.0020 Loss 0.6922 (0.8246)	Acc@1 78.125 (75.080)	Acc@5 96.875 (95.460)
Testing the models......
Loss: 1.4980, Prec@1: 61.27, Prec@5: 87.10
Epoch time: 81s
Epoch: 28  lr: 0.100
Epoch: [28][000/391]	Time 1.1340 Data 0.9167 Loss 0.7889 (0.7889)	Acc@1 79.688 (79.688)	Acc@5 95.312 (95.312)
Epoch: [28][100/391]	Time 0.1904 Data 0.0026 Loss 0.5942 (0.7339)	Acc@1 82.812 (77.189)	Acc@5 98.438 (96.504)
Epoch: [28][200/391]	Time 0.1898 Data 0.0021 Loss 0.8703 (0.7722)	Acc@1 71.875 (76.201)	Acc@5 94.531 (95.876)
Epoch: [28][300/391]	Time 0.1897 Data 0.0026 Loss 0.8966 (0.7945)	Acc@1 76.562 (75.568)	Acc@5 94.531 (95.730)
Testing the models......
Loss: 1.5044, Prec@1: 60.74, Prec@5: 87.19
Epoch time: 82s
Epoch: 29  lr: 0.100
Epoch: [29][000/391]	Time 1.1047 Data 0.9136 Loss 0.6928 (0.6928)	Acc@1 73.438 (73.438)	Acc@5 99.219 (99.219)
Epoch: [29][100/391]	Time 0.1939 Data 0.0022 Loss 0.8504 (0.7103)	Acc@1 73.438 (77.661)	Acc@5 96.094 (96.805)
Epoch: [29][200/391]	Time 0.1899 Data 0.0022 Loss 0.7370 (0.7325)	Acc@1 75.781 (77.083)	Acc@5 97.656 (96.587)
Epoch: [29][300/391]	Time 0.1924 Data 0.0021 Loss 0.8390 (0.7577)	Acc@1 75.000 (76.521)	Acc@5 92.188 (96.327)
Testing the models......
Loss: 1.5746, Prec@1: 60.13, Prec@5: 86.71
Epoch time: 82s
Epoch: 30  lr: 0.100
Epoch: [30][000/391]	Time 1.1705 Data 0.9075 Loss 0.7426 (0.7426)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
Epoch: [30][100/391]	Time 0.1895 Data 0.0019 Loss 0.6375 (0.6815)	Acc@1 83.594 (79.394)	Acc@5 97.656 (97.030)
Epoch: [30][200/391]	Time 0.1893 Data 0.0021 Loss 0.7696 (0.7088)	Acc@1 74.219 (78.203)	Acc@5 95.312 (96.856)
Epoch: [30][300/391]	Time 0.1934 Data 0.0022 Loss 0.6097 (0.7297)	Acc@1 82.812 (77.562)	Acc@5 98.438 (96.654)
Testing the models......
Loss: 1.4449, Prec@1: 62.86, Prec@5: 88.06
Epoch time: 82s
Epoch: 31  lr: 0.100
Epoch: [31][000/391]	Time 1.1845 Data 0.9949 Loss 0.6646 (0.6646)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [31][100/391]	Time 0.1919 Data 0.0023 Loss 0.8476 (0.6473)	Acc@1 73.438 (80.244)	Acc@5 95.312 (96.999)
Epoch: [31][200/391]	Time 0.1907 Data 0.0021 Loss 0.5904 (0.6744)	Acc@1 82.031 (79.116)	Acc@5 98.438 (96.879)
Epoch: [31][300/391]	Time 0.1905 Data 0.0022 Loss 0.7009 (0.6943)	Acc@1 75.781 (78.530)	Acc@5 98.438 (96.717)
Testing the models......
Loss: 1.4854, Prec@1: 62.65, Prec@5: 87.42
Epoch time: 82s
Epoch: 32  lr: 0.100
Epoch: [32][000/391]	Time 1.2513 Data 1.0867 Loss 0.7118 (0.7118)	Acc@1 78.906 (78.906)	Acc@5 95.312 (95.312)
Epoch: [32][100/391]	Time 0.1900 Data 0.0021 Loss 0.6792 (0.6226)	Acc@1 82.031 (80.670)	Acc@5 98.438 (97.401)
Epoch: [32][200/391]	Time 0.1897 Data 0.0022 Loss 0.5376 (0.6529)	Acc@1 83.594 (79.746)	Acc@5 98.438 (97.186)
Epoch: [32][300/391]	Time 0.1904 Data 0.0022 Loss 0.6544 (0.6691)	Acc@1 77.344 (79.161)	Acc@5 97.656 (97.116)
Testing the models......
Loss: 1.5613, Prec@1: 61.52, Prec@5: 87.03
Epoch time: 82s
Epoch: 33  lr: 0.100
Epoch: [33][000/391]	Time 1.1858 Data 0.9807 Loss 0.5506 (0.5506)	Acc@1 82.031 (82.031)	Acc@5 98.438 (98.438)
Epoch: [33][100/391]	Time 0.1903 Data 0.0025 Loss 0.5754 (0.6218)	Acc@1 80.469 (80.840)	Acc@5 99.219 (97.123)
Epoch: [33][200/391]	Time 0.1903 Data 0.0023 Loss 0.7343 (0.6392)	Acc@1 73.438 (80.057)	Acc@5 96.875 (97.182)
Epoch: [33][300/391]	Time 0.1951 Data 0.0029 Loss 0.6869 (0.6598)	Acc@1 77.344 (79.527)	Acc@5 96.875 (97.114)
Testing the models......
Loss: 1.4755, Prec@1: 63.20, Prec@5: 87.71
Epoch time: 82s
Saving models
Epoch: 34  lr: 0.100
Epoch: [34][000/391]	Time 1.2141 Data 0.9838 Loss 0.5360 (0.5360)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [34][100/391]	Time 0.1892 Data 0.0021 Loss 0.7132 (0.5803)	Acc@1 76.562 (81.838)	Acc@5 96.094 (97.873)
Epoch: [34][200/391]	Time 0.1893 Data 0.0021 Loss 0.7672 (0.6039)	Acc@1 78.125 (81.161)	Acc@5 92.969 (97.524)
Epoch: [34][300/391]	Time 0.1900 Data 0.0021 Loss 0.7887 (0.6252)	Acc@1 74.219 (80.528)	Acc@5 96.094 (97.371)
Testing the models......
Loss: 1.4398, Prec@1: 63.81, Prec@5: 88.70
Epoch time: 82s
Saving models
Epoch: 35  lr: 0.100
Epoch: [35][000/391]	Time 1.1607 Data 0.9304 Loss 0.5125 (0.5125)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [35][100/391]	Time 0.1891 Data 0.0019 Loss 0.5261 (0.5428)	Acc@1 82.031 (82.890)	Acc@5 97.656 (98.028)
Epoch: [35][200/391]	Time 0.1913 Data 0.0020 Loss 0.6747 (0.5657)	Acc@1 77.344 (82.377)	Acc@5 97.656 (97.901)
Epoch: [35][300/391]	Time 0.1891 Data 0.0020 Loss 0.8247 (0.5889)	Acc@1 75.000 (81.660)	Acc@5 97.656 (97.716)
Testing the models......
Loss: 1.4831, Prec@1: 63.71, Prec@5: 87.77
Epoch time: 82s
Epoch: 36  lr: 0.100
Epoch: [36][000/391]	Time 1.1873 Data 0.9843 Loss 0.4558 (0.4558)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)
Epoch: [36][100/391]	Time 0.1923 Data 0.0021 Loss 0.5575 (0.5390)	Acc@1 79.688 (82.913)	Acc@5 99.219 (98.066)
Epoch: [36][200/391]	Time 0.1898 Data 0.0020 Loss 0.5204 (0.5609)	Acc@1 85.156 (82.299)	Acc@5 97.656 (98.041)
Epoch: [36][300/391]	Time 0.1893 Data 0.0021 Loss 0.6311 (0.5815)	Acc@1 82.031 (81.813)	Acc@5 96.094 (97.786)
Testing the models......
Loss: 1.4920, Prec@1: 63.18, Prec@5: 87.89
Epoch time: 82s
Epoch: 37  lr: 0.100
Epoch: [37][000/391]	Time 1.2401 Data 1.0306 Loss 0.4040 (0.4040)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [37][100/391]	Time 0.1903 Data 0.0022 Loss 0.5388 (0.5123)	Acc@1 83.594 (83.663)	Acc@5 99.219 (98.546)
Epoch: [37][200/391]	Time 0.1905 Data 0.0024 Loss 0.4791 (0.5363)	Acc@1 85.938 (82.824)	Acc@5 99.219 (98.305)
Epoch: [37][300/391]	Time 0.1924 Data 0.0024 Loss 0.6892 (0.5622)	Acc@1 78.906 (82.135)	Acc@5 98.438 (98.022)
Testing the models......
Loss: 1.5184, Prec@1: 62.66, Prec@5: 87.74
Epoch time: 82s
Epoch: 38  lr: 0.100
Epoch: [38][000/391]	Time 1.2483 Data 0.9861 Loss 0.8235 (0.8235)	Acc@1 76.562 (76.562)	Acc@5 96.875 (96.875)
Epoch: [38][100/391]	Time 0.1903 Data 0.0022 Loss 0.4914 (0.5067)	Acc@1 83.594 (83.764)	Acc@5 96.875 (98.584)
Epoch: [38][200/391]	Time 0.1903 Data 0.0021 Loss 0.4565 (0.5243)	Acc@1 85.156 (83.283)	Acc@5 98.438 (98.348)
Epoch: [38][300/391]	Time 0.1928 Data 0.0024 Loss 0.7765 (0.5440)	Acc@1 74.219 (82.825)	Acc@5 96.094 (98.131)
Testing the models......
Loss: 1.4795, Prec@1: 64.39, Prec@5: 88.63
Epoch time: 82s
Saving models
Epoch: 39  lr: 0.100
Epoch: [39][000/391]	Time 1.2506 Data 1.0597 Loss 0.5759 (0.5759)	Acc@1 79.688 (79.688)	Acc@5 98.438 (98.438)
Epoch: [39][100/391]	Time 0.1909 Data 0.0023 Loss 0.4960 (0.4821)	Acc@1 83.594 (84.777)	Acc@5 98.438 (98.499)
Epoch: [39][200/391]	Time 0.1917 Data 0.0020 Loss 0.5452 (0.5079)	Acc@1 81.250 (84.021)	Acc@5 99.219 (98.403)
Epoch: [39][300/391]	Time 0.1963 Data 0.0023 Loss 0.4630 (0.5257)	Acc@1 82.812 (83.467)	Acc@5 99.219 (98.297)
Testing the models......
Loss: 1.5671, Prec@1: 62.97, Prec@5: 87.39
Epoch time: 82s
Epoch: 40  lr: 0.100
Epoch: [40][000/391]	Time 1.1607 Data 0.9981 Loss 0.4439 (0.4439)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [40][100/391]	Time 0.1906 Data 0.0021 Loss 0.4342 (0.4750)	Acc@1 85.938 (84.870)	Acc@5 98.438 (98.670)
Epoch: [40][200/391]	Time 0.1921 Data 0.0020 Loss 0.4766 (0.4934)	Acc@1 86.719 (84.204)	Acc@5 97.656 (98.589)
Epoch: [40][300/391]	Time 0.1903 Data 0.0021 Loss 0.7542 (0.5117)	Acc@1 77.344 (83.705)	Acc@5 98.438 (98.427)
Testing the models......
Loss: 1.5786, Prec@1: 62.59, Prec@5: 87.42
Epoch time: 82s
Epoch: 41  lr: 0.100
Epoch: [41][000/391]	Time 1.2005 Data 1.0046 Loss 0.5198 (0.5198)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [41][100/391]	Time 0.1919 Data 0.0021 Loss 0.4254 (0.4731)	Acc@1 84.375 (85.048)	Acc@5 98.438 (98.685)
Epoch: [41][200/391]	Time 0.1929 Data 0.0023 Loss 0.4592 (0.4922)	Acc@1 83.594 (84.359)	Acc@5 98.438 (98.620)
Epoch: [41][300/391]	Time 0.1906 Data 0.0022 Loss 0.8082 (0.5121)	Acc@1 76.562 (83.716)	Acc@5 96.875 (98.476)
Testing the models......
Loss: 1.4808, Prec@1: 64.65, Prec@5: 88.81
Epoch time: 82s
Saving models
Epoch: 42  lr: 0.100
Epoch: [42][000/391]	Time 1.1932 Data 0.9983 Loss 0.4059 (0.4059)	Acc@1 85.156 (85.156)	Acc@5 100.000 (100.000)
Epoch: [42][100/391]	Time 0.1902 Data 0.0026 Loss 0.5280 (0.4664)	Acc@1 85.938 (85.249)	Acc@5 98.438 (98.793)
Epoch: [42][200/391]	Time 0.1901 Data 0.0025 Loss 0.5784 (0.4823)	Acc@1 82.812 (84.760)	Acc@5 97.656 (98.632)
Epoch: [42][300/391]	Time 0.1906 Data 0.0021 Loss 0.5826 (0.4875)	Acc@1 83.594 (84.663)	Acc@5 96.094 (98.549)
Testing the models......
Loss: 1.5443, Prec@1: 63.76, Prec@5: 87.77
Epoch time: 82s
Epoch: 43  lr: 0.100
Epoch: [43][000/391]	Time 1.2568 Data 0.9891 Loss 0.4571 (0.4571)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [43][100/391]	Time 0.1904 Data 0.0020 Loss 0.4591 (0.4317)	Acc@1 85.938 (86.301)	Acc@5 98.438 (98.987)
Epoch: [43][200/391]	Time 0.1917 Data 0.0021 Loss 0.4035 (0.4530)	Acc@1 87.500 (85.627)	Acc@5 97.656 (98.826)
Epoch: [43][300/391]	Time 0.1948 Data 0.0021 Loss 0.5731 (0.4800)	Acc@1 79.688 (84.780)	Acc@5 98.438 (98.630)
Testing the models......
Loss: 1.6466, Prec@1: 62.25, Prec@5: 86.40
Epoch time: 82s
Epoch: 44  lr: 0.100
Epoch: [44][000/391]	Time 1.2053 Data 1.0439 Loss 0.5017 (0.5017)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [44][100/391]	Time 0.1904 Data 0.0022 Loss 0.3173 (0.4312)	Acc@1 88.281 (86.487)	Acc@5 98.438 (98.994)
Epoch: [44][200/391]	Time 0.1896 Data 0.0022 Loss 0.4396 (0.4505)	Acc@1 85.938 (85.716)	Acc@5 100.000 (98.869)
Epoch: [44][300/391]	Time 0.1903 Data 0.0022 Loss 0.4782 (0.4667)	Acc@1 85.156 (85.276)	Acc@5 99.219 (98.728)
Testing the models......
Loss: 1.5048, Prec@1: 64.76, Prec@5: 88.42
Epoch time: 82s
Saving models
Epoch: 45  lr: 0.100
Epoch: [45][000/391]	Time 1.1506 Data 0.9207 Loss 0.3806 (0.3806)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [45][100/391]	Time 0.1917 Data 0.0023 Loss 0.4138 (0.4252)	Acc@1 86.719 (86.440)	Acc@5 99.219 (98.987)
Epoch: [45][200/391]	Time 0.1934 Data 0.0022 Loss 0.5723 (0.4387)	Acc@1 83.594 (86.085)	Acc@5 99.219 (98.919)
Epoch: [45][300/391]	Time 0.1896 Data 0.0022 Loss 0.5157 (0.4470)	Acc@1 87.500 (85.774)	Acc@5 98.438 (98.824)
Testing the models......
Loss: 1.4661, Prec@1: 64.94, Prec@5: 88.85
Epoch time: 82s
Saving models
Epoch: 46  lr: 0.100
Epoch: [46][000/391]	Time 1.2322 Data 0.9732 Loss 0.3581 (0.3581)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [46][100/391]	Time 0.1947 Data 0.0021 Loss 0.4207 (0.3988)	Acc@1 87.500 (87.283)	Acc@5 97.656 (99.095)
Epoch: [46][200/391]	Time 0.1907 Data 0.0023 Loss 0.4695 (0.4133)	Acc@1 81.250 (86.874)	Acc@5 99.219 (98.958)
Epoch: [46][300/391]	Time 0.1911 Data 0.0023 Loss 0.4620 (0.4364)	Acc@1 86.719 (86.114)	Acc@5 99.219 (98.853)
Testing the models......
Loss: 1.6406, Prec@1: 61.94, Prec@5: 87.03
Epoch time: 82s
Epoch: 47  lr: 0.100
Epoch: [47][000/391]	Time 1.1654 Data 0.9654 Loss 0.4469 (0.4469)	Acc@1 87.500 (87.500)	Acc@5 97.656 (97.656)
Epoch: [47][100/391]	Time 0.1920 Data 0.0022 Loss 0.4758 (0.3983)	Acc@1 83.594 (87.160)	Acc@5 99.219 (99.219)
Epoch: [47][200/391]	Time 0.1898 Data 0.0021 Loss 0.4774 (0.4159)	Acc@1 83.594 (86.730)	Acc@5 97.656 (99.048)
Epoch: [47][300/391]	Time 0.1926 Data 0.0021 Loss 0.3879 (0.4397)	Acc@1 86.719 (86.018)	Acc@5 99.219 (98.863)
Testing the models......
Loss: 1.5807, Prec@1: 63.02, Prec@5: 87.82
Epoch time: 82s
Epoch: 48  lr: 0.100
Epoch: [48][000/391]	Time 1.2310 Data 1.0084 Loss 0.2467 (0.2467)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [48][100/391]	Time 0.1899 Data 0.0021 Loss 0.3993 (0.3979)	Acc@1 89.062 (87.485)	Acc@5 99.219 (99.064)
Epoch: [48][200/391]	Time 0.1900 Data 0.0022 Loss 0.4006 (0.4114)	Acc@1 86.719 (86.991)	Acc@5 100.000 (99.005)
Epoch: [48][300/391]	Time 0.1909 Data 0.0023 Loss 0.4468 (0.4280)	Acc@1 85.938 (86.516)	Acc@5 97.656 (98.918)
Testing the models......
Loss: 1.5396, Prec@1: 64.09, Prec@5: 88.05
Epoch time: 82s
Epoch: 49  lr: 0.100
Epoch: [49][000/391]	Time 1.2875 Data 1.0236 Loss 0.3848 (0.3848)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [49][100/391]	Time 0.1901 Data 0.0022 Loss 0.3639 (0.3769)	Acc@1 88.281 (87.833)	Acc@5 100.000 (99.257)
Epoch: [49][200/391]	Time 0.1918 Data 0.0022 Loss 0.3793 (0.3944)	Acc@1 90.625 (87.430)	Acc@5 98.438 (99.118)
Epoch: [49][300/391]	Time 0.1909 Data 0.0022 Loss 0.4869 (0.4104)	Acc@1 84.375 (86.890)	Acc@5 100.000 (99.021)
Testing the models......
Loss: 1.5935, Prec@1: 63.24, Prec@5: 87.24
Epoch time: 82s
Epoch: 50  lr: 0.100
Epoch: [50][000/391]	Time 1.1183 Data 0.9297 Loss 0.4947 (0.4947)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [50][100/391]	Time 0.1893 Data 0.0022 Loss 0.3726 (0.3977)	Acc@1 86.719 (87.075)	Acc@5 99.219 (99.219)
Epoch: [50][200/391]	Time 0.1923 Data 0.0028 Loss 0.4025 (0.3961)	Acc@1 86.719 (87.170)	Acc@5 99.219 (99.176)
Epoch: [50][300/391]	Time 0.1902 Data 0.0023 Loss 0.5044 (0.4135)	Acc@1 84.375 (86.646)	Acc@5 96.875 (99.123)
Testing the models......
Loss: 1.5649, Prec@1: 63.93, Prec@5: 88.52
Epoch time: 82s
Epoch: 51  lr: 0.100
Epoch: [51][000/391]	Time 1.2164 Data 1.0306 Loss 0.3425 (0.3425)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [51][100/391]	Time 0.1897 Data 0.0020 Loss 0.3608 (0.3762)	Acc@1 88.281 (88.011)	Acc@5 100.000 (99.211)
Epoch: [51][200/391]	Time 0.1899 Data 0.0021 Loss 0.4725 (0.3792)	Acc@1 83.594 (87.928)	Acc@5 98.438 (99.184)
Epoch: [51][300/391]	Time 0.1956 Data 0.0023 Loss 0.4680 (0.4008)	Acc@1 82.031 (87.290)	Acc@5 100.000 (99.112)
Testing the models......
Loss: 1.5358, Prec@1: 64.35, Prec@5: 87.65
Epoch time: 82s
Epoch: 52  lr: 0.100
Epoch: [52][000/391]	Time 1.2047 Data 1.0116 Loss 0.3524 (0.3524)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [52][100/391]	Time 0.1900 Data 0.0023 Loss 0.4606 (0.3657)	Acc@1 86.719 (88.096)	Acc@5 100.000 (99.327)
Epoch: [52][200/391]	Time 0.1893 Data 0.0023 Loss 0.3654 (0.3735)	Acc@1 85.938 (87.998)	Acc@5 97.656 (99.219)
Epoch: [52][300/391]	Time 0.1915 Data 0.0022 Loss 0.2185 (0.3948)	Acc@1 92.969 (87.381)	Acc@5 100.000 (99.105)
Testing the models......
Loss: 1.6839, Prec@1: 61.85, Prec@5: 86.61
Epoch time: 82s
Epoch: 53  lr: 0.100
Epoch: [53][000/391]	Time 1.1645 Data 0.9678 Loss 0.3398 (0.3398)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [53][100/391]	Time 0.1889 Data 0.0024 Loss 0.3350 (0.3498)	Acc@1 86.719 (89.039)	Acc@5 99.219 (99.327)
Epoch: [53][200/391]	Time 0.1931 Data 0.0022 Loss 0.3730 (0.3738)	Acc@1 88.281 (88.250)	Acc@5 99.219 (99.192)
Epoch: [53][300/391]	Time 0.1944 Data 0.0024 Loss 0.4105 (0.3976)	Acc@1 85.156 (87.466)	Acc@5 100.000 (99.063)
Testing the models......
Loss: 1.5130, Prec@1: 64.65, Prec@5: 88.64
Epoch time: 82s
Epoch: 54  lr: 0.100
Epoch: [54][000/391]	Time 1.5089 Data 1.2737 Loss 0.3203 (0.3203)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [54][100/391]	Time 0.1913 Data 0.0019 Loss 0.3989 (0.3546)	Acc@1 88.281 (88.467)	Acc@5 99.219 (99.404)
Epoch: [54][200/391]	Time 0.1895 Data 0.0020 Loss 0.3115 (0.3630)	Acc@1 89.844 (88.281)	Acc@5 99.219 (99.335)
Epoch: [54][300/391]	Time 0.1896 Data 0.0020 Loss 0.5477 (0.3803)	Acc@1 84.375 (87.830)	Acc@5 98.438 (99.268)
Testing the models......
Loss: 1.7247, Prec@1: 62.07, Prec@5: 86.82
Epoch time: 82s
Epoch: 55  lr: 0.100
Epoch: [55][000/391]	Time 1.4865 Data 1.2121 Loss 0.3739 (0.3739)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [55][100/391]	Time 0.1919 Data 0.0027 Loss 0.2992 (0.3523)	Acc@1 89.844 (88.869)	Acc@5 100.000 (99.404)
Epoch: [55][200/391]	Time 0.1902 Data 0.0019 Loss 0.5085 (0.3606)	Acc@1 84.375 (88.627)	Acc@5 97.656 (99.285)
Epoch: [55][300/391]	Time 0.1893 Data 0.0021 Loss 0.4077 (0.3826)	Acc@1 89.062 (87.988)	Acc@5 100.000 (99.146)
Testing the models......
Loss: 1.6103, Prec@1: 63.25, Prec@5: 87.43
Epoch time: 82s
Epoch: 56  lr: 0.100
Epoch: [56][000/391]	Time 1.4738 Data 1.2718 Loss 0.3304 (0.3304)	Acc@1 89.844 (89.844)	Acc@5 97.656 (97.656)
Epoch: [56][100/391]	Time 0.1893 Data 0.0024 Loss 0.3300 (0.3529)	Acc@1 88.281 (88.769)	Acc@5 99.219 (99.281)
Epoch: [56][200/391]	Time 0.1901 Data 0.0024 Loss 0.4514 (0.3553)	Acc@1 85.938 (88.829)	Acc@5 98.438 (99.273)
Epoch: [56][300/391]	Time 0.1899 Data 0.0020 Loss 0.3516 (0.3739)	Acc@1 89.062 (88.328)	Acc@5 100.000 (99.206)
Testing the models......
Loss: 1.5561, Prec@1: 64.10, Prec@5: 88.20
Epoch time: 82s
Epoch: 57  lr: 0.100
Epoch: [57][000/391]	Time 1.4785 Data 1.2177 Loss 0.3920 (0.3920)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [57][100/391]	Time 0.1902 Data 0.0026 Loss 0.3270 (0.3274)	Acc@1 89.844 (89.828)	Acc@5 98.438 (99.389)
Epoch: [57][200/391]	Time 0.1899 Data 0.0024 Loss 0.3656 (0.3574)	Acc@1 89.062 (88.732)	Acc@5 98.438 (99.250)
Epoch: [57][300/391]	Time 0.1902 Data 0.0032 Loss 0.3184 (0.3751)	Acc@1 87.500 (88.196)	Acc@5 100.000 (99.172)
Testing the models......
Loss: 1.5683, Prec@1: 65.17, Prec@5: 87.83
Epoch time: 82s
Saving models
Epoch: 58  lr: 0.100
Epoch: [58][000/391]	Time 1.3276 Data 1.1008 Loss 0.3275 (0.3275)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [58][100/391]	Time 0.1804 Data 0.0025 Loss 0.3340 (0.3333)	Acc@1 89.844 (89.511)	Acc@5 100.000 (99.420)
Epoch: [58][200/391]	Time 0.1899 Data 0.0029 Loss 0.3368 (0.3481)	Acc@1 90.625 (88.794)	Acc@5 100.000 (99.320)
Epoch: [58][300/391]	Time 0.1906 Data 0.0038 Loss 0.4206 (0.3681)	Acc@1 89.062 (88.172)	Acc@5 98.438 (99.237)
Testing the models......
Loss: 1.5258, Prec@1: 65.08, Prec@5: 88.31
Epoch time: 82s
Epoch: 59  lr: 0.100
Epoch: [59][000/391]	Time 1.2504 Data 1.0559 Loss 0.3860 (0.3860)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [59][100/391]	Time 0.1908 Data 0.0020 Loss 0.1958 (0.3167)	Acc@1 93.750 (89.844)	Acc@5 100.000 (99.459)
Epoch: [59][200/391]	Time 0.1926 Data 0.0020 Loss 0.2878 (0.3313)	Acc@1 91.406 (89.521)	Acc@5 100.000 (99.374)
Epoch: [59][300/391]	Time 0.1912 Data 0.0022 Loss 0.5213 (0.3530)	Acc@1 85.938 (88.868)	Acc@5 97.656 (99.284)
Testing the models......
Loss: 1.5583, Prec@1: 64.55, Prec@5: 88.32
Epoch time: 82s
Epoch: 60  lr: 0.100
Epoch: [60][000/391]	Time 1.1664 Data 0.9976 Loss 0.3251 (0.3251)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [60][100/391]	Time 0.1890 Data 0.0019 Loss 0.4191 (0.3067)	Acc@1 87.500 (90.393)	Acc@5 100.000 (99.451)
Epoch: [60][200/391]	Time 0.1919 Data 0.0020 Loss 0.3942 (0.3286)	Acc@1 88.281 (89.731)	Acc@5 96.094 (99.401)
Epoch: [60][300/391]	Time 0.1909 Data 0.0020 Loss 0.3621 (0.3547)	Acc@1 89.062 (88.938)	Acc@5 97.656 (99.265)
Testing the models......
Loss: 1.5276, Prec@1: 64.96, Prec@5: 88.11
Epoch time: 82s
Epoch: 61  lr: 0.100
Epoch: [61][000/391]	Time 1.2067 Data 1.0077 Loss 0.3202 (0.3202)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [61][100/391]	Time 0.1896 Data 0.0021 Loss 0.3376 (0.3224)	Acc@1 87.500 (89.851)	Acc@5 100.000 (99.443)
Epoch: [61][200/391]	Time 0.1891 Data 0.0021 Loss 0.2902 (0.3372)	Acc@1 92.969 (89.556)	Acc@5 99.219 (99.308)
Epoch: [61][300/391]	Time 0.1920 Data 0.0021 Loss 0.4233 (0.3580)	Acc@1 85.938 (88.920)	Acc@5 97.656 (99.221)
Testing the models......
Loss: 1.6434, Prec@1: 63.15, Prec@5: 86.54
Epoch time: 82s
Epoch: 62  lr: 0.100
Epoch: [62][000/391]	Time 1.1808 Data 0.9725 Loss 0.2842 (0.2842)	Acc@1 90.625 (90.625)	Acc@5 98.438 (98.438)
Epoch: [62][100/391]	Time 0.1906 Data 0.0025 Loss 0.2502 (0.3130)	Acc@1 90.625 (90.192)	Acc@5 100.000 (99.397)
Epoch: [62][200/391]	Time 0.1914 Data 0.0020 Loss 0.4408 (0.3245)	Acc@1 85.156 (89.743)	Acc@5 99.219 (99.401)
Epoch: [62][300/391]	Time 0.1894 Data 0.0019 Loss 0.3988 (0.3457)	Acc@1 86.719 (89.088)	Acc@5 100.000 (99.273)
Testing the models......
Loss: 1.5186, Prec@1: 65.44, Prec@5: 88.38
Epoch time: 82s
Saving models
Epoch: 63  lr: 0.100
Epoch: [63][000/391]	Time 1.1296 Data 0.9195 Loss 0.2052 (0.2052)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [63][100/391]	Time 0.1909 Data 0.0021 Loss 0.2301 (0.3046)	Acc@1 93.750 (90.362)	Acc@5 100.000 (99.420)
Epoch: [63][200/391]	Time 0.1894 Data 0.0021 Loss 0.5546 (0.3128)	Acc@1 82.031 (89.914)	Acc@5 99.219 (99.452)
Epoch: [63][300/391]	Time 0.1897 Data 0.0023 Loss 0.2004 (0.3397)	Acc@1 94.531 (89.143)	Acc@5 100.000 (99.328)
Testing the models......
Loss: 1.5877, Prec@1: 64.57, Prec@5: 88.11
Epoch time: 82s
Epoch: 64  lr: 0.100
Epoch: [64][000/391]	Time 1.2457 Data 1.0672 Loss 0.3784 (0.3784)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [64][100/391]	Time 0.1931 Data 0.0020 Loss 0.1798 (0.3273)	Acc@1 93.750 (89.728)	Acc@5 100.000 (99.482)
Epoch: [64][200/391]	Time 0.1948 Data 0.0021 Loss 0.4494 (0.3447)	Acc@1 86.719 (89.218)	Acc@5 100.000 (99.347)
Epoch: [64][300/391]	Time 0.1911 Data 0.0019 Loss 0.4078 (0.3547)	Acc@1 86.719 (88.795)	Acc@5 100.000 (99.252)
Testing the models......
Loss: 1.4983, Prec@1: 65.47, Prec@5: 88.53
Epoch time: 82s
Saving models
Epoch: 65  lr: 0.100
Epoch: [65][000/391]	Time 1.1583 Data 0.9889 Loss 0.1898 (0.1898)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [65][100/391]	Time 0.1895 Data 0.0019 Loss 0.4052 (0.3100)	Acc@1 87.500 (90.277)	Acc@5 99.219 (99.435)
Epoch: [65][200/391]	Time 0.1915 Data 0.0020 Loss 0.3729 (0.3218)	Acc@1 91.406 (89.980)	Acc@5 100.000 (99.421)
Epoch: [65][300/391]	Time 0.1921 Data 0.0021 Loss 0.3213 (0.3424)	Acc@1 89.062 (89.270)	Acc@5 100.000 (99.367)
Testing the models......
Loss: 1.6897, Prec@1: 63.37, Prec@5: 86.55
Epoch time: 82s
Epoch: 66  lr: 0.100
Epoch: [66][000/391]	Time 1.1802 Data 0.9715 Loss 0.3642 (0.3642)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [66][100/391]	Time 0.1894 Data 0.0023 Loss 0.3514 (0.3225)	Acc@1 88.281 (89.813)	Acc@5 100.000 (99.443)
Epoch: [66][200/391]	Time 0.1892 Data 0.0019 Loss 0.3561 (0.3301)	Acc@1 89.062 (89.599)	Acc@5 100.000 (99.425)
Epoch: [66][300/391]	Time 0.1899 Data 0.0020 Loss 0.4375 (0.3413)	Acc@1 89.062 (89.239)	Acc@5 99.219 (99.380)
Testing the models......
Loss: 1.6116, Prec@1: 64.41, Prec@5: 87.03
Epoch time: 82s
Epoch: 67  lr: 0.100
Epoch: [67][000/391]	Time 1.1709 Data 0.9831 Loss 0.2954 (0.2954)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [67][100/391]	Time 0.1894 Data 0.0020 Loss 0.4293 (0.3206)	Acc@1 86.719 (89.735)	Acc@5 99.219 (99.350)
Epoch: [67][200/391]	Time 0.1892 Data 0.0020 Loss 0.2291 (0.3300)	Acc@1 92.969 (89.451)	Acc@5 99.219 (99.273)
Epoch: [67][300/391]	Time 0.1899 Data 0.0019 Loss 0.4322 (0.3434)	Acc@1 86.719 (89.091)	Acc@5 99.219 (99.216)
Testing the models......
Loss: 1.6523, Prec@1: 63.60, Prec@5: 87.25
Epoch time: 82s
Epoch: 68  lr: 0.100
Epoch: [68][000/391]	Time 1.1662 Data 1.0056 Loss 0.2298 (0.2298)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [68][100/391]	Time 0.1895 Data 0.0019 Loss 0.3733 (0.2981)	Acc@1 89.844 (90.455)	Acc@5 100.000 (99.567)
Epoch: [68][200/391]	Time 0.1905 Data 0.0020 Loss 0.2726 (0.3127)	Acc@1 89.844 (89.995)	Acc@5 99.219 (99.502)
Epoch: [68][300/391]	Time 0.1914 Data 0.0021 Loss 0.2933 (0.3252)	Acc@1 91.406 (89.621)	Acc@5 99.219 (99.432)
Testing the models......
Loss: 1.6139, Prec@1: 65.07, Prec@5: 86.96
Epoch time: 82s
Epoch: 69  lr: 0.100
Epoch: [69][000/391]	Time 1.1993 Data 0.9803 Loss 0.4158 (0.4158)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [69][100/391]	Time 0.1902 Data 0.0020 Loss 0.3235 (0.3109)	Acc@1 89.844 (89.921)	Acc@5 98.438 (99.567)
Epoch: [69][200/391]	Time 0.1892 Data 0.0021 Loss 0.3307 (0.3248)	Acc@1 89.062 (89.642)	Acc@5 100.000 (99.429)
Epoch: [69][300/391]	Time 0.1909 Data 0.0020 Loss 0.4497 (0.3384)	Acc@1 85.938 (89.148)	Acc@5 99.219 (99.351)
Testing the models......
Loss: 1.6221, Prec@1: 64.16, Prec@5: 88.00
Epoch time: 82s
Epoch: 70  lr: 0.100
Epoch: [70][000/391]	Time 1.1768 Data 0.9567 Loss 0.3035 (0.3035)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [70][100/391]	Time 0.1911 Data 0.0021 Loss 0.2481 (0.3015)	Acc@1 92.188 (90.207)	Acc@5 100.000 (99.528)
Epoch: [70][200/391]	Time 0.1923 Data 0.0021 Loss 0.3479 (0.3157)	Acc@1 89.844 (89.906)	Acc@5 99.219 (99.433)
Epoch: [70][300/391]	Time 0.1901 Data 0.0020 Loss 0.2827 (0.3323)	Acc@1 91.406 (89.486)	Acc@5 99.219 (99.336)
Testing the models......
Loss: 1.5991, Prec@1: 64.61, Prec@5: 87.54
Epoch time: 82s
Epoch: 71  lr: 0.100
Epoch: [71][000/391]	Time 1.1865 Data 0.9861 Loss 0.2204 (0.2204)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [71][100/391]	Time 0.1906 Data 0.0020 Loss 0.3323 (0.2989)	Acc@1 90.625 (90.702)	Acc@5 99.219 (99.575)
Epoch: [71][200/391]	Time 0.1902 Data 0.0021 Loss 0.2313 (0.3187)	Acc@1 90.625 (90.058)	Acc@5 100.000 (99.436)
Epoch: [71][300/391]	Time 0.1911 Data 0.0020 Loss 0.4385 (0.3365)	Acc@1 85.938 (89.524)	Acc@5 99.219 (99.338)
Testing the models......
Loss: 1.6428, Prec@1: 62.97, Prec@5: 87.22
Epoch time: 82s
Epoch: 72  lr: 0.100
Epoch: [72][000/391]	Time 1.3916 Data 1.1711 Loss 0.3003 (0.3003)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [72][100/391]	Time 0.1909 Data 0.0022 Loss 0.3332 (0.3120)	Acc@1 89.844 (90.238)	Acc@5 99.219 (99.505)
Epoch: [72][200/391]	Time 0.1889 Data 0.0019 Loss 0.2532 (0.3228)	Acc@1 92.188 (89.890)	Acc@5 99.219 (99.468)
Epoch: [72][300/391]	Time 0.1888 Data 0.0019 Loss 0.3040 (0.3352)	Acc@1 89.844 (89.392)	Acc@5 99.219 (99.333)
Testing the models......
Loss: 1.5857, Prec@1: 65.29, Prec@5: 88.28
Epoch time: 82s
Epoch: 73  lr: 0.100
Epoch: [73][000/391]	Time 1.1699 Data 0.9077 Loss 0.3457 (0.3457)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [73][100/391]	Time 0.1892 Data 0.0020 Loss 0.3914 (0.2983)	Acc@1 89.062 (90.756)	Acc@5 98.438 (99.451)
Epoch: [73][200/391]	Time 0.1893 Data 0.0021 Loss 0.2602 (0.3076)	Acc@1 92.969 (90.240)	Acc@5 100.000 (99.491)
Epoch: [73][300/391]	Time 0.1895 Data 0.0020 Loss 0.3001 (0.3245)	Acc@1 90.625 (89.737)	Acc@5 99.219 (99.429)
Testing the models......
Loss: 1.6174, Prec@1: 64.10, Prec@5: 87.70
Epoch time: 82s
Epoch: 74  lr: 0.100
Epoch: [74][000/391]	Time 1.2452 Data 1.0910 Loss 0.2575 (0.2575)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [74][100/391]	Time 0.1904 Data 0.0020 Loss 0.2985 (0.2805)	Acc@1 90.625 (91.337)	Acc@5 99.219 (99.621)
Epoch: [74][200/391]	Time 0.1901 Data 0.0019 Loss 0.3316 (0.2888)	Acc@1 90.625 (91.095)	Acc@5 99.219 (99.537)
Epoch: [74][300/391]	Time 0.1942 Data 0.0020 Loss 0.3875 (0.3080)	Acc@1 88.281 (90.389)	Acc@5 100.000 (99.437)
Testing the models......
Loss: 1.6174, Prec@1: 64.65, Prec@5: 87.66
Epoch time: 82s
Epoch: 75  lr: 0.100
Epoch: [75][000/391]	Time 1.1528 Data 0.9720 Loss 0.2603 (0.2603)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [75][100/391]	Time 0.1887 Data 0.0021 Loss 0.1989 (0.2889)	Acc@1 92.188 (90.934)	Acc@5 100.000 (99.451)
Epoch: [75][200/391]	Time 0.1966 Data 0.0030 Loss 0.3016 (0.3001)	Acc@1 89.844 (90.625)	Acc@5 100.000 (99.440)
Epoch: [75][300/391]	Time 0.1902 Data 0.0021 Loss 0.4827 (0.3163)	Acc@1 82.812 (90.028)	Acc@5 99.219 (99.377)
Testing the models......
Loss: 1.5622, Prec@1: 65.37, Prec@5: 88.48
Epoch time: 81s
Epoch: 76  lr: 0.100
Epoch: [76][000/391]	Time 1.1606 Data 0.9426 Loss 0.2434 (0.2434)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [76][100/391]	Time 0.1896 Data 0.0021 Loss 0.3789 (0.2824)	Acc@1 87.500 (91.004)	Acc@5 100.000 (99.544)
Epoch: [76][200/391]	Time 0.1897 Data 0.0021 Loss 0.2937 (0.2882)	Acc@1 89.844 (90.975)	Acc@5 100.000 (99.522)
Epoch: [76][300/391]	Time 0.1895 Data 0.0020 Loss 0.3491 (0.3097)	Acc@1 89.062 (90.215)	Acc@5 100.000 (99.437)
Testing the models......
Loss: 1.7166, Prec@1: 63.57, Prec@5: 86.90
Epoch time: 82s
Epoch: 77  lr: 0.100
Epoch: [77][000/391]	Time 1.2245 Data 1.0634 Loss 0.2072 (0.2072)	Acc@1 94.531 (94.531)	Acc@5 99.219 (99.219)
Epoch: [77][100/391]	Time 0.1904 Data 0.0020 Loss 0.2009 (0.2771)	Acc@1 95.312 (91.275)	Acc@5 100.000 (99.520)
Epoch: [77][200/391]	Time 0.1892 Data 0.0018 Loss 0.3425 (0.2895)	Acc@1 89.062 (91.014)	Acc@5 100.000 (99.471)
Epoch: [77][300/391]	Time 0.1888 Data 0.0021 Loss 0.3534 (0.3157)	Acc@1 87.500 (90.116)	Acc@5 99.219 (99.413)
Testing the models......
Loss: 1.5783, Prec@1: 65.70, Prec@5: 87.90
Epoch time: 82s
Saving models
Epoch: 78  lr: 0.100
Epoch: [78][000/391]	Time 1.1177 Data 0.8797 Loss 0.3532 (0.3532)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [78][100/391]	Time 0.1895 Data 0.0020 Loss 0.3894 (0.2775)	Acc@1 87.500 (91.329)	Acc@5 99.219 (99.544)
Epoch: [78][200/391]	Time 0.1921 Data 0.0024 Loss 0.2414 (0.2841)	Acc@1 94.531 (91.239)	Acc@5 99.219 (99.471)
Epoch: [78][300/391]	Time 0.1927 Data 0.0020 Loss 0.2388 (0.3023)	Acc@1 92.188 (90.511)	Acc@5 100.000 (99.419)
Testing the models......
Loss: 1.5205, Prec@1: 66.28, Prec@5: 87.70
Epoch time: 82s
Saving models
Epoch: 79  lr: 0.100
Epoch: [79][000/391]	Time 1.1961 Data 0.9999 Loss 0.3040 (0.3040)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [79][100/391]	Time 0.1888 Data 0.0019 Loss 0.2629 (0.2586)	Acc@1 92.188 (91.785)	Acc@5 99.219 (99.621)
Epoch: [79][200/391]	Time 0.1900 Data 0.0020 Loss 0.4863 (0.2935)	Acc@1 85.156 (90.656)	Acc@5 99.219 (99.479)
Epoch: [79][300/391]	Time 0.1905 Data 0.0019 Loss 0.3338 (0.3167)	Acc@1 89.844 (89.994)	Acc@5 100.000 (99.419)
Testing the models......
Loss: 1.5356, Prec@1: 65.99, Prec@5: 88.34
Epoch time: 82s
Epoch: 80  lr: 0.100
Epoch: [80][000/391]	Time 1.2359 Data 1.0221 Loss 0.2427 (0.2427)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [80][100/391]	Time 0.1916 Data 0.0019 Loss 0.2222 (0.2780)	Acc@1 89.844 (90.996)	Acc@5 100.000 (99.513)
Epoch: [80][200/391]	Time 0.1900 Data 0.0022 Loss 0.3037 (0.2881)	Acc@1 92.188 (90.951)	Acc@5 98.438 (99.495)
Epoch: [80][300/391]	Time 0.1939 Data 0.0021 Loss 0.2511 (0.3045)	Acc@1 92.188 (90.454)	Acc@5 100.000 (99.450)
Testing the models......
Loss: 1.7589, Prec@1: 63.01, Prec@5: 86.57
Epoch time: 82s
Epoch: 81  lr: 0.100
Epoch: [81][000/391]	Time 1.2024 Data 0.9751 Loss 0.2375 (0.2375)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [81][100/391]	Time 0.1893 Data 0.0021 Loss 0.1890 (0.2808)	Acc@1 97.656 (91.074)	Acc@5 99.219 (99.613)
Epoch: [81][200/391]	Time 0.1899 Data 0.0019 Loss 0.3896 (0.2882)	Acc@1 91.406 (90.971)	Acc@5 98.438 (99.502)
Epoch: [81][300/391]	Time 0.1918 Data 0.0020 Loss 0.2359 (0.3033)	Acc@1 93.750 (90.578)	Acc@5 99.219 (99.421)
Testing the models......
Loss: 1.6043, Prec@1: 65.23, Prec@5: 88.53
Epoch time: 82s
Epoch: 82  lr: 0.100
Epoch: [82][000/391]	Time 1.1795 Data 0.9211 Loss 0.2747 (0.2747)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [82][100/391]	Time 0.1894 Data 0.0022 Loss 0.3856 (0.2835)	Acc@1 87.500 (91.190)	Acc@5 99.219 (99.489)
Epoch: [82][200/391]	Time 0.1899 Data 0.0019 Loss 0.2856 (0.2947)	Acc@1 90.625 (90.827)	Acc@5 100.000 (99.452)
Epoch: [82][300/391]	Time 0.1892 Data 0.0019 Loss 0.2598 (0.3055)	Acc@1 90.625 (90.425)	Acc@5 100.000 (99.429)
Testing the models......
Loss: 1.6569, Prec@1: 64.76, Prec@5: 87.71
Epoch time: 82s
Epoch: 83  lr: 0.100
Epoch: [83][000/391]	Time 1.2023 Data 0.9754 Loss 0.2525 (0.2525)	Acc@1 93.750 (93.750)	Acc@5 98.438 (98.438)
Epoch: [83][100/391]	Time 0.1892 Data 0.0020 Loss 0.1863 (0.2781)	Acc@1 93.750 (91.530)	Acc@5 100.000 (99.474)
Epoch: [83][200/391]	Time 0.1893 Data 0.0019 Loss 0.2704 (0.2892)	Acc@1 90.625 (90.924)	Acc@5 99.219 (99.491)
Epoch: [83][300/391]	Time 0.1918 Data 0.0020 Loss 0.3537 (0.3089)	Acc@1 89.062 (90.334)	Acc@5 100.000 (99.445)
Testing the models......
Loss: 1.5602, Prec@1: 65.80, Prec@5: 87.72
Epoch time: 82s
Epoch: 84  lr: 0.100
Epoch: [84][000/391]	Time 1.1436 Data 0.9891 Loss 0.2334 (0.2334)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [84][100/391]	Time 0.1898 Data 0.0020 Loss 0.2914 (0.2672)	Acc@1 90.625 (91.723)	Acc@5 100.000 (99.544)
Epoch: [84][200/391]	Time 0.1895 Data 0.0019 Loss 0.4361 (0.2864)	Acc@1 89.062 (91.103)	Acc@5 99.219 (99.510)
Epoch: [84][300/391]	Time 0.1898 Data 0.0020 Loss 0.2875 (0.2900)	Acc@1 89.844 (90.874)	Acc@5 100.000 (99.486)
Testing the models......
Loss: 1.7025, Prec@1: 64.12, Prec@5: 87.03
Epoch time: 82s
Epoch: 85  lr: 0.100
Epoch: [85][000/391]	Time 1.1793 Data 1.0139 Loss 0.2552 (0.2552)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [85][100/391]	Time 0.1911 Data 0.0019 Loss 0.3430 (0.2820)	Acc@1 89.844 (91.120)	Acc@5 100.000 (99.613)
Epoch: [85][200/391]	Time 0.1891 Data 0.0019 Loss 0.2909 (0.2884)	Acc@1 90.625 (91.006)	Acc@5 98.438 (99.534)
Epoch: [85][300/391]	Time 0.1914 Data 0.0019 Loss 0.3414 (0.3097)	Acc@1 88.281 (90.417)	Acc@5 100.000 (99.426)
Testing the models......
Loss: 1.5939, Prec@1: 65.55, Prec@5: 87.64
Epoch time: 82s
Epoch: 86  lr: 0.100
Epoch: [86][000/391]	Time 1.1376 Data 0.9865 Loss 0.1867 (0.1867)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [86][100/391]	Time 0.1893 Data 0.0020 Loss 0.2517 (0.2686)	Acc@1 93.750 (91.662)	Acc@5 99.219 (99.551)
Epoch: [86][200/391]	Time 0.1894 Data 0.0021 Loss 0.4654 (0.2759)	Acc@1 85.156 (91.426)	Acc@5 99.219 (99.565)
Epoch: [86][300/391]	Time 0.1894 Data 0.0023 Loss 0.2581 (0.2898)	Acc@1 93.750 (90.957)	Acc@5 100.000 (99.528)
Testing the models......
Loss: 1.6320, Prec@1: 64.47, Prec@5: 87.46
Epoch time: 82s
Epoch: 87  lr: 0.100
Epoch: [87][000/391]	Time 1.1923 Data 0.9826 Loss 0.1863 (0.1863)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [87][100/391]	Time 0.1896 Data 0.0024 Loss 0.4093 (0.2593)	Acc@1 86.719 (92.017)	Acc@5 97.656 (99.567)
Epoch: [87][200/391]	Time 0.1898 Data 0.0019 Loss 0.4264 (0.2716)	Acc@1 88.281 (91.542)	Acc@5 100.000 (99.549)
Epoch: [87][300/391]	Time 0.1895 Data 0.0019 Loss 0.2966 (0.2942)	Acc@1 88.281 (90.783)	Acc@5 100.000 (99.460)
Testing the models......
Loss: 1.7964, Prec@1: 62.83, Prec@5: 86.47
Epoch time: 82s
Epoch: 88  lr: 0.100
Epoch: [88][000/391]	Time 1.2095 Data 0.9817 Loss 0.3317 (0.3317)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)
Epoch: [88][100/391]	Time 0.1896 Data 0.0025 Loss 0.3356 (0.2870)	Acc@1 89.844 (90.888)	Acc@5 99.219 (99.505)
Epoch: [88][200/391]	Time 0.1902 Data 0.0021 Loss 0.4339 (0.2977)	Acc@1 89.062 (90.644)	Acc@5 98.438 (99.487)
Epoch: [88][300/391]	Time 0.1890 Data 0.0019 Loss 0.4068 (0.3106)	Acc@1 86.719 (90.202)	Acc@5 100.000 (99.486)
Testing the models......
Loss: 1.7320, Prec@1: 63.23, Prec@5: 86.89
Epoch time: 82s
Epoch: 89  lr: 0.100
Epoch: [89][000/391]	Time 1.1974 Data 0.9970 Loss 0.3122 (0.3122)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [89][100/391]	Time 0.1902 Data 0.0028 Loss 0.4399 (0.2933)	Acc@1 86.719 (90.795)	Acc@5 97.656 (99.459)
Epoch: [89][200/391]	Time 0.1898 Data 0.0021 Loss 0.2522 (0.2913)	Acc@1 89.844 (90.870)	Acc@5 100.000 (99.394)
Epoch: [89][300/391]	Time 0.1917 Data 0.0021 Loss 0.2919 (0.3037)	Acc@1 90.625 (90.438)	Acc@5 98.438 (99.372)
Testing the models......
Loss: 1.6806, Prec@1: 64.26, Prec@5: 87.29
Epoch time: 82s
Epoch: 90  lr: 0.100
Epoch: [90][000/391]	Time 1.2054 Data 0.9868 Loss 0.3145 (0.3145)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [90][100/391]	Time 0.1888 Data 0.0021 Loss 0.2818 (0.2817)	Acc@1 90.625 (91.321)	Acc@5 99.219 (99.544)
Epoch: [90][200/391]	Time 0.1912 Data 0.0020 Loss 0.2555 (0.2846)	Acc@1 92.188 (91.072)	Acc@5 99.219 (99.530)
Epoch: [90][300/391]	Time 0.1891 Data 0.0019 Loss 0.2299 (0.2949)	Acc@1 92.188 (90.742)	Acc@5 100.000 (99.509)
Testing the models......
Loss: 1.5800, Prec@1: 65.87, Prec@5: 87.75
Epoch time: 82s
Epoch: 91  lr: 0.100
Epoch: [91][000/391]	Time 1.2096 Data 1.0142 Loss 0.3845 (0.3845)	Acc@1 89.844 (89.844)	Acc@5 96.875 (96.875)
Epoch: [91][100/391]	Time 0.1912 Data 0.0020 Loss 0.2636 (0.2522)	Acc@1 90.625 (92.118)	Acc@5 100.000 (99.582)
Epoch: [91][200/391]	Time 0.1902 Data 0.0018 Loss 0.4354 (0.2574)	Acc@1 88.281 (91.966)	Acc@5 97.656 (99.611)
Epoch: [91][300/391]	Time 0.1888 Data 0.0020 Loss 0.2252 (0.2743)	Acc@1 93.750 (91.437)	Acc@5 99.219 (99.559)
Testing the models......
Loss: 1.6802, Prec@1: 64.57, Prec@5: 87.10
Epoch time: 82s
Epoch: 92  lr: 0.100
Epoch: [92][000/391]	Time 1.1002 Data 0.9056 Loss 0.2402 (0.2402)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [92][100/391]	Time 0.1906 Data 0.0023 Loss 0.2674 (0.2744)	Acc@1 92.188 (91.723)	Acc@5 99.219 (99.505)
Epoch: [92][200/391]	Time 0.1913 Data 0.0033 Loss 0.3388 (0.2913)	Acc@1 88.281 (91.134)	Acc@5 98.438 (99.506)
Epoch: [92][300/391]	Time 0.1895 Data 0.0019 Loss 0.4084 (0.2918)	Acc@1 85.156 (91.014)	Acc@5 99.219 (99.512)
Testing the models......
Loss: 1.7669, Prec@1: 62.38, Prec@5: 86.68
Epoch time: 82s
Epoch: 93  lr: 0.100
Epoch: [93][000/391]	Time 1.1860 Data 0.9727 Loss 0.1649 (0.1649)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [93][100/391]	Time 0.1896 Data 0.0019 Loss 0.1722 (0.2728)	Acc@1 95.312 (91.530)	Acc@5 100.000 (99.606)
Epoch: [93][200/391]	Time 0.1912 Data 0.0021 Loss 0.3229 (0.2690)	Acc@1 86.719 (91.558)	Acc@5 100.000 (99.619)
Epoch: [93][300/391]	Time 0.1890 Data 0.0020 Loss 0.3670 (0.2767)	Acc@1 90.625 (91.380)	Acc@5 99.219 (99.564)
Testing the models......
Loss: 1.5446, Prec@1: 66.51, Prec@5: 88.39
Epoch time: 82s
Saving models
Epoch: 94  lr: 0.100
Epoch: [94][000/391]	Time 1.2134 Data 1.0166 Loss 0.1896 (0.1896)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [94][100/391]	Time 0.1891 Data 0.0021 Loss 0.1260 (0.2442)	Acc@1 96.875 (92.582)	Acc@5 100.000 (99.636)
Epoch: [94][200/391]	Time 0.1908 Data 0.0021 Loss 0.3598 (0.2594)	Acc@1 88.281 (92.207)	Acc@5 99.219 (99.592)
Epoch: [94][300/391]	Time 0.1906 Data 0.0025 Loss 0.2920 (0.2771)	Acc@1 90.625 (91.515)	Acc@5 99.219 (99.517)
Testing the models......
Loss: 1.6006, Prec@1: 65.26, Prec@5: 88.25
Epoch time: 82s
Epoch: 95  lr: 0.100
Epoch: [95][000/391]	Time 1.1688 Data 0.9742 Loss 0.1956 (0.1956)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [95][100/391]	Time 0.1895 Data 0.0021 Loss 0.2289 (0.2618)	Acc@1 91.406 (91.878)	Acc@5 100.000 (99.598)
Epoch: [95][200/391]	Time 0.1897 Data 0.0022 Loss 0.3454 (0.2740)	Acc@1 88.281 (91.422)	Acc@5 99.219 (99.565)
Epoch: [95][300/391]	Time 0.1896 Data 0.0020 Loss 0.3806 (0.2925)	Acc@1 85.938 (90.916)	Acc@5 99.219 (99.489)
Testing the models......
Loss: 1.6991, Prec@1: 64.12, Prec@5: 87.13
Epoch time: 82s
Epoch: 96  lr: 0.100
Epoch: [96][000/391]	Time 1.1436 Data 0.9502 Loss 0.3384 (0.3384)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [96][100/391]	Time 0.1893 Data 0.0019 Loss 0.2154 (0.2812)	Acc@1 93.750 (91.499)	Acc@5 100.000 (99.451)
Epoch: [96][200/391]	Time 0.1896 Data 0.0020 Loss 0.1329 (0.2809)	Acc@1 95.312 (91.406)	Acc@5 100.000 (99.468)
Epoch: [96][300/391]	Time 0.1917 Data 0.0020 Loss 0.1552 (0.2876)	Acc@1 96.094 (91.186)	Acc@5 100.000 (99.439)
Testing the models......
Loss: 1.5998, Prec@1: 66.06, Prec@5: 88.32
Epoch time: 82s
Epoch: 97  lr: 0.100
Epoch: [97][000/391]	Time 1.2484 Data 0.9850 Loss 0.3153 (0.3153)	Acc@1 91.406 (91.406)	Acc@5 98.438 (98.438)
Epoch: [97][100/391]	Time 0.1895 Data 0.0021 Loss 0.2359 (0.2620)	Acc@1 92.969 (91.940)	Acc@5 99.219 (99.613)
Epoch: [97][200/391]	Time 0.1896 Data 0.0021 Loss 0.3403 (0.2817)	Acc@1 89.062 (91.336)	Acc@5 100.000 (99.506)
Epoch: [97][300/391]	Time 0.1901 Data 0.0025 Loss 0.4053 (0.2886)	Acc@1 89.062 (90.988)	Acc@5 98.438 (99.507)
Testing the models......
Loss: 1.7270, Prec@1: 64.32, Prec@5: 86.58
Epoch time: 82s
Epoch: 98  lr: 0.100
Epoch: [98][000/391]	Time 1.2054 Data 0.9885 Loss 0.3980 (0.3980)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [98][100/391]	Time 0.1891 Data 0.0020 Loss 0.3692 (0.2732)	Acc@1 88.281 (91.499)	Acc@5 99.219 (99.636)
Epoch: [98][200/391]	Time 0.1888 Data 0.0020 Loss 0.2009 (0.2758)	Acc@1 94.531 (91.387)	Acc@5 100.000 (99.580)
Epoch: [98][300/391]	Time 0.1903 Data 0.0021 Loss 0.2700 (0.2887)	Acc@1 91.406 (90.931)	Acc@5 100.000 (99.509)
Testing the models......
Loss: 1.5901, Prec@1: 64.78, Prec@5: 88.09
Epoch time: 82s
Epoch: 99  lr: 0.100
Epoch: [99][000/391]	Time 1.1576 Data 0.8959 Loss 0.1829 (0.1829)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [99][100/391]	Time 0.1849 Data 0.0022 Loss 0.2836 (0.2724)	Acc@1 90.625 (91.468)	Acc@5 100.000 (99.559)
Epoch: [99][200/391]	Time 0.1967 Data 0.0022 Loss 0.4046 (0.2742)	Acc@1 89.062 (91.492)	Acc@5 98.438 (99.530)
Epoch: [99][300/391]	Time 0.1900 Data 0.0021 Loss 0.2976 (0.2862)	Acc@1 92.188 (91.144)	Acc@5 99.219 (99.478)
Testing the models......
Loss: 1.5979, Prec@1: 65.84, Prec@5: 87.68
Epoch time: 82s
Epoch: 100  lr: 0.010
Epoch: [100][000/391]	Time 1.2054 Data 1.0253 Loss 0.3160 (0.3160)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [100][100/391]	Time 0.1907 Data 0.0021 Loss 0.1304 (0.1459)	Acc@1 95.312 (95.862)	Acc@5 100.000 (99.899)
Epoch: [100][200/391]	Time 0.1895 Data 0.0020 Loss 0.0654 (0.1211)	Acc@1 98.438 (96.727)	Acc@5 100.000 (99.934)
Epoch: [100][300/391]	Time 0.1896 Data 0.0020 Loss 0.0815 (0.1070)	Acc@1 98.438 (97.176)	Acc@5 100.000 (99.951)
Testing the models......
Loss: 1.0588, Prec@1: 73.77, Prec@5: 92.45
Epoch time: 82s
Saving models
Epoch: 101  lr: 0.010
Epoch: [101][000/391]	Time 1.1409 Data 0.9139 Loss 0.0213 (0.0213)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [101][100/391]	Time 0.1924 Data 0.0021 Loss 0.0683 (0.0592)	Acc@1 99.219 (98.971)	Acc@5 100.000 (100.000)
Epoch: [101][200/391]	Time 0.1925 Data 0.0021 Loss 0.0781 (0.0561)	Acc@1 98.438 (99.032)	Acc@5 100.000 (99.996)
Epoch: [101][300/391]	Time 0.1900 Data 0.0020 Loss 0.0444 (0.0553)	Acc@1 99.219 (99.029)	Acc@5 100.000 (99.995)
Testing the models......
Loss: 1.0233, Prec@1: 74.55, Prec@5: 92.46
Epoch time: 82s
Saving models
Epoch: 102  lr: 0.010
Epoch: [102][000/391]	Time 1.1878 Data 0.9959 Loss 0.0544 (0.0544)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [102][100/391]	Time 0.1904 Data 0.0020 Loss 0.0362 (0.0445)	Acc@1 100.000 (99.343)	Acc@5 100.000 (99.992)
Epoch: [102][200/391]	Time 0.1901 Data 0.0020 Loss 0.0428 (0.0441)	Acc@1 99.219 (99.390)	Acc@5 100.000 (99.996)
Epoch: [102][300/391]	Time 0.1897 Data 0.0020 Loss 0.0369 (0.0435)	Acc@1 100.000 (99.400)	Acc@5 100.000 (99.997)
Testing the models......
Loss: 1.0108, Prec@1: 74.50, Prec@5: 92.59
Epoch time: 82s
Epoch: 103  lr: 0.010
Epoch: [103][000/391]	Time 1.1398 Data 0.9420 Loss 0.0469 (0.0469)	Acc@1 98.438 (98.438)	Acc@5 100.000 (100.000)
Epoch: [103][100/391]	Time 0.1894 Data 0.0019 Loss 0.0669 (0.0415)	Acc@1 98.438 (99.397)	Acc@5 100.000 (100.000)
Epoch: [103][200/391]	Time 0.1902 Data 0.0020 Loss 0.0349 (0.0396)	Acc@1 100.000 (99.487)	Acc@5 100.000 (100.000)
Epoch: [103][300/391]	Time 0.1945 Data 0.0020 Loss 0.0399 (0.0390)	Acc@1 99.219 (99.535)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0049, Prec@1: 74.64, Prec@5: 92.73
Epoch time: 82s
Saving models
Epoch: 104  lr: 0.010
Epoch: [104][000/391]	Time 1.2436 Data 1.0488 Loss 0.0234 (0.0234)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [104][100/391]	Time 0.1945 Data 0.0028 Loss 0.0406 (0.0367)	Acc@1 100.000 (99.582)	Acc@5 100.000 (100.000)
Epoch: [104][200/391]	Time 0.1900 Data 0.0020 Loss 0.0275 (0.0354)	Acc@1 99.219 (99.600)	Acc@5 100.000 (100.000)
Epoch: [104][300/391]	Time 0.1899 Data 0.0022 Loss 0.0440 (0.0350)	Acc@1 99.219 (99.603)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9876, Prec@1: 75.05, Prec@5: 92.73
Epoch time: 82s
Saving models
Epoch: 105  lr: 0.010
Epoch: [105][000/391]	Time 1.2517 Data 1.0488 Loss 0.0456 (0.0456)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [105][100/391]	Time 0.1894 Data 0.0026 Loss 0.0297 (0.0300)	Acc@1 100.000 (99.838)	Acc@5 100.000 (100.000)
Epoch: [105][200/391]	Time 0.1893 Data 0.0021 Loss 0.0191 (0.0316)	Acc@1 100.000 (99.775)	Acc@5 100.000 (100.000)
Epoch: [105][300/391]	Time 0.1888 Data 0.0022 Loss 0.0220 (0.0319)	Acc@1 100.000 (99.748)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9839, Prec@1: 75.11, Prec@5: 92.75
Epoch time: 82s
Saving models
Epoch: 106  lr: 0.010
Epoch: [106][000/391]	Time 1.1895 Data 0.9831 Loss 0.0367 (0.0367)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [106][100/391]	Time 0.1892 Data 0.0020 Loss 0.0243 (0.0307)	Acc@1 100.000 (99.783)	Acc@5 100.000 (100.000)
Epoch: [106][200/391]	Time 0.1893 Data 0.0020 Loss 0.0368 (0.0294)	Acc@1 100.000 (99.810)	Acc@5 100.000 (100.000)
Epoch: [106][300/391]	Time 0.1907 Data 0.0022 Loss 0.0243 (0.0298)	Acc@1 100.000 (99.795)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9769, Prec@1: 75.27, Prec@5: 92.89
Epoch time: 82s
Saving models
Epoch: 107  lr: 0.010
Epoch: [107][000/391]	Time 1.2495 Data 1.0208 Loss 0.0334 (0.0334)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [107][100/391]	Time 0.1929 Data 0.0021 Loss 0.0506 (0.0285)	Acc@1 99.219 (99.791)	Acc@5 100.000 (100.000)
Epoch: [107][200/391]	Time 0.1893 Data 0.0021 Loss 0.0193 (0.0289)	Acc@1 100.000 (99.794)	Acc@5 100.000 (100.000)
Epoch: [107][300/391]	Time 0.1891 Data 0.0020 Loss 0.0253 (0.0288)	Acc@1 100.000 (99.769)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9760, Prec@1: 75.19, Prec@5: 92.75
Epoch time: 82s
Epoch: 108  lr: 0.010
Epoch: [108][000/391]	Time 1.1966 Data 0.9887 Loss 0.0332 (0.0332)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [108][100/391]	Time 0.1923 Data 0.0020 Loss 0.0301 (0.0274)	Acc@1 100.000 (99.814)	Acc@5 100.000 (100.000)
Epoch: [108][200/391]	Time 0.1906 Data 0.0020 Loss 0.0245 (0.0276)	Acc@1 100.000 (99.841)	Acc@5 100.000 (100.000)
Epoch: [108][300/391]	Time 0.1902 Data 0.0020 Loss 0.0201 (0.0275)	Acc@1 100.000 (99.829)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9728, Prec@1: 75.15, Prec@5: 92.76
Epoch time: 82s
Epoch: 109  lr: 0.010
Epoch: [109][000/391]	Time 1.1304 Data 0.9231 Loss 0.0249 (0.0249)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [109][100/391]	Time 0.1893 Data 0.0020 Loss 0.0285 (0.0251)	Acc@1 100.000 (99.861)	Acc@5 100.000 (100.000)
Epoch: [109][200/391]	Time 0.1922 Data 0.0022 Loss 0.0226 (0.0256)	Acc@1 100.000 (99.864)	Acc@5 100.000 (100.000)
Epoch: [109][300/391]	Time 0.1914 Data 0.0024 Loss 0.0544 (0.0258)	Acc@1 98.438 (99.849)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9733, Prec@1: 75.30, Prec@5: 92.80
Epoch time: 82s
Saving models
Epoch: 110  lr: 0.010
Epoch: [110][000/391]	Time 1.2241 Data 0.9561 Loss 0.0189 (0.0189)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [110][100/391]	Time 0.1891 Data 0.0020 Loss 0.0378 (0.0255)	Acc@1 100.000 (99.838)	Acc@5 100.000 (100.000)
Epoch: [110][200/391]	Time 0.1920 Data 0.0020 Loss 0.0254 (0.0261)	Acc@1 100.000 (99.821)	Acc@5 100.000 (100.000)
Epoch: [110][300/391]	Time 0.1893 Data 0.0021 Loss 0.0376 (0.0258)	Acc@1 100.000 (99.834)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9679, Prec@1: 75.42, Prec@5: 92.81
Epoch time: 82s
Saving models
opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=0.9, distill='kd', epochs=240, lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
Epoch: [1][000/391]	Time 2.6033 Data 1.1110 Loss 4.8249 (4.8249)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)
Epoch: [1][100/391]	Time 0.1869 Data 0.0020 Loss 4.5503 (5.4163)	Acc@1 3.906 (1.477)	Acc@5 14.062 (6.567)
Epoch: [1][200/391]	Time 0.1884 Data 0.0024 Loss 4.6716 (5.1113)	Acc@1 1.562 (1.559)	Acc@5 6.250 (6.915)
Epoch: [1][300/391]	Time 0.1880 Data 0.0019 Loss 4.4757 (5.0048)	Acc@1 1.562 (1.638)	Acc@5 10.156 (7.008)
Testing the models......
Loss: 4.6647, Prec@1: 1.71, Prec@5: 8.74
Epoch time: 84s
Saving models
Epoch: 2  lr: 0.100
Epoch: [2][000/391]	Time 1.2572 Data 1.0213 Loss 4.6429 (4.6429)	Acc@1 0.781 (0.781)	Acc@5 7.812 (7.812)
Epoch: [2][100/391]	Time 0.1884 Data 0.0020 Loss 4.4470 (4.6985)	Acc@1 6.250 (2.243)	Acc@5 12.500 (9.584)
Epoch: [2][200/391]	Time 0.1911 Data 0.0020 Loss 4.4925 (4.7014)	Acc@1 0.000 (2.437)	Acc@5 8.594 (10.300)
Epoch: [2][300/391]	Time 0.1877 Data 0.0021 Loss 4.5373 (4.6802)	Acc@1 2.344 (2.463)	Acc@5 14.844 (10.582)
Testing the models......
Loss: 4.8322, Prec@1: 3.09, Prec@5: 14.30
Epoch time: 81s
Saving models
Epoch: 3  lr: 0.100
Epoch: [3][000/391]	Time 1.1279 Data 0.8997 Loss 4.3779 (4.3779)	Acc@1 2.344 (2.344)	Acc@5 14.062 (14.062)
Epoch: [3][100/391]	Time 0.1904 Data 0.0022 Loss 4.3758 (4.4700)	Acc@1 3.906 (3.767)	Acc@5 17.969 (16.530)
Epoch: [3][200/391]	Time 0.1885 Data 0.0019 Loss 4.5251 (4.4448)	Acc@1 3.125 (3.949)	Acc@5 19.531 (16.966)
Epoch: [3][300/391]	Time 0.1892 Data 0.0020 Loss 7.2494 (4.4244)	Acc@1 4.688 (4.192)	Acc@5 20.312 (17.862)
Testing the models......
Loss: 4.4300, Prec@1: 6.67, Prec@5: 24.76
Epoch time: 81s
Saving models
Epoch: 4  lr: 0.100
Epoch: [4][000/391]	Time 1.2108 Data 0.9744 Loss 3.9300 (3.9300)	Acc@1 7.812 (7.812)	Acc@5 26.562 (26.562)
Epoch: [4][100/391]	Time 0.1882 Data 0.0022 Loss 4.1978 (4.2454)	Acc@1 7.812 (6.521)	Acc@5 25.000 (24.049)
Epoch: [4][200/391]	Time 0.1889 Data 0.0020 Loss 4.0984 (4.2350)	Acc@1 15.625 (6.880)	Acc@5 32.031 (24.864)
Epoch: [4][300/391]	Time 0.1891 Data 0.0025 Loss 3.9095 (4.2097)	Acc@1 13.281 (7.356)	Acc@5 32.031 (25.649)
Testing the models......
Loss: 4.1500, Prec@1: 9.27, Prec@5: 30.63
Epoch time: 81s
Saving models
Epoch: 5  lr: 0.100
Epoch: [5][000/391]	Time 1.1041 Data 0.9222 Loss 4.2764 (4.2764)	Acc@1 7.812 (7.812)	Acc@5 27.344 (27.344)
Epoch: [5][100/391]	Time 0.1894 Data 0.0020 Loss 4.1363 (4.0742)	Acc@1 8.594 (9.189)	Acc@5 28.125 (29.966)
Epoch: [5][200/391]	Time 0.1893 Data 0.0021 Loss 4.0304 (4.0568)	Acc@1 11.719 (9.803)	Acc@5 29.688 (31.087)
Epoch: [5][300/391]	Time 0.1905 Data 0.0024 Loss 3.7228 (4.0352)	Acc@1 16.406 (10.138)	Acc@5 32.031 (31.943)
Testing the models......
Loss: 3.9130, Prec@1: 14.37, Prec@5: 38.01
Epoch time: 81s
Saving models
Epoch: 6  lr: 0.100
Epoch: [6][000/391]	Time 1.2351 Data 0.9646 Loss 3.7754 (3.7754)	Acc@1 12.500 (12.500)	Acc@5 34.375 (34.375)
Epoch: [6][100/391]	Time 0.1886 Data 0.0019 Loss 3.7793 (3.8305)	Acc@1 8.594 (13.567)	Acc@5 41.406 (38.351)
Epoch: [6][200/391]	Time 0.1895 Data 0.0020 Loss 3.6939 (3.8098)	Acc@1 15.625 (13.880)	Acc@5 47.656 (39.086)
Epoch: [6][300/391]	Time 0.1893 Data 0.0022 Loss 3.3152 (3.7545)	Acc@1 20.312 (14.657)	Acc@5 48.438 (40.352)
Testing the models......
Loss: 3.9401, Prec@1: 17.21, Prec@5: 44.24
Epoch time: 82s
Saving models
Epoch: 7  lr: 0.100
Epoch: [7][000/391]	Time 1.2247 Data 0.9914 Loss 3.4763 (3.4763)	Acc@1 22.656 (22.656)	Acc@5 46.094 (46.094)
Epoch: [7][100/391]	Time 0.1894 Data 0.0026 Loss 3.3035 (3.5133)	Acc@1 16.406 (18.441)	Acc@5 50.000 (45.815)
Epoch: [7][200/391]	Time 0.1939 Data 0.0020 Loss 3.5264 (3.4777)	Acc@1 21.875 (18.983)	Acc@5 46.875 (46.630)
Epoch: [7][300/391]	Time 0.1893 Data 0.0021 Loss 3.1519 (3.4386)	Acc@1 23.438 (19.786)	Acc@5 53.125 (48.027)
Testing the models......
Loss: 3.3563, Prec@1: 23.48, Prec@5: 52.38
Epoch time: 81s
Saving models
Epoch: 8  lr: 0.100
Epoch: [8][000/391]	Time 1.2402 Data 0.9662 Loss 3.4478 (3.4478)	Acc@1 15.625 (15.625)	Acc@5 50.000 (50.000)
Epoch: [8][100/391]	Time 0.1887 Data 0.0021 Loss 3.4508 (3.2160)	Acc@1 23.438 (23.004)	Acc@5 49.219 (53.226)
Epoch: [8][200/391]	Time 0.1896 Data 0.0026 Loss 2.7873 (3.1874)	Acc@1 31.250 (23.768)	Acc@5 57.812 (53.716)
Epoch: [8][300/391]	Time 0.1897 Data 0.0020 Loss 3.1091 (3.1650)	Acc@1 21.094 (24.349)	Acc@5 58.594 (54.446)
Testing the models......
Loss: 3.1839, Prec@1: 27.29, Prec@5: 57.70
Epoch time: 81s
Saving models
Epoch: 9  lr: 0.100
Epoch: [9][000/391]	Time 1.1928 Data 0.9799 Loss 3.1398 (3.1398)	Acc@1 29.688 (29.688)	Acc@5 58.594 (58.594)
Epoch: [9][100/391]	Time 0.1909 Data 0.0022 Loss 2.6246 (2.9283)	Acc@1 36.719 (28.984)	Acc@5 71.875 (59.816)
Epoch: [9][200/391]	Time 0.1892 Data 0.0020 Loss 2.6205 (2.9127)	Acc@1 32.031 (29.291)	Acc@5 65.625 (60.145)
Epoch: [9][300/391]	Time 0.1892 Data 0.0021 Loss 2.7962 (2.8862)	Acc@1 34.375 (29.729)	Acc@5 65.625 (60.647)
Testing the models......
Loss: 2.8517, Prec@1: 32.19, Prec@5: 63.60
Epoch time: 81s
Saving models
Epoch: 10  lr: 0.100
Epoch: [10][000/391]	Time 1.1397 Data 0.9350 Loss 2.6180 (2.6180)	Acc@1 34.375 (34.375)	Acc@5 66.406 (66.406)
Epoch: [10][100/391]	Time 0.1891 Data 0.0019 Loss 2.2979 (2.6536)	Acc@1 39.062 (33.857)	Acc@5 73.438 (66.136)
Epoch: [10][200/391]	Time 0.1891 Data 0.0020 Loss 2.6432 (2.6376)	Acc@1 39.844 (34.391)	Acc@5 70.312 (66.150)
Epoch: [10][300/391]	Time 0.1898 Data 0.0020 Loss 2.4931 (2.6132)	Acc@1 35.938 (34.798)	Acc@5 65.625 (66.692)
Testing the models......
Loss: 2.6307, Prec@1: 35.03, Prec@5: 67.58
Epoch time: 81s
Saving models
Epoch: 11  lr: 0.100
Epoch: [11][000/391]	Time 1.1975 Data 1.0206 Loss 2.1721 (2.1721)	Acc@1 42.188 (42.188)	Acc@5 76.562 (76.562)
Epoch: [11][100/391]	Time 0.1899 Data 0.0020 Loss 2.6520 (2.3868)	Acc@1 35.156 (38.784)	Acc@5 67.969 (71.287)
Epoch: [11][200/391]	Time 0.1887 Data 0.0021 Loss 2.1190 (2.3780)	Acc@1 50.000 (38.810)	Acc@5 74.219 (71.280)
Epoch: [11][300/391]	Time 0.1893 Data 0.0020 Loss 2.3423 (2.3781)	Acc@1 39.844 (38.909)	Acc@5 72.656 (71.356)
Testing the models......
Loss: 2.3619, Prec@1: 39.48, Prec@5: 71.65
Epoch time: 82s
Saving models
Epoch: 12  lr: 0.100
Epoch: [12][000/391]	Time 1.1859 Data 0.9562 Loss 2.2267 (2.2267)	Acc@1 40.625 (40.625)	Acc@5 71.875 (71.875)
Epoch: [12][100/391]	Time 0.1894 Data 0.0021 Loss 2.3199 (2.1979)	Acc@1 39.844 (42.698)	Acc@5 75.000 (74.667)
Epoch: [12][200/391]	Time 0.1896 Data 0.0030 Loss 2.0485 (2.1869)	Acc@1 43.750 (42.988)	Acc@5 75.781 (74.992)
Epoch: [12][300/391]	Time 0.1889 Data 0.0021 Loss 2.0821 (2.1669)	Acc@1 45.312 (43.584)	Acc@5 76.562 (75.441)
Testing the models......
Loss: 2.2976, Prec@1: 41.76, Prec@5: 73.87
Epoch time: 82s
Saving models
Epoch: 13  lr: 0.100
Epoch: [13][000/391]	Time 1.1951 Data 0.9643 Loss 1.9240 (1.9240)	Acc@1 46.875 (46.875)	Acc@5 78.906 (78.906)
Epoch: [13][100/391]	Time 0.1898 Data 0.0020 Loss 2.2383 (2.0257)	Acc@1 37.500 (46.558)	Acc@5 74.219 (77.847)
Epoch: [13][200/391]	Time 0.1889 Data 0.0020 Loss 1.9068 (2.0110)	Acc@1 46.875 (46.514)	Acc@5 85.156 (78.401)
Epoch: [13][300/391]	Time 0.1891 Data 0.0019 Loss 2.1947 (2.0041)	Acc@1 40.625 (46.795)	Acc@5 74.219 (78.587)
Testing the models......
Loss: 2.1342, Prec@1: 44.45, Prec@5: 76.42
Epoch time: 82s
Saving models
Epoch: 14  lr: 0.100
Epoch: [14][000/391]	Time 1.2906 Data 1.0568 Loss 1.8040 (1.8040)	Acc@1 49.219 (49.219)	Acc@5 77.344 (77.344)
Epoch: [14][100/391]	Time 0.1899 Data 0.0020 Loss 1.8163 (1.8357)	Acc@1 53.906 (49.776)	Acc@5 79.688 (80.979)
Epoch: [14][200/391]	Time 0.1909 Data 0.0019 Loss 1.7141 (1.8394)	Acc@1 52.344 (49.763)	Acc@5 85.156 (81.052)
Epoch: [14][300/391]	Time 0.1909 Data 0.0019 Loss 1.7334 (1.8296)	Acc@1 50.000 (49.844)	Acc@5 81.250 (81.201)
Testing the models......
Loss: 1.8836, Prec@1: 49.23, Prec@5: 79.93
Epoch time: 82s
Saving models
Epoch: 15  lr: 0.100
Epoch: [15][000/391]	Time 1.1264 Data 0.9331 Loss 1.6094 (1.6094)	Acc@1 57.031 (57.031)	Acc@5 82.812 (82.812)
Epoch: [15][100/391]	Time 0.1954 Data 0.0020 Loss 1.5820 (1.6604)	Acc@1 56.250 (53.752)	Acc@5 86.719 (84.035)
Epoch: [15][200/391]	Time 0.1903 Data 0.0021 Loss 1.6893 (1.6742)	Acc@1 54.688 (53.141)	Acc@5 82.812 (83.703)
Epoch: [15][300/391]	Time 0.1921 Data 0.0022 Loss 2.0462 (1.6758)	Acc@1 46.094 (53.094)	Acc@5 73.438 (83.506)
Testing the models......
Loss: 1.8396, Prec@1: 50.75, Prec@5: 80.94
Epoch time: 82s
Saving models
Epoch: 16  lr: 0.100
Epoch: [16][000/391]	Time 1.2399 Data 1.0466 Loss 1.4688 (1.4688)	Acc@1 62.500 (62.500)	Acc@5 85.938 (85.938)
Epoch: [16][100/391]	Time 0.1946 Data 0.0023 Loss 1.5898 (1.5396)	Acc@1 52.344 (56.907)	Acc@5 87.500 (85.961)
Epoch: [16][200/391]	Time 0.1901 Data 0.0020 Loss 1.5058 (1.5485)	Acc@1 59.375 (56.592)	Acc@5 83.594 (85.720)
Epoch: [16][300/391]	Time 0.1889 Data 0.0022 Loss 1.3736 (1.5484)	Acc@1 59.375 (56.556)	Acc@5 93.750 (85.740)
Testing the models......
Loss: 1.8175, Prec@1: 51.41, Prec@5: 81.60
Epoch time: 82s
Saving models
Epoch: 17  lr: 0.100
Epoch: [17][000/391]	Time 1.2042 Data 0.9340 Loss 1.4248 (1.4248)	Acc@1 54.688 (54.688)	Acc@5 87.500 (87.500)
Epoch: [17][100/391]	Time 0.1901 Data 0.0019 Loss 1.4669 (1.4407)	Acc@1 58.594 (58.826)	Acc@5 86.719 (87.763)
Epoch: [17][200/391]	Time 0.1894 Data 0.0020 Loss 1.6172 (1.4501)	Acc@1 50.781 (59.087)	Acc@5 88.281 (87.387)
Epoch: [17][300/391]	Time 0.1933 Data 0.0024 Loss 1.5810 (1.4609)	Acc@1 59.375 (58.729)	Acc@5 87.500 (87.235)
Testing the models......
Loss: 1.6579, Prec@1: 54.20, Prec@5: 84.21
Epoch time: 82s
Saving models
Epoch: 18  lr: 0.100
Epoch: [18][000/391]	Time 1.2111 Data 0.9318 Loss 1.2835 (1.2835)	Acc@1 63.281 (63.281)	Acc@5 91.406 (91.406)
Epoch: [18][100/391]	Time 0.1919 Data 0.0020 Loss 1.4561 (1.3629)	Acc@1 64.062 (60.736)	Acc@5 83.594 (88.343)
Epoch: [18][200/391]	Time 0.1894 Data 0.0020 Loss 1.5562 (1.3700)	Acc@1 58.594 (60.662)	Acc@5 85.938 (88.394)
Epoch: [18][300/391]	Time 0.1895 Data 0.0020 Loss 1.4540 (1.3775)	Acc@1 58.594 (60.629)	Acc@5 89.844 (88.224)
Testing the models......
Loss: 1.6880, Prec@1: 54.74, Prec@5: 83.54
Epoch time: 82s
Saving models
Epoch: 19  lr: 0.100
Epoch: [19][000/391]	Time 1.1770 Data 0.9630 Loss 1.2677 (1.2677)	Acc@1 61.719 (61.719)	Acc@5 88.281 (88.281)
Epoch: [19][100/391]	Time 0.1899 Data 0.0021 Loss 1.3824 (1.2778)	Acc@1 61.719 (62.864)	Acc@5 89.062 (89.805)
Epoch: [19][200/391]	Time 0.1892 Data 0.0020 Loss 1.3737 (1.3018)	Acc@1 61.719 (62.360)	Acc@5 88.281 (89.521)
Epoch: [19][300/391]	Time 0.1888 Data 0.0020 Loss 1.4612 (1.3028)	Acc@1 55.469 (62.272)	Acc@5 89.062 (89.439)
Testing the models......
Loss: 1.6221, Prec@1: 55.69, Prec@5: 85.25
Epoch time: 82s
Saving models
Epoch: 20  lr: 0.100
Epoch: [20][000/391]	Time 1.1172 Data 0.9124 Loss 1.3152 (1.3152)	Acc@1 60.156 (60.156)	Acc@5 90.625 (90.625)
Epoch: [20][100/391]	Time 0.1896 Data 0.0024 Loss 1.1991 (1.1941)	Acc@1 65.625 (64.836)	Acc@5 89.062 (90.958)
Epoch: [20][200/391]	Time 0.1893 Data 0.0022 Loss 1.4042 (1.1973)	Acc@1 60.938 (65.015)	Acc@5 88.281 (90.808)
Epoch: [20][300/391]	Time 0.1894 Data 0.0020 Loss 1.3938 (1.2061)	Acc@1 59.375 (64.753)	Acc@5 89.062 (90.669)
Testing the models......
Loss: 1.4849, Prec@1: 59.74, Prec@5: 86.49
Epoch time: 82s
Saving models
Epoch: 21  lr: 0.100
Epoch: [21][000/391]	Time 1.2262 Data 1.0662 Loss 0.9957 (0.9957)	Acc@1 67.969 (67.969)	Acc@5 95.312 (95.312)
Epoch: [21][100/391]	Time 0.1956 Data 0.0026 Loss 0.9624 (1.1217)	Acc@1 67.969 (67.102)	Acc@5 93.750 (92.133)
Epoch: [21][200/391]	Time 0.1899 Data 0.0020 Loss 1.2864 (1.1443)	Acc@1 63.281 (66.430)	Acc@5 90.625 (91.733)
Epoch: [21][300/391]	Time 0.1909 Data 0.0022 Loss 1.0845 (1.1565)	Acc@1 67.188 (66.020)	Acc@5 92.969 (91.528)
Testing the models......
Loss: 1.4747, Prec@1: 59.85, Prec@5: 86.56
Epoch time: 82s
Saving models
Epoch: 22  lr: 0.100
Epoch: [22][000/391]	Time 1.2166 Data 1.0218 Loss 1.2194 (1.2194)	Acc@1 64.844 (64.844)	Acc@5 90.625 (90.625)
Epoch: [22][100/391]	Time 0.1889 Data 0.0021 Loss 0.9427 (1.0640)	Acc@1 71.875 (68.348)	Acc@5 95.312 (92.652)
Epoch: [22][200/391]	Time 0.1894 Data 0.0026 Loss 1.1141 (1.0714)	Acc@1 71.875 (68.012)	Acc@5 88.281 (92.646)
Epoch: [22][300/391]	Time 0.1890 Data 0.0020 Loss 1.1481 (1.0868)	Acc@1 67.969 (67.787)	Acc@5 92.188 (92.395)
Testing the models......
Loss: 1.5042, Prec@1: 59.60, Prec@5: 85.94
Epoch time: 82s
Epoch: 23  lr: 0.100
Epoch: [23][000/391]	Time 1.2606 Data 1.0038 Loss 1.0706 (1.0706)	Acc@1 65.625 (65.625)	Acc@5 94.531 (94.531)
Epoch: [23][100/391]	Time 0.1891 Data 0.0020 Loss 0.9126 (1.0034)	Acc@1 74.219 (70.073)	Acc@5 92.969 (93.479)
Epoch: [23][200/391]	Time 0.1888 Data 0.0020 Loss 0.9771 (1.0230)	Acc@1 71.875 (69.625)	Acc@5 94.531 (93.249)
Epoch: [23][300/391]	Time 0.1891 Data 0.0020 Loss 1.1981 (1.0473)	Acc@1 64.062 (68.914)	Acc@5 92.188 (92.883)
Testing the models......
Loss: 1.5228, Prec@1: 59.71, Prec@5: 86.81
Epoch time: 81s
Epoch: 24  lr: 0.100
Epoch: [24][000/391]	Time 1.1688 Data 0.8893 Loss 0.9550 (0.9550)	Acc@1 71.875 (71.875)	Acc@5 93.750 (93.750)
Epoch: [24][100/391]	Time 0.1893 Data 0.0020 Loss 0.9271 (0.9375)	Acc@1 73.438 (71.759)	Acc@5 95.312 (94.353)
Epoch: [24][200/391]	Time 0.1890 Data 0.0020 Loss 0.9624 (0.9625)	Acc@1 71.094 (71.008)	Acc@5 97.656 (93.913)
Epoch: [24][300/391]	Time 0.1888 Data 0.0020 Loss 1.1256 (0.9863)	Acc@1 70.312 (70.476)	Acc@5 89.844 (93.670)
Testing the models......
Loss: 1.4735, Prec@1: 60.22, Prec@5: 87.26
Epoch time: 81s
Saving models
Epoch: 25  lr: 0.100
Epoch: [25][000/391]	Time 1.1721 Data 0.9688 Loss 0.8448 (0.8448)	Acc@1 76.562 (76.562)	Acc@5 92.969 (92.969)
Epoch: [25][100/391]	Time 0.1887 Data 0.0021 Loss 0.8525 (0.9107)	Acc@1 75.781 (72.502)	Acc@5 95.312 (94.585)
Epoch: [25][200/391]	Time 0.1892 Data 0.0021 Loss 1.0198 (0.9374)	Acc@1 73.438 (71.821)	Acc@5 92.969 (94.384)
Epoch: [25][300/391]	Time 0.1890 Data 0.0021 Loss 0.6814 (0.9413)	Acc@1 80.469 (71.826)	Acc@5 97.656 (94.261)
Testing the models......
Loss: 1.5329, Prec@1: 60.38, Prec@5: 86.38
Epoch time: 81s
Saving models
Epoch: 26  lr: 0.100
Epoch: [26][000/391]	Time 1.1512 Data 0.9420 Loss 0.8635 (0.8635)	Acc@1 72.656 (72.656)	Acc@5 96.094 (96.094)
Epoch: [26][100/391]	Time 0.1890 Data 0.0020 Loss 0.9344 (0.8530)	Acc@1 72.656 (74.188)	Acc@5 92.969 (95.073)
Epoch: [26][200/391]	Time 0.1893 Data 0.0020 Loss 1.2000 (0.8818)	Acc@1 61.719 (73.329)	Acc@5 94.531 (94.644)
Epoch: [26][300/391]	Time 0.1890 Data 0.0020 Loss 0.8800 (0.8946)	Acc@1 72.656 (73.033)	Acc@5 98.438 (94.583)
Testing the models......
Loss: 1.5103, Prec@1: 60.47, Prec@5: 87.04
Epoch time: 82s
Saving models
Epoch: 27  lr: 0.100
Epoch: [27][000/391]	Time 1.1406 Data 0.9228 Loss 0.7350 (0.7350)	Acc@1 77.344 (77.344)	Acc@5 98.438 (98.438)
Epoch: [27][100/391]	Time 0.1906 Data 0.0020 Loss 0.8399 (0.8093)	Acc@1 70.312 (75.193)	Acc@5 96.875 (95.722)
Epoch: [27][200/391]	Time 0.1899 Data 0.0020 Loss 0.6962 (0.8357)	Acc@1 75.000 (74.343)	Acc@5 97.656 (95.382)
Epoch: [27][300/391]	Time 0.1891 Data 0.0020 Loss 0.7737 (0.8571)	Acc@1 77.344 (73.970)	Acc@5 95.312 (95.094)
Testing the models......
Loss: 1.5581, Prec@1: 59.55, Prec@5: 86.11
Epoch time: 81s
Epoch: 28  lr: 0.100
Epoch: [28][000/391]	Time 1.1620 Data 0.9603 Loss 0.7979 (0.7979)	Acc@1 72.656 (72.656)	Acc@5 95.312 (95.312)
Epoch: [28][100/391]	Time 0.1899 Data 0.0020 Loss 0.6271 (0.7489)	Acc@1 81.250 (76.617)	Acc@5 98.438 (96.295)
Epoch: [28][200/391]	Time 0.1902 Data 0.0022 Loss 0.9855 (0.7974)	Acc@1 70.312 (75.470)	Acc@5 91.406 (95.709)
Epoch: [28][300/391]	Time 0.1890 Data 0.0020 Loss 1.0338 (0.8192)	Acc@1 69.531 (74.883)	Acc@5 92.969 (95.450)
Testing the models......
Loss: 1.5488, Prec@1: 60.79, Prec@5: 86.68
Epoch time: 82s
Saving models
Epoch: 29  lr: 0.100
Epoch: [29][000/391]	Time 1.1132 Data 0.9137 Loss 0.7248 (0.7248)	Acc@1 76.562 (76.562)	Acc@5 97.656 (97.656)
Epoch: [29][100/391]	Time 0.1893 Data 0.0020 Loss 0.8842 (0.7316)	Acc@1 73.438 (77.158)	Acc@5 93.750 (96.597)
Epoch: [29][200/391]	Time 0.1893 Data 0.0020 Loss 0.8842 (0.7598)	Acc@1 74.219 (76.426)	Acc@5 95.312 (96.377)
Epoch: [29][300/391]	Time 0.1905 Data 0.0026 Loss 0.8532 (0.7820)	Acc@1 77.344 (75.934)	Acc@5 91.406 (96.096)
Testing the models......
Loss: 1.4663, Prec@1: 62.25, Prec@5: 88.12
Epoch time: 81s
Saving models
Epoch: 30  lr: 0.100
Epoch: [30][000/391]	Time 1.1625 Data 0.9447 Loss 0.7137 (0.7137)	Acc@1 79.688 (79.688)	Acc@5 96.875 (96.875)
Epoch: [30][100/391]	Time 0.1889 Data 0.0020 Loss 0.6099 (0.7102)	Acc@1 84.375 (78.117)	Acc@5 96.094 (96.612)
Epoch: [30][200/391]	Time 0.1894 Data 0.0021 Loss 0.5736 (0.7273)	Acc@1 81.250 (77.569)	Acc@5 97.656 (96.463)
Epoch: [30][300/391]	Time 0.1886 Data 0.0021 Loss 0.8442 (0.7504)	Acc@1 76.562 (76.843)	Acc@5 94.531 (96.239)
Testing the models......
Loss: 1.4298, Prec@1: 63.56, Prec@5: 87.91
Epoch time: 82s
Saving models
Epoch: 31  lr: 0.100
Epoch: [31][000/391]	Time 1.1890 Data 0.9798 Loss 0.6219 (0.6219)	Acc@1 82.812 (82.812)	Acc@5 97.656 (97.656)
Epoch: [31][100/391]	Time 0.1915 Data 0.0020 Loss 0.8197 (0.6719)	Acc@1 72.656 (79.200)	Acc@5 96.094 (97.153)
Epoch: [31][200/391]	Time 0.1891 Data 0.0020 Loss 0.6085 (0.7031)	Acc@1 77.344 (78.249)	Acc@5 99.219 (96.786)
Epoch: [31][300/391]	Time 0.1895 Data 0.0020 Loss 0.7678 (0.7180)	Acc@1 78.906 (77.819)	Acc@5 92.969 (96.647)
Testing the models......
Loss: 1.5193, Prec@1: 61.70, Prec@5: 87.80
Epoch time: 82s
Epoch: 32  lr: 0.100
Epoch: [32][000/391]	Time 1.1275 Data 0.9700 Loss 0.9362 (0.9362)	Acc@1 72.656 (72.656)	Acc@5 92.188 (92.188)
Epoch: [32][100/391]	Time 0.1899 Data 0.0021 Loss 0.5906 (0.6393)	Acc@1 80.469 (80.113)	Acc@5 97.656 (97.107)
Epoch: [32][200/391]	Time 0.1908 Data 0.0023 Loss 0.4460 (0.6620)	Acc@1 89.062 (79.427)	Acc@5 99.219 (96.976)
Epoch: [32][300/391]	Time 0.1905 Data 0.0020 Loss 0.5771 (0.6858)	Acc@1 78.125 (78.813)	Acc@5 99.219 (96.836)
Testing the models......
Loss: 1.4408, Prec@1: 63.03, Prec@5: 88.43
Epoch time: 81s
Epoch: 33  lr: 0.100
Epoch: [33][000/391]	Time 1.2331 Data 1.0176 Loss 0.5140 (0.5140)	Acc@1 84.375 (84.375)	Acc@5 97.656 (97.656)
Epoch: [33][100/391]	Time 0.1889 Data 0.0020 Loss 0.6465 (0.6261)	Acc@1 82.031 (80.616)	Acc@5 95.312 (97.068)
Epoch: [33][200/391]	Time 0.1932 Data 0.0019 Loss 0.7313 (0.6532)	Acc@1 76.562 (79.610)	Acc@5 95.312 (97.030)
Epoch: [33][300/391]	Time 0.1893 Data 0.0024 Loss 0.7749 (0.6835)	Acc@1 72.656 (78.727)	Acc@5 95.312 (96.870)
Testing the models......
Loss: 1.4676, Prec@1: 63.52, Prec@5: 87.91
Epoch time: 82s
Epoch: 34  lr: 0.100
Epoch: [34][000/391]	Time 1.1503 Data 0.9487 Loss 0.5080 (0.5080)	Acc@1 82.812 (82.812)	Acc@5 100.000 (100.000)
Epoch: [34][100/391]	Time 0.1905 Data 0.0019 Loss 0.6320 (0.6011)	Acc@1 78.125 (81.095)	Acc@5 97.656 (97.780)
Epoch: [34][200/391]	Time 0.1892 Data 0.0020 Loss 0.8256 (0.6256)	Acc@1 75.781 (80.368)	Acc@5 96.094 (97.524)
Epoch: [34][300/391]	Time 0.1889 Data 0.0019 Loss 0.7316 (0.6480)	Acc@1 75.781 (79.786)	Acc@5 97.656 (97.303)
Testing the models......
Loss: 1.5213, Prec@1: 62.14, Prec@5: 87.85
Epoch time: 81s
Epoch: 35  lr: 0.100
Epoch: [35][000/391]	Time 1.1691 Data 0.9592 Loss 0.5149 (0.5149)	Acc@1 81.250 (81.250)	Acc@5 99.219 (99.219)
Epoch: [35][100/391]	Time 0.1896 Data 0.0020 Loss 0.5289 (0.5731)	Acc@1 83.594 (81.544)	Acc@5 97.656 (98.097)
Epoch: [35][200/391]	Time 0.1891 Data 0.0019 Loss 0.8564 (0.6024)	Acc@1 71.875 (80.718)	Acc@5 95.312 (97.909)
Epoch: [35][300/391]	Time 0.1892 Data 0.0021 Loss 0.9094 (0.6173)	Acc@1 71.875 (80.308)	Acc@5 94.531 (97.693)
Testing the models......
Loss: 1.4309, Prec@1: 64.48, Prec@5: 88.27
Epoch time: 81s
Saving models
Epoch: 36  lr: 0.100
Epoch: [36][000/391]	Time 1.2144 Data 1.0001 Loss 0.4685 (0.4685)	Acc@1 86.719 (86.719)	Acc@5 97.656 (97.656)
Epoch: [36][100/391]	Time 0.1893 Data 0.0020 Loss 0.5288 (0.5337)	Acc@1 82.031 (83.269)	Acc@5 100.000 (98.151)
Epoch: [36][200/391]	Time 0.1889 Data 0.0021 Loss 0.5165 (0.5648)	Acc@1 87.500 (82.288)	Acc@5 96.875 (97.812)
Epoch: [36][300/391]	Time 0.1903 Data 0.0020 Loss 0.7077 (0.5865)	Acc@1 75.781 (81.603)	Acc@5 97.656 (97.703)
Testing the models......
Loss: 1.5177, Prec@1: 62.99, Prec@5: 87.53
Epoch time: 81s
Epoch: 37  lr: 0.100
Epoch: [37][000/391]	Time 1.1645 Data 0.9370 Loss 0.7116 (0.7116)	Acc@1 75.000 (75.000)	Acc@5 96.094 (96.094)
Epoch: [37][100/391]	Time 0.1912 Data 0.0020 Loss 0.3945 (0.5249)	Acc@1 87.500 (83.601)	Acc@5 99.219 (98.260)
Epoch: [37][200/391]	Time 0.1894 Data 0.0020 Loss 0.5128 (0.5506)	Acc@1 86.719 (82.906)	Acc@5 98.438 (98.041)
Epoch: [37][300/391]	Time 0.1897 Data 0.0020 Loss 0.6428 (0.5817)	Acc@1 82.812 (81.969)	Acc@5 96.875 (97.861)
Testing the models......
Loss: 1.4590, Prec@1: 63.70, Prec@5: 88.00
Epoch time: 82s
Epoch: 38  lr: 0.100
Epoch: [38][000/391]	Time 1.1701 Data 0.9544 Loss 0.8811 (0.8811)	Acc@1 71.875 (71.875)	Acc@5 95.312 (95.312)
Epoch: [38][100/391]	Time 0.1941 Data 0.0027 Loss 0.4577 (0.5023)	Acc@1 85.156 (84.182)	Acc@5 100.000 (98.345)
Epoch: [38][200/391]	Time 0.1930 Data 0.0020 Loss 0.5587 (0.5254)	Acc@1 84.375 (83.567)	Acc@5 99.219 (98.239)
Epoch: [38][300/391]	Time 0.1894 Data 0.0020 Loss 0.6839 (0.5500)	Acc@1 76.562 (82.810)	Acc@5 98.438 (98.048)
Testing the models......
Loss: 1.5031, Prec@1: 63.60, Prec@5: 88.26
Epoch time: 82s
Epoch: 39  lr: 0.100
Epoch: [39][000/391]	Time 1.2056 Data 0.9971 Loss 0.6648 (0.6648)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
Epoch: [39][100/391]	Time 0.1892 Data 0.0021 Loss 0.4957 (0.4990)	Acc@1 85.156 (84.336)	Acc@5 97.656 (98.376)
Epoch: [39][200/391]	Time 0.1889 Data 0.0021 Loss 0.4886 (0.5248)	Acc@1 85.156 (83.617)	Acc@5 99.219 (98.146)
Epoch: [39][300/391]	Time 0.1894 Data 0.0025 Loss 0.5144 (0.5404)	Acc@1 82.031 (83.054)	Acc@5 98.438 (98.059)
Testing the models......
Loss: 1.4680, Prec@1: 64.49, Prec@5: 88.47
Epoch time: 81s
Saving models
Epoch: 40  lr: 0.100
Epoch: [40][000/391]	Time 1.2297 Data 1.0341 Loss 0.5261 (0.5261)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [40][100/391]	Time 0.1892 Data 0.0020 Loss 0.5943 (0.4811)	Acc@1 82.812 (84.723)	Acc@5 96.094 (98.507)
Epoch: [40][200/391]	Time 0.1893 Data 0.0020 Loss 0.4013 (0.5062)	Acc@1 85.938 (84.010)	Acc@5 99.219 (98.441)
Epoch: [40][300/391]	Time 0.1891 Data 0.0021 Loss 0.4289 (0.5285)	Acc@1 85.156 (83.313)	Acc@5 99.219 (98.243)
Testing the models......
Loss: 1.5682, Prec@1: 62.79, Prec@5: 87.46
Epoch time: 82s
Epoch: 41  lr: 0.100
Epoch: [41][000/391]	Time 1.1906 Data 0.9111 Loss 0.4306 (0.4306)	Acc@1 85.938 (85.938)	Acc@5 97.656 (97.656)
Epoch: [41][100/391]	Time 0.1895 Data 0.0020 Loss 0.5234 (0.4688)	Acc@1 78.125 (85.071)	Acc@5 96.875 (98.600)
Epoch: [41][200/391]	Time 0.1890 Data 0.0024 Loss 0.5143 (0.4883)	Acc@1 85.938 (84.495)	Acc@5 98.438 (98.504)
Epoch: [41][300/391]	Time 0.1890 Data 0.0019 Loss 0.7247 (0.5117)	Acc@1 79.688 (83.838)	Acc@5 96.094 (98.380)
Testing the models......
Loss: 1.5269, Prec@1: 64.27, Prec@5: 87.96
Epoch time: 81s
Epoch: 42  lr: 0.100
Epoch: [42][000/391]	Time 1.1186 Data 0.8992 Loss 0.4693 (0.4693)	Acc@1 86.719 (86.719)	Acc@5 99.219 (99.219)
Epoch: [42][100/391]	Time 0.1890 Data 0.0020 Loss 0.4826 (0.4728)	Acc@1 87.500 (85.071)	Acc@5 98.438 (98.716)
Epoch: [42][200/391]	Time 0.1890 Data 0.0019 Loss 0.6743 (0.4874)	Acc@1 81.250 (84.589)	Acc@5 97.656 (98.570)
Epoch: [42][300/391]	Time 0.1893 Data 0.0025 Loss 0.5927 (0.5005)	Acc@1 85.156 (84.269)	Acc@5 96.094 (98.445)
Testing the models......
Loss: 1.6363, Prec@1: 62.55, Prec@5: 86.90
Epoch time: 81s
Epoch: 43  lr: 0.100
Epoch: [43][000/391]	Time 1.1874 Data 0.9083 Loss 0.4850 (0.4850)	Acc@1 84.375 (84.375)	Acc@5 98.438 (98.438)
Epoch: [43][100/391]	Time 0.1916 Data 0.0020 Loss 0.3998 (0.4555)	Acc@1 85.156 (85.497)	Acc@5 98.438 (98.708)
Epoch: [43][200/391]	Time 0.1894 Data 0.0020 Loss 0.4926 (0.4737)	Acc@1 85.156 (84.911)	Acc@5 98.438 (98.593)
Epoch: [43][300/391]	Time 0.1925 Data 0.0019 Loss 0.6426 (0.4958)	Acc@1 80.469 (84.222)	Acc@5 99.219 (98.482)
Testing the models......
Loss: 1.5181, Prec@1: 63.99, Prec@5: 87.83
Epoch time: 82s
Epoch: 44  lr: 0.100
Epoch: [44][000/391]	Time 1.2387 Data 1.0403 Loss 0.5099 (0.5099)	Acc@1 81.250 (81.250)	Acc@5 98.438 (98.438)
Epoch: [44][100/391]	Time 0.1893 Data 0.0020 Loss 0.3536 (0.4359)	Acc@1 90.625 (85.999)	Acc@5 99.219 (98.894)
Epoch: [44][200/391]	Time 0.1888 Data 0.0021 Loss 0.4008 (0.4621)	Acc@1 86.719 (85.141)	Acc@5 98.438 (98.799)
Epoch: [44][300/391]	Time 0.1899 Data 0.0020 Loss 0.4858 (0.4776)	Acc@1 86.719 (84.868)	Acc@5 96.875 (98.645)
Testing the models......
Loss: 1.5578, Prec@1: 63.92, Prec@5: 87.85
Epoch time: 81s
Epoch: 45  lr: 0.100
Epoch: [45][000/391]	Time 1.2580 Data 0.9975 Loss 0.3405 (0.3405)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [45][100/391]	Time 0.1978 Data 0.0021 Loss 0.4757 (0.4262)	Acc@1 84.375 (86.757)	Acc@5 98.438 (98.940)
Epoch: [45][200/391]	Time 0.1895 Data 0.0019 Loss 0.5314 (0.4393)	Acc@1 83.594 (86.443)	Acc@5 100.000 (98.842)
Epoch: [45][300/391]	Time 0.1889 Data 0.0020 Loss 0.5874 (0.4607)	Acc@1 80.469 (85.616)	Acc@5 96.875 (98.663)
Testing the models......
Loss: 1.5063, Prec@1: 64.06, Prec@5: 87.95
Epoch time: 82s
Epoch: 46  lr: 0.100
Epoch: [46][000/391]	Time 1.1993 Data 0.9754 Loss 0.4099 (0.4099)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [46][100/391]	Time 0.1898 Data 0.0030 Loss 0.6174 (0.4133)	Acc@1 85.156 (86.904)	Acc@5 99.219 (98.971)
Epoch: [46][200/391]	Time 0.1890 Data 0.0020 Loss 0.4041 (0.4149)	Acc@1 87.500 (86.793)	Acc@5 99.219 (98.947)
Epoch: [46][300/391]	Time 0.1889 Data 0.0020 Loss 0.6176 (0.4412)	Acc@1 80.469 (86.015)	Acc@5 97.656 (98.829)
Testing the models......
Loss: 1.5069, Prec@1: 64.15, Prec@5: 88.36
Epoch time: 81s
Epoch: 47  lr: 0.100
Epoch: [47][000/391]	Time 1.1970 Data 0.9779 Loss 0.3716 (0.3716)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [47][100/391]	Time 0.1890 Data 0.0020 Loss 0.3115 (0.4007)	Acc@1 89.062 (87.345)	Acc@5 100.000 (99.141)
Epoch: [47][200/391]	Time 0.1897 Data 0.0021 Loss 0.5178 (0.4195)	Acc@1 83.594 (86.785)	Acc@5 99.219 (99.024)
Epoch: [47][300/391]	Time 0.1889 Data 0.0028 Loss 0.4851 (0.4370)	Acc@1 85.156 (86.187)	Acc@5 99.219 (98.905)
Testing the models......
Loss: 1.6043, Prec@1: 63.12, Prec@5: 87.20
Epoch time: 82s
Epoch: 48  lr: 0.100
Epoch: [48][000/391]	Time 1.1525 Data 0.9535 Loss 0.4327 (0.4327)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [48][100/391]	Time 0.1889 Data 0.0019 Loss 0.3016 (0.4008)	Acc@1 89.062 (87.361)	Acc@5 100.000 (99.141)
Epoch: [48][200/391]	Time 0.1890 Data 0.0020 Loss 0.4091 (0.4129)	Acc@1 85.938 (87.002)	Acc@5 100.000 (99.153)
Epoch: [48][300/391]	Time 0.1896 Data 0.0020 Loss 0.4579 (0.4300)	Acc@1 85.156 (86.464)	Acc@5 98.438 (98.980)
Testing the models......
Loss: 1.5340, Prec@1: 64.34, Prec@5: 88.11
Epoch time: 81s
Epoch: 49  lr: 0.100
Epoch: [49][000/391]	Time 1.1829 Data 0.9575 Loss 0.3039 (0.3039)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [49][100/391]	Time 0.1906 Data 0.0019 Loss 0.3341 (0.3785)	Acc@1 89.844 (88.003)	Acc@5 99.219 (99.157)
Epoch: [49][200/391]	Time 0.1892 Data 0.0021 Loss 0.5236 (0.4053)	Acc@1 85.938 (87.247)	Acc@5 98.438 (99.024)
Epoch: [49][300/391]	Time 0.1887 Data 0.0024 Loss 0.4133 (0.4227)	Acc@1 89.062 (86.669)	Acc@5 99.219 (98.910)
Testing the models......
Loss: 1.6086, Prec@1: 63.22, Prec@5: 87.30
Epoch time: 82s
Epoch: 50  lr: 0.100
Epoch: [50][000/391]	Time 1.1724 Data 1.0116 Loss 0.3870 (0.3870)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [50][100/391]	Time 0.1888 Data 0.0030 Loss 0.2411 (0.3905)	Acc@1 92.188 (87.554)	Acc@5 100.000 (99.203)
Epoch: [50][200/391]	Time 0.1894 Data 0.0030 Loss 0.4947 (0.3962)	Acc@1 87.500 (87.414)	Acc@5 98.438 (99.153)
Epoch: [50][300/391]	Time 0.1886 Data 0.0020 Loss 0.5472 (0.4125)	Acc@1 81.250 (86.885)	Acc@5 99.219 (99.055)
Testing the models......
Loss: 1.5096, Prec@1: 64.55, Prec@5: 88.13
Epoch time: 81s
Saving models
Epoch: 51  lr: 0.100
Epoch: [51][000/391]	Time 1.1734 Data 0.9373 Loss 0.4600 (0.4600)	Acc@1 85.938 (85.938)	Acc@5 97.656 (97.656)
Epoch: [51][100/391]	Time 0.1896 Data 0.0021 Loss 0.3552 (0.3642)	Acc@1 90.625 (88.637)	Acc@5 99.219 (99.211)
Epoch: [51][200/391]	Time 0.1893 Data 0.0021 Loss 0.5473 (0.3763)	Acc@1 86.719 (88.180)	Acc@5 99.219 (99.125)
Epoch: [51][300/391]	Time 0.1894 Data 0.0021 Loss 0.3263 (0.4014)	Acc@1 91.406 (87.352)	Acc@5 98.438 (99.055)
Testing the models......
Loss: 1.5195, Prec@1: 65.21, Prec@5: 88.15
Epoch time: 82s
Saving models
Epoch: 52  lr: 0.100
Epoch: [52][000/391]	Time 1.2105 Data 0.9738 Loss 0.3013 (0.3013)	Acc@1 92.969 (92.969)	Acc@5 98.438 (98.438)
Epoch: [52][100/391]	Time 0.1891 Data 0.0020 Loss 0.4683 (0.3786)	Acc@1 84.375 (88.065)	Acc@5 99.219 (99.126)
Epoch: [52][200/391]	Time 0.1894 Data 0.0021 Loss 0.4798 (0.3852)	Acc@1 85.938 (87.900)	Acc@5 100.000 (99.106)
Epoch: [52][300/391]	Time 0.1888 Data 0.0020 Loss 0.4553 (0.4049)	Acc@1 86.719 (87.235)	Acc@5 97.656 (99.076)
Testing the models......
Loss: 1.5241, Prec@1: 65.24, Prec@5: 88.48
Epoch time: 82s
Saving models
Epoch: 53  lr: 0.100
Epoch: [53][000/391]	Time 1.2054 Data 0.9342 Loss 0.3518 (0.3518)	Acc@1 89.844 (89.844)	Acc@5 98.438 (98.438)
Epoch: [53][100/391]	Time 0.1893 Data 0.0019 Loss 0.4091 (0.3446)	Acc@1 86.719 (89.016)	Acc@5 98.438 (99.327)
Epoch: [53][200/391]	Time 0.1962 Data 0.0020 Loss 0.3882 (0.3734)	Acc@1 87.500 (88.289)	Acc@5 97.656 (99.164)
Epoch: [53][300/391]	Time 0.1894 Data 0.0020 Loss 0.4884 (0.3865)	Acc@1 83.594 (87.830)	Acc@5 98.438 (99.084)
Testing the models......
Loss: 1.6364, Prec@1: 63.07, Prec@5: 87.14
Epoch time: 81s
Epoch: 54  lr: 0.100
Epoch: [54][000/391]	Time 1.1804 Data 0.9668 Loss 0.3004 (0.3004)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [54][100/391]	Time 0.1894 Data 0.0021 Loss 0.4444 (0.3640)	Acc@1 86.719 (88.529)	Acc@5 98.438 (99.172)
Epoch: [54][200/391]	Time 0.1894 Data 0.0020 Loss 0.5521 (0.3551)	Acc@1 85.156 (88.697)	Acc@5 98.438 (99.219)
Epoch: [54][300/391]	Time 0.1898 Data 0.0020 Loss 0.4974 (0.3816)	Acc@1 81.250 (87.858)	Acc@5 98.438 (99.146)
Testing the models......
Loss: 1.6929, Prec@1: 63.27, Prec@5: 86.59
Epoch time: 82s
Epoch: 55  lr: 0.100
Epoch: [55][000/391]	Time 1.2665 Data 1.0198 Loss 0.3283 (0.3283)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [55][100/391]	Time 0.1902 Data 0.0019 Loss 0.2571 (0.3484)	Acc@1 90.625 (88.900)	Acc@5 100.000 (99.327)
Epoch: [55][200/391]	Time 0.1920 Data 0.0021 Loss 0.3933 (0.3709)	Acc@1 86.719 (88.207)	Acc@5 98.438 (99.203)
Epoch: [55][300/391]	Time 0.1892 Data 0.0021 Loss 0.4463 (0.3860)	Acc@1 85.938 (87.752)	Acc@5 97.656 (99.110)
Testing the models......
Loss: 1.5630, Prec@1: 64.37, Prec@5: 87.79
Epoch time: 82s
Epoch: 56  lr: 0.100
Epoch: [56][000/391]	Time 1.1858 Data 0.9853 Loss 0.5022 (0.5022)	Acc@1 83.594 (83.594)	Acc@5 97.656 (97.656)
Epoch: [56][100/391]	Time 0.1892 Data 0.0020 Loss 0.2715 (0.3660)	Acc@1 91.406 (88.297)	Acc@5 100.000 (99.165)
Epoch: [56][200/391]	Time 0.1891 Data 0.0020 Loss 0.3917 (0.3640)	Acc@1 85.938 (88.561)	Acc@5 98.438 (99.215)
Epoch: [56][300/391]	Time 0.1893 Data 0.0024 Loss 0.3977 (0.3802)	Acc@1 88.281 (87.970)	Acc@5 99.219 (99.164)
Testing the models......
Loss: 1.5650, Prec@1: 64.91, Prec@5: 88.33
Epoch time: 82s
Epoch: 57  lr: 0.100
Epoch: [57][000/391]	Time 1.1972 Data 0.9835 Loss 0.2848 (0.2848)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [57][100/391]	Time 0.1888 Data 0.0020 Loss 0.3334 (0.3341)	Acc@1 88.281 (89.318)	Acc@5 99.219 (99.389)
Epoch: [57][200/391]	Time 0.1910 Data 0.0020 Loss 0.4340 (0.3516)	Acc@1 87.500 (88.798)	Acc@5 99.219 (99.273)
Epoch: [57][300/391]	Time 0.1917 Data 0.0020 Loss 0.3641 (0.3668)	Acc@1 86.719 (88.284)	Acc@5 100.000 (99.190)
Testing the models......
Loss: 1.6169, Prec@1: 63.85, Prec@5: 87.15
Epoch time: 82s
Epoch: 58  lr: 0.100
Epoch: [58][000/391]	Time 1.1818 Data 0.9637 Loss 0.3007 (0.3007)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [58][100/391]	Time 0.1885 Data 0.0020 Loss 0.3225 (0.3356)	Acc@1 89.062 (89.349)	Acc@5 100.000 (99.343)
Epoch: [58][200/391]	Time 0.1899 Data 0.0021 Loss 0.3538 (0.3408)	Acc@1 89.844 (89.381)	Acc@5 98.438 (99.300)
Epoch: [58][300/391]	Time 0.1891 Data 0.0022 Loss 0.3560 (0.3539)	Acc@1 89.062 (88.948)	Acc@5 99.219 (99.258)
Testing the models......
Loss: 1.5381, Prec@1: 64.98, Prec@5: 88.34
Epoch time: 82s
Epoch: 59  lr: 0.100
Epoch: [59][000/391]	Time 1.2033 Data 0.9281 Loss 0.3536 (0.3536)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [59][100/391]	Time 0.1916 Data 0.0020 Loss 0.1960 (0.3077)	Acc@1 92.969 (90.145)	Acc@5 100.000 (99.513)
Epoch: [59][200/391]	Time 0.1939 Data 0.0025 Loss 0.3936 (0.3235)	Acc@1 87.500 (89.754)	Acc@5 99.219 (99.464)
Epoch: [59][300/391]	Time 0.1933 Data 0.0025 Loss 0.6102 (0.3433)	Acc@1 78.906 (89.047)	Acc@5 99.219 (99.387)
Testing the models......
Loss: 1.5424, Prec@1: 64.73, Prec@5: 88.14
Epoch time: 82s
Epoch: 60  lr: 0.100
Epoch: [60][000/391]	Time 1.2221 Data 1.0340 Loss 0.3354 (0.3354)	Acc@1 89.844 (89.844)	Acc@5 97.656 (97.656)
Epoch: [60][100/391]	Time 0.1888 Data 0.0020 Loss 0.3393 (0.3215)	Acc@1 89.062 (89.735)	Acc@5 99.219 (99.389)
Epoch: [60][200/391]	Time 0.1899 Data 0.0021 Loss 0.2675 (0.3351)	Acc@1 94.531 (89.412)	Acc@5 99.219 (99.347)
Epoch: [60][300/391]	Time 0.1906 Data 0.0024 Loss 0.3011 (0.3544)	Acc@1 89.062 (88.899)	Acc@5 100.000 (99.252)
Testing the models......
Loss: 1.4962, Prec@1: 65.22, Prec@5: 88.18
Epoch time: 81s
Epoch: 61  lr: 0.100
Epoch: [61][000/391]	Time 1.1505 Data 0.9887 Loss 0.3797 (0.3797)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [61][100/391]	Time 0.1913 Data 0.0019 Loss 0.3363 (0.3225)	Acc@1 89.062 (89.921)	Acc@5 98.438 (99.466)
Epoch: [61][200/391]	Time 0.1897 Data 0.0026 Loss 0.3067 (0.3333)	Acc@1 91.406 (89.443)	Acc@5 100.000 (99.429)
Epoch: [61][300/391]	Time 0.1903 Data 0.0020 Loss 0.4483 (0.3556)	Acc@1 85.156 (88.751)	Acc@5 98.438 (99.325)
Testing the models......
Loss: 1.5293, Prec@1: 65.47, Prec@5: 88.10
Epoch time: 82s
Saving models
Epoch: 62  lr: 0.100
Epoch: [62][000/391]	Time 1.1557 Data 0.9563 Loss 0.1813 (0.1813)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [62][100/391]	Time 0.1890 Data 0.0019 Loss 0.2191 (0.3179)	Acc@1 95.312 (90.084)	Acc@5 100.000 (99.598)
Epoch: [62][200/391]	Time 0.1894 Data 0.0028 Loss 0.4012 (0.3269)	Acc@1 87.500 (89.778)	Acc@5 99.219 (99.468)
Epoch: [62][300/391]	Time 0.1889 Data 0.0020 Loss 0.3713 (0.3463)	Acc@1 87.500 (89.127)	Acc@5 99.219 (99.297)
Testing the models......
Loss: 1.5690, Prec@1: 65.50, Prec@5: 88.59
Epoch time: 81s
Saving models
Epoch: 63  lr: 0.100
Epoch: [63][000/391]	Time 1.1984 Data 0.9898 Loss 0.3079 (0.3079)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [63][100/391]	Time 0.1889 Data 0.0021 Loss 0.3353 (0.3254)	Acc@1 89.844 (89.968)	Acc@5 100.000 (99.389)
Epoch: [63][200/391]	Time 0.1895 Data 0.0022 Loss 0.4769 (0.3330)	Acc@1 81.250 (89.595)	Acc@5 100.000 (99.343)
Epoch: [63][300/391]	Time 0.1887 Data 0.0020 Loss 0.4366 (0.3474)	Acc@1 86.719 (89.075)	Acc@5 98.438 (99.278)
Testing the models......
Loss: 1.6585, Prec@1: 63.92, Prec@5: 87.35
Epoch time: 82s
Epoch: 64  lr: 0.100
Epoch: [64][000/391]	Time 1.1811 Data 0.9699 Loss 0.3569 (0.3569)	Acc@1 83.594 (83.594)	Acc@5 100.000 (100.000)
Epoch: [64][100/391]	Time 0.1890 Data 0.0021 Loss 0.3280 (0.3327)	Acc@1 89.844 (89.186)	Acc@5 98.438 (99.389)
Epoch: [64][200/391]	Time 0.1892 Data 0.0020 Loss 0.4858 (0.3491)	Acc@1 85.156 (88.899)	Acc@5 99.219 (99.293)
Epoch: [64][300/391]	Time 0.1896 Data 0.0021 Loss 0.3497 (0.3561)	Acc@1 88.281 (88.595)	Acc@5 100.000 (99.247)
Testing the models......
Loss: 1.5097, Prec@1: 66.21, Prec@5: 88.63
Epoch time: 81s
Saving models
Epoch: 65  lr: 0.100
Epoch: [65][000/391]	Time 1.1336 Data 0.9015 Loss 0.2023 (0.2023)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [65][100/391]	Time 0.1949 Data 0.0025 Loss 0.3769 (0.3000)	Acc@1 92.969 (90.331)	Acc@5 100.000 (99.590)
Epoch: [65][200/391]	Time 0.1904 Data 0.0021 Loss 0.4934 (0.3125)	Acc@1 80.469 (90.007)	Acc@5 99.219 (99.471)
Epoch: [65][300/391]	Time 0.1917 Data 0.0021 Loss 0.4244 (0.3363)	Acc@1 88.281 (89.332)	Acc@5 99.219 (99.346)
Testing the models......
Loss: 1.7978, Prec@1: 61.89, Prec@5: 86.39
Epoch time: 82s
Epoch: 66  lr: 0.100
Epoch: [66][000/391]	Time 1.2289 Data 0.9637 Loss 0.3505 (0.3505)	Acc@1 89.844 (89.844)	Acc@5 97.656 (97.656)
Epoch: [66][100/391]	Time 0.1891 Data 0.0021 Loss 0.2856 (0.3223)	Acc@1 92.969 (89.867)	Acc@5 99.219 (99.358)
Epoch: [66][200/391]	Time 0.1893 Data 0.0025 Loss 0.4852 (0.3273)	Acc@1 82.031 (89.712)	Acc@5 100.000 (99.331)
Epoch: [66][300/391]	Time 0.1893 Data 0.0020 Loss 0.5506 (0.3416)	Acc@1 86.719 (89.200)	Acc@5 96.094 (99.250)
Testing the models......
Loss: 1.6903, Prec@1: 62.75, Prec@5: 87.06
Epoch time: 81s
Epoch: 67  lr: 0.100
Epoch: [67][000/391]	Time 1.2568 Data 1.0556 Loss 0.2496 (0.2496)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [67][100/391]	Time 0.1892 Data 0.0020 Loss 0.3348 (0.3292)	Acc@1 89.062 (89.442)	Acc@5 100.000 (99.327)
Epoch: [67][200/391]	Time 0.1893 Data 0.0020 Loss 0.2572 (0.3370)	Acc@1 90.625 (89.039)	Acc@5 100.000 (99.398)
Epoch: [67][300/391]	Time 0.1897 Data 0.0030 Loss 0.4957 (0.3453)	Acc@1 85.938 (88.933)	Acc@5 98.438 (99.315)
Testing the models......
Loss: 1.5954, Prec@1: 64.41, Prec@5: 88.19
Epoch time: 81s
Epoch: 68  lr: 0.100
Epoch: [68][000/391]	Time 1.1619 Data 0.9368 Loss 0.3900 (0.3900)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [68][100/391]	Time 0.1891 Data 0.0021 Loss 0.2865 (0.3093)	Acc@1 89.844 (90.153)	Acc@5 100.000 (99.474)
Epoch: [68][200/391]	Time 0.1895 Data 0.0019 Loss 0.3092 (0.3130)	Acc@1 88.281 (90.127)	Acc@5 100.000 (99.448)
Epoch: [68][300/391]	Time 0.1885 Data 0.0021 Loss 0.3517 (0.3235)	Acc@1 89.062 (89.701)	Acc@5 98.438 (99.393)
Testing the models......
Loss: 1.5701, Prec@1: 65.38, Prec@5: 87.77
Epoch time: 81s
Epoch: 69  lr: 0.100
Epoch: [69][000/391]	Time 1.1562 Data 0.9420 Loss 0.3229 (0.3229)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [69][100/391]	Time 0.1887 Data 0.0020 Loss 0.2329 (0.2985)	Acc@1 93.750 (90.617)	Acc@5 100.000 (99.505)
Epoch: [69][200/391]	Time 0.1891 Data 0.0020 Loss 0.4107 (0.3117)	Acc@1 90.625 (90.046)	Acc@5 99.219 (99.452)
Epoch: [69][300/391]	Time 0.1892 Data 0.0019 Loss 0.4507 (0.3319)	Acc@1 82.031 (89.410)	Acc@5 100.000 (99.359)
Testing the models......
Loss: 1.4469, Prec@1: 66.58, Prec@5: 89.08
Epoch time: 81s
Saving models
Epoch: 70  lr: 0.100
Epoch: [70][000/391]	Time 1.1742 Data 0.9434 Loss 0.2248 (0.2248)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [70][100/391]	Time 0.1890 Data 0.0020 Loss 0.3414 (0.2969)	Acc@1 86.719 (90.888)	Acc@5 100.000 (99.459)
Epoch: [70][200/391]	Time 0.1886 Data 0.0020 Loss 0.2473 (0.3029)	Acc@1 92.969 (90.497)	Acc@5 100.000 (99.502)
Epoch: [70][300/391]	Time 0.1909 Data 0.0020 Loss 0.2599 (0.3216)	Acc@1 91.406 (89.924)	Acc@5 99.219 (99.426)
Testing the models......
Loss: 1.5270, Prec@1: 65.76, Prec@5: 88.16
Epoch time: 81s
Epoch: 71  lr: 0.100
Epoch: [71][000/391]	Time 1.1772 Data 0.9766 Loss 0.2235 (0.2235)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [71][100/391]	Time 0.1891 Data 0.0020 Loss 0.3144 (0.2828)	Acc@1 92.188 (91.344)	Acc@5 100.000 (99.582)
Epoch: [71][200/391]	Time 0.1889 Data 0.0020 Loss 0.2811 (0.3037)	Acc@1 89.062 (90.493)	Acc@5 100.000 (99.499)
Epoch: [71][300/391]	Time 0.1917 Data 0.0020 Loss 0.2885 (0.3176)	Acc@1 93.750 (90.064)	Acc@5 98.438 (99.468)
Testing the models......
Loss: 1.4914, Prec@1: 66.01, Prec@5: 88.81
Epoch time: 81s
Epoch: 72  lr: 0.100
Epoch: [72][000/391]	Time 1.1804 Data 0.9745 Loss 0.2966 (0.2966)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [72][100/391]	Time 0.1919 Data 0.0020 Loss 0.2318 (0.3089)	Acc@1 92.969 (90.532)	Acc@5 100.000 (99.358)
Epoch: [72][200/391]	Time 0.1909 Data 0.0019 Loss 0.3109 (0.3073)	Acc@1 91.406 (90.551)	Acc@5 100.000 (99.444)
Epoch: [72][300/391]	Time 0.1892 Data 0.0024 Loss 0.2613 (0.3196)	Acc@1 89.844 (90.085)	Acc@5 100.000 (99.390)
Testing the models......
Loss: 1.6063, Prec@1: 65.17, Prec@5: 87.76
Epoch time: 82s
Epoch: 73  lr: 0.100
Epoch: [73][000/391]	Time 1.1792 Data 0.9669 Loss 0.2622 (0.2622)	Acc@1 93.750 (93.750)	Acc@5 97.656 (97.656)
Epoch: [73][100/391]	Time 0.1892 Data 0.0021 Loss 0.3070 (0.2924)	Acc@1 91.406 (91.105)	Acc@5 100.000 (99.520)
Epoch: [73][200/391]	Time 0.1892 Data 0.0019 Loss 0.3264 (0.3002)	Acc@1 92.188 (90.668)	Acc@5 98.438 (99.499)
Epoch: [73][300/391]	Time 0.1898 Data 0.0020 Loss 0.1779 (0.3099)	Acc@1 95.312 (90.272)	Acc@5 100.000 (99.491)
Testing the models......
Loss: 1.6737, Prec@1: 63.69, Prec@5: 87.16
Epoch time: 81s
Epoch: 74  lr: 0.100
Epoch: [74][000/391]	Time 1.1464 Data 0.9149 Loss 0.3589 (0.3589)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [74][100/391]	Time 0.1893 Data 0.0020 Loss 0.3296 (0.2935)	Acc@1 90.625 (90.772)	Acc@5 99.219 (99.420)
Epoch: [74][200/391]	Time 0.1908 Data 0.0022 Loss 0.3143 (0.2981)	Acc@1 89.844 (90.606)	Acc@5 100.000 (99.499)
Epoch: [74][300/391]	Time 0.1902 Data 0.0020 Loss 0.3334 (0.3120)	Acc@1 88.281 (90.223)	Acc@5 98.438 (99.439)
Testing the models......
Loss: 1.5788, Prec@1: 65.18, Prec@5: 88.26
Epoch time: 81s
Epoch: 75  lr: 0.100
Epoch: [75][000/391]	Time 1.1987 Data 0.9992 Loss 0.2944 (0.2944)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [75][100/391]	Time 0.1887 Data 0.0021 Loss 0.1655 (0.2688)	Acc@1 96.094 (91.607)	Acc@5 100.000 (99.722)
Epoch: [75][200/391]	Time 0.1892 Data 0.0022 Loss 0.2518 (0.2763)	Acc@1 91.406 (91.317)	Acc@5 99.219 (99.627)
Epoch: [75][300/391]	Time 0.1889 Data 0.0020 Loss 0.3362 (0.2907)	Acc@1 86.719 (90.807)	Acc@5 100.000 (99.564)
Testing the models......
Loss: 1.8151, Prec@1: 61.54, Prec@5: 86.16
Epoch time: 81s
Epoch: 76  lr: 0.100
Epoch: [76][000/391]	Time 1.2603 Data 0.9953 Loss 0.2455 (0.2455)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [76][100/391]	Time 0.1889 Data 0.0019 Loss 0.4169 (0.2930)	Acc@1 89.062 (90.880)	Acc@5 100.000 (99.451)
Epoch: [76][200/391]	Time 0.1890 Data 0.0020 Loss 0.2727 (0.2903)	Acc@1 92.188 (90.882)	Acc@5 99.219 (99.468)
Epoch: [76][300/391]	Time 0.1931 Data 0.0023 Loss 0.4762 (0.3014)	Acc@1 85.938 (90.529)	Acc@5 96.875 (99.473)
Testing the models......
Loss: 1.5303, Prec@1: 66.50, Prec@5: 88.49
Epoch time: 82s
Epoch: 77  lr: 0.100
Epoch: [77][000/391]	Time 1.2418 Data 1.0105 Loss 0.2212 (0.2212)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [77][100/391]	Time 0.1893 Data 0.0020 Loss 0.1826 (0.2791)	Acc@1 91.406 (91.058)	Acc@5 100.000 (99.667)
Epoch: [77][200/391]	Time 0.1890 Data 0.0020 Loss 0.3492 (0.2908)	Acc@1 91.406 (90.792)	Acc@5 100.000 (99.615)
Epoch: [77][300/391]	Time 0.1979 Data 0.0022 Loss 0.3297 (0.3151)	Acc@1 87.500 (90.077)	Acc@5 99.219 (99.504)
Testing the models......
Loss: 1.5345, Prec@1: 66.00, Prec@5: 88.29
Epoch time: 81s
Epoch: 78  lr: 0.100
Epoch: [78][000/391]	Time 1.2880 Data 1.1113 Loss 0.1796 (0.1796)	Acc@1 96.094 (96.094)	Acc@5 99.219 (99.219)
Epoch: [78][100/391]	Time 0.1890 Data 0.0020 Loss 0.3331 (0.2746)	Acc@1 90.625 (91.662)	Acc@5 99.219 (99.466)
Epoch: [78][200/391]	Time 0.1894 Data 0.0020 Loss 0.3386 (0.2783)	Acc@1 89.062 (91.433)	Acc@5 99.219 (99.530)
Epoch: [78][300/391]	Time 0.1885 Data 0.0020 Loss 0.2544 (0.2871)	Acc@1 91.406 (91.056)	Acc@5 98.438 (99.517)
Testing the models......
Loss: 1.6244, Prec@1: 64.53, Prec@5: 87.01
Epoch time: 82s
Epoch: 79  lr: 0.100
Epoch: [79][000/391]	Time 1.2244 Data 1.0140 Loss 0.1645 (0.1645)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [79][100/391]	Time 0.1889 Data 0.0020 Loss 0.1577 (0.2699)	Acc@1 94.531 (91.623)	Acc@5 100.000 (99.489)
Epoch: [79][200/391]	Time 0.1899 Data 0.0022 Loss 0.4964 (0.2914)	Acc@1 86.719 (90.866)	Acc@5 99.219 (99.487)
Epoch: [79][300/391]	Time 0.1899 Data 0.0020 Loss 0.4085 (0.3089)	Acc@1 88.281 (90.295)	Acc@5 100.000 (99.452)
Testing the models......
Loss: 1.5616, Prec@1: 65.09, Prec@5: 88.30
Epoch time: 82s
Epoch: 80  lr: 0.100
Epoch: [80][000/391]	Time 1.2145 Data 0.9963 Loss 0.3286 (0.3286)	Acc@1 89.844 (89.844)	Acc@5 99.219 (99.219)
Epoch: [80][100/391]	Time 0.1890 Data 0.0020 Loss 0.2991 (0.2810)	Acc@1 91.406 (91.089)	Acc@5 99.219 (99.474)
Epoch: [80][200/391]	Time 0.1886 Data 0.0020 Loss 0.3208 (0.2890)	Acc@1 89.844 (90.913)	Acc@5 97.656 (99.429)
Epoch: [80][300/391]	Time 0.1886 Data 0.0024 Loss 0.2392 (0.3027)	Acc@1 92.969 (90.534)	Acc@5 100.000 (99.395)
Testing the models......
Loss: 1.6324, Prec@1: 65.82, Prec@5: 87.81
Epoch time: 81s
Epoch: 81  lr: 0.100
Epoch: [81][000/391]	Time 1.1923 Data 1.0222 Loss 0.3009 (0.3009)	Acc@1 89.062 (89.062)	Acc@5 98.438 (98.438)
Epoch: [81][100/391]	Time 0.1892 Data 0.0022 Loss 0.2704 (0.2896)	Acc@1 92.188 (90.896)	Acc@5 99.219 (99.520)
Epoch: [81][200/391]	Time 0.1890 Data 0.0021 Loss 0.2335 (0.2834)	Acc@1 93.750 (91.181)	Acc@5 99.219 (99.526)
Epoch: [81][300/391]	Time 0.1889 Data 0.0021 Loss 0.3089 (0.2923)	Acc@1 89.844 (90.892)	Acc@5 100.000 (99.507)
Testing the models......
Loss: 1.5228, Prec@1: 66.27, Prec@5: 88.67
Epoch time: 81s
Epoch: 82  lr: 0.100
Epoch: [82][000/391]	Time 1.2189 Data 1.0615 Loss 0.2330 (0.2330)	Acc@1 94.531 (94.531)	Acc@5 99.219 (99.219)
Epoch: [82][100/391]	Time 0.1890 Data 0.0020 Loss 0.4187 (0.2557)	Acc@1 85.938 (92.048)	Acc@5 98.438 (99.598)
Epoch: [82][200/391]	Time 0.1935 Data 0.0021 Loss 0.1774 (0.2600)	Acc@1 93.750 (91.853)	Acc@5 100.000 (99.619)
Epoch: [82][300/391]	Time 0.1891 Data 0.0025 Loss 0.3858 (0.2804)	Acc@1 88.281 (91.154)	Acc@5 100.000 (99.559)
Testing the models......
Loss: 1.5804, Prec@1: 65.87, Prec@5: 88.14
Epoch time: 82s
Epoch: 83  lr: 0.100
Epoch: [83][000/391]	Time 1.1778 Data 0.9489 Loss 0.2037 (0.2037)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [83][100/391]	Time 0.1894 Data 0.0020 Loss 0.2876 (0.2738)	Acc@1 92.188 (91.762)	Acc@5 99.219 (99.528)
Epoch: [83][200/391]	Time 0.1884 Data 0.0020 Loss 0.3356 (0.2833)	Acc@1 89.062 (91.336)	Acc@5 100.000 (99.495)
Epoch: [83][300/391]	Time 0.1893 Data 0.0022 Loss 0.3717 (0.3008)	Acc@1 89.062 (90.755)	Acc@5 99.219 (99.445)
Testing the models......
Loss: 1.5342, Prec@1: 66.47, Prec@5: 88.72
Epoch time: 82s
Epoch: 84  lr: 0.100
Epoch: [84][000/391]	Time 1.1717 Data 0.9055 Loss 0.1718 (0.1718)	Acc@1 95.312 (95.312)	Acc@5 100.000 (100.000)
Epoch: [84][100/391]	Time 0.1945 Data 0.0020 Loss 0.4026 (0.2579)	Acc@1 89.844 (91.925)	Acc@5 99.219 (99.644)
Epoch: [84][200/391]	Time 0.1906 Data 0.0024 Loss 0.4010 (0.2693)	Acc@1 89.062 (91.663)	Acc@5 98.438 (99.588)
Epoch: [84][300/391]	Time 0.1891 Data 0.0022 Loss 0.3034 (0.2820)	Acc@1 92.188 (91.289)	Acc@5 99.219 (99.530)
Testing the models......
Loss: 1.6836, Prec@1: 64.23, Prec@5: 86.96
Epoch time: 81s
Epoch: 85  lr: 0.100
Epoch: [85][000/391]	Time 1.1918 Data 0.9873 Loss 0.2415 (0.2415)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [85][100/391]	Time 0.1894 Data 0.0032 Loss 0.3181 (0.2541)	Acc@1 91.406 (92.203)	Acc@5 99.219 (99.598)
Epoch: [85][200/391]	Time 0.1907 Data 0.0022 Loss 0.2317 (0.2679)	Acc@1 93.750 (91.729)	Acc@5 100.000 (99.600)
Epoch: [85][300/391]	Time 0.1914 Data 0.0020 Loss 0.3223 (0.2925)	Acc@1 89.844 (90.903)	Acc@5 100.000 (99.502)
Testing the models......
Loss: 1.7680, Prec@1: 62.62, Prec@5: 86.12
Epoch time: 81s
Epoch: 86  lr: 0.100
Epoch: [86][000/391]	Time 1.1984 Data 0.9382 Loss 0.2159 (0.2159)	Acc@1 94.531 (94.531)	Acc@5 99.219 (99.219)
Epoch: [86][100/391]	Time 0.1900 Data 0.0036 Loss 0.3224 (0.2679)	Acc@1 88.281 (91.747)	Acc@5 100.000 (99.613)
Epoch: [86][200/391]	Time 0.1898 Data 0.0020 Loss 0.3833 (0.2727)	Acc@1 87.500 (91.566)	Acc@5 99.219 (99.553)
Epoch: [86][300/391]	Time 0.1931 Data 0.0020 Loss 0.2469 (0.2925)	Acc@1 92.188 (90.892)	Acc@5 99.219 (99.494)
Testing the models......
Loss: 1.6904, Prec@1: 63.10, Prec@5: 87.62
Epoch time: 82s
Epoch: 87  lr: 0.100
Epoch: [87][000/391]	Time 1.2532 Data 1.0005 Loss 0.2143 (0.2143)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [87][100/391]	Time 0.1899 Data 0.0020 Loss 0.3608 (0.2587)	Acc@1 89.062 (91.886)	Acc@5 97.656 (99.567)
Epoch: [87][200/391]	Time 0.1887 Data 0.0019 Loss 0.3317 (0.2746)	Acc@1 90.625 (91.379)	Acc@5 100.000 (99.557)
Epoch: [87][300/391]	Time 0.1891 Data 0.0020 Loss 0.3346 (0.2862)	Acc@1 91.406 (91.020)	Acc@5 100.000 (99.509)
Testing the models......
Loss: 1.5945, Prec@1: 65.74, Prec@5: 88.27
Epoch time: 81s
Epoch: 88  lr: 0.100
Epoch: [88][000/391]	Time 1.2231 Data 0.9925 Loss 0.2164 (0.2164)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [88][100/391]	Time 0.1898 Data 0.0033 Loss 0.3275 (0.2645)	Acc@1 90.625 (91.793)	Acc@5 99.219 (99.629)
Epoch: [88][200/391]	Time 0.1889 Data 0.0022 Loss 0.3765 (0.2735)	Acc@1 89.062 (91.550)	Acc@5 99.219 (99.561)
Epoch: [88][300/391]	Time 0.1895 Data 0.0019 Loss 0.3486 (0.2865)	Acc@1 87.500 (91.079)	Acc@5 100.000 (99.504)
Testing the models......
Loss: 1.6500, Prec@1: 63.67, Prec@5: 87.17
Epoch time: 81s
Epoch: 89  lr: 0.100
Epoch: [89][000/391]	Time 1.1639 Data 0.8946 Loss 0.2214 (0.2214)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [89][100/391]	Time 0.1961 Data 0.0020 Loss 0.2563 (0.2707)	Acc@1 91.406 (91.778)	Acc@5 100.000 (99.590)
Epoch: [89][200/391]	Time 0.1902 Data 0.0019 Loss 0.2065 (0.2831)	Acc@1 95.312 (91.266)	Acc@5 100.000 (99.557)
Epoch: [89][300/391]	Time 0.1892 Data 0.0022 Loss 0.2801 (0.2893)	Acc@1 93.750 (91.014)	Acc@5 97.656 (99.491)
Testing the models......
Loss: 1.6256, Prec@1: 64.98, Prec@5: 87.47
Epoch time: 81s
Epoch: 90  lr: 0.100
Epoch: [90][000/391]	Time 1.3076 Data 1.0882 Loss 0.2904 (0.2904)	Acc@1 92.188 (92.188)	Acc@5 97.656 (97.656)
Epoch: [90][100/391]	Time 0.1952 Data 0.0020 Loss 0.2706 (0.2740)	Acc@1 92.969 (91.662)	Acc@5 99.219 (99.528)
Epoch: [90][200/391]	Time 0.1954 Data 0.0023 Loss 0.3797 (0.2681)	Acc@1 89.062 (91.721)	Acc@5 99.219 (99.561)
Epoch: [90][300/391]	Time 0.1895 Data 0.0020 Loss 0.2122 (0.2777)	Acc@1 93.750 (91.404)	Acc@5 99.219 (99.515)
Testing the models......
Loss: 1.6733, Prec@1: 64.42, Prec@5: 87.61
Epoch time: 82s
Epoch: 91  lr: 0.100
Epoch: [91][000/391]	Time 1.1534 Data 0.9420 Loss 0.2681 (0.2681)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [91][100/391]	Time 0.1894 Data 0.0020 Loss 0.3859 (0.2638)	Acc@1 88.281 (91.739)	Acc@5 97.656 (99.582)
Epoch: [91][200/391]	Time 0.1888 Data 0.0020 Loss 0.3834 (0.2752)	Acc@1 89.062 (91.500)	Acc@5 100.000 (99.557)
Epoch: [91][300/391]	Time 0.1909 Data 0.0020 Loss 0.2697 (0.2892)	Acc@1 92.188 (91.069)	Acc@5 100.000 (99.491)
Testing the models......
Loss: 1.7174, Prec@1: 63.21, Prec@5: 87.00
Epoch time: 81s
Epoch: 92  lr: 0.100
Epoch: [92][000/391]	Time 1.1483 Data 0.9175 Loss 0.2623 (0.2623)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [92][100/391]	Time 0.1886 Data 0.0019 Loss 0.3358 (0.2528)	Acc@1 92.188 (92.126)	Acc@5 99.219 (99.683)
Epoch: [92][200/391]	Time 0.1886 Data 0.0020 Loss 0.3109 (0.2640)	Acc@1 89.062 (91.674)	Acc@5 98.438 (99.592)
Epoch: [92][300/391]	Time 0.1905 Data 0.0020 Loss 0.3588 (0.2694)	Acc@1 89.062 (91.513)	Acc@5 98.438 (99.561)
Testing the models......
Loss: 1.6567, Prec@1: 64.49, Prec@5: 87.77
Epoch time: 81s
Epoch: 93  lr: 0.100
Epoch: [93][000/391]	Time 1.1344 Data 0.9327 Loss 0.3544 (0.3544)	Acc@1 89.844 (89.844)	Acc@5 97.656 (97.656)
Epoch: [93][100/391]	Time 0.1893 Data 0.0021 Loss 0.1467 (0.2531)	Acc@1 96.875 (92.242)	Acc@5 99.219 (99.652)
Epoch: [93][200/391]	Time 0.1895 Data 0.0020 Loss 0.1673 (0.2555)	Acc@1 93.750 (92.133)	Acc@5 100.000 (99.662)
Epoch: [93][300/391]	Time 0.1886 Data 0.0030 Loss 0.1736 (0.2719)	Acc@1 96.094 (91.546)	Acc@5 100.000 (99.613)
Testing the models......
Loss: 1.6634, Prec@1: 64.48, Prec@5: 87.10
Epoch time: 81s
Epoch: 94  lr: 0.100
Epoch: [94][000/391]	Time 1.0917 Data 0.9013 Loss 0.3254 (0.3254)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [94][100/391]	Time 0.1897 Data 0.0019 Loss 0.1757 (0.2595)	Acc@1 96.094 (91.932)	Acc@5 99.219 (99.644)
Epoch: [94][200/391]	Time 0.1893 Data 0.0022 Loss 0.2049 (0.2649)	Acc@1 94.531 (91.694)	Acc@5 99.219 (99.615)
Epoch: [94][300/391]	Time 0.1894 Data 0.0020 Loss 0.1923 (0.2768)	Acc@1 94.531 (91.251)	Acc@5 99.219 (99.587)
Testing the models......
Loss: 1.7293, Prec@1: 64.23, Prec@5: 87.20
Epoch time: 81s
Epoch: 95  lr: 0.100
Epoch: [95][000/391]	Time 1.1924 Data 0.9847 Loss 0.3115 (0.3115)	Acc@1 87.500 (87.500)	Acc@5 98.438 (98.438)
Epoch: [95][100/391]	Time 0.1887 Data 0.0019 Loss 0.1439 (0.2495)	Acc@1 95.312 (92.528)	Acc@5 100.000 (99.598)
Epoch: [95][200/391]	Time 0.1890 Data 0.0020 Loss 0.3652 (0.2630)	Acc@1 90.625 (91.997)	Acc@5 99.219 (99.572)
Epoch: [95][300/391]	Time 0.1895 Data 0.0020 Loss 0.3291 (0.2780)	Acc@1 89.844 (91.461)	Acc@5 100.000 (99.548)
Testing the models......
Loss: 1.7616, Prec@1: 64.09, Prec@5: 86.74
Epoch time: 81s
Epoch: 96  lr: 0.100
Epoch: [96][000/391]	Time 1.2189 Data 0.9904 Loss 0.2929 (0.2929)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [96][100/391]	Time 0.1914 Data 0.0020 Loss 0.1726 (0.2532)	Acc@1 95.312 (92.257)	Acc@5 100.000 (99.575)
Epoch: [96][200/391]	Time 0.1889 Data 0.0020 Loss 0.1930 (0.2625)	Acc@1 94.531 (91.974)	Acc@5 99.219 (99.545)
Epoch: [96][300/391]	Time 0.1892 Data 0.0019 Loss 0.2396 (0.2775)	Acc@1 93.750 (91.461)	Acc@5 100.000 (99.520)
Testing the models......
Loss: 1.5751, Prec@1: 65.80, Prec@5: 88.37
Epoch time: 81s
Epoch: 97  lr: 0.100
Epoch: [97][000/391]	Time 1.1220 Data 0.9279 Loss 0.2617 (0.2617)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [97][100/391]	Time 0.1889 Data 0.0047 Loss 0.2910 (0.2606)	Acc@1 92.188 (91.986)	Acc@5 100.000 (99.497)
Epoch: [97][200/391]	Time 0.1977 Data 0.0020 Loss 0.4386 (0.2742)	Acc@1 85.156 (91.418)	Acc@5 100.000 (99.522)
Epoch: [97][300/391]	Time 0.1894 Data 0.0020 Loss 0.3325 (0.2845)	Acc@1 89.062 (91.064)	Acc@5 98.438 (99.489)
Testing the models......
Loss: 1.6242, Prec@1: 65.68, Prec@5: 87.47
Epoch time: 81s
Epoch: 98  lr: 0.100
Epoch: [98][000/391]	Time 1.1954 Data 0.9687 Loss 0.2218 (0.2218)	Acc@1 94.531 (94.531)	Acc@5 99.219 (99.219)
Epoch: [98][100/391]	Time 0.1887 Data 0.0020 Loss 0.2081 (0.2730)	Acc@1 92.969 (91.538)	Acc@5 100.000 (99.482)
Epoch: [98][200/391]	Time 0.1894 Data 0.0020 Loss 0.3219 (0.2789)	Acc@1 86.719 (91.422)	Acc@5 100.000 (99.487)
Epoch: [98][300/391]	Time 0.1898 Data 0.0021 Loss 0.3491 (0.2892)	Acc@1 89.062 (91.134)	Acc@5 99.219 (99.471)
Testing the models......
Loss: 1.8388, Prec@1: 63.23, Prec@5: 87.36
Epoch time: 81s
Epoch: 99  lr: 0.100
Epoch: [99][000/391]	Time 1.1003 Data 0.9071 Loss 0.2480 (0.2480)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [99][100/391]	Time 0.1897 Data 0.0020 Loss 0.2531 (0.2810)	Acc@1 91.406 (91.236)	Acc@5 100.000 (99.497)
Epoch: [99][200/391]	Time 0.1891 Data 0.0022 Loss 0.3556 (0.2750)	Acc@1 88.281 (91.395)	Acc@5 99.219 (99.495)
Epoch: [99][300/391]	Time 0.1892 Data 0.0019 Loss 0.2145 (0.2906)	Acc@1 92.969 (90.911)	Acc@5 100.000 (99.421)
Testing the models......
Loss: 1.5637, Prec@1: 66.38, Prec@5: 88.01
Epoch time: 81s
Epoch: 100  lr: 0.010
Epoch: [100][000/391]	Time 1.1033 Data 0.9156 Loss 0.2058 (0.2058)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [100][100/391]	Time 0.1893 Data 0.0020 Loss 0.1790 (0.1490)	Acc@1 96.094 (95.661)	Acc@5 100.000 (99.845)
Epoch: [100][200/391]	Time 0.1888 Data 0.0020 Loss 0.0500 (0.1208)	Acc@1 99.219 (96.688)	Acc@5 100.000 (99.918)
Epoch: [100][300/391]	Time 0.1894 Data 0.0020 Loss 0.0970 (0.1073)	Acc@1 98.438 (97.176)	Acc@5 100.000 (99.945)
Testing the models......
Loss: 1.0673, Prec@1: 74.11, Prec@5: 92.13
Epoch time: 81s
Saving models
Epoch: 101  lr: 0.010
Epoch: [101][000/391]	Time 1.1428 Data 0.9172 Loss 0.0348 (0.0348)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [101][100/391]	Time 0.1887 Data 0.0021 Loss 0.0786 (0.0560)	Acc@1 99.219 (99.087)	Acc@5 100.000 (100.000)
Epoch: [101][200/391]	Time 0.1888 Data 0.0022 Loss 0.1186 (0.0561)	Acc@1 97.656 (99.024)	Acc@5 100.000 (100.000)
Epoch: [101][300/391]	Time 0.1894 Data 0.0021 Loss 0.0500 (0.0556)	Acc@1 99.219 (99.050)	Acc@5 100.000 (99.997)
Testing the models......
Loss: 1.0319, Prec@1: 74.64, Prec@5: 92.34
Epoch time: 81s
Saving models
Epoch: 102  lr: 0.010
Epoch: [102][000/391]	Time 1.2579 Data 1.0124 Loss 0.0303 (0.0303)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [102][100/391]	Time 0.1894 Data 0.0024 Loss 0.0388 (0.0464)	Acc@1 100.000 (99.343)	Acc@5 100.000 (99.985)
Epoch: [102][200/391]	Time 0.1908 Data 0.0021 Loss 0.0569 (0.0466)	Acc@1 98.438 (99.339)	Acc@5 100.000 (99.992)
Epoch: [102][300/391]	Time 0.1908 Data 0.0023 Loss 0.0419 (0.0459)	Acc@1 99.219 (99.372)	Acc@5 100.000 (99.995)
Testing the models......
Loss: 1.0184, Prec@1: 74.86, Prec@5: 92.54
Epoch time: 82s
Saving models
Epoch: 103  lr: 0.010
Epoch: [103][000/391]	Time 1.1742 Data 0.9341 Loss 0.0421 (0.0421)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [103][100/391]	Time 0.1892 Data 0.0020 Loss 0.0418 (0.0427)	Acc@1 99.219 (99.443)	Acc@5 100.000 (100.000)
Epoch: [103][200/391]	Time 0.1899 Data 0.0020 Loss 0.0468 (0.0418)	Acc@1 99.219 (99.491)	Acc@5 100.000 (100.000)
Epoch: [103][300/391]	Time 0.1896 Data 0.0020 Loss 0.0341 (0.0406)	Acc@1 99.219 (99.525)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0076, Prec@1: 74.98, Prec@5: 92.48
Epoch time: 81s
Saving models
Epoch: 104  lr: 0.010
Epoch: [104][000/391]	Time 1.3072 Data 1.0801 Loss 0.0142 (0.0142)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [104][100/391]	Time 0.1967 Data 0.0021 Loss 0.0403 (0.0359)	Acc@1 100.000 (99.667)	Acc@5 100.000 (100.000)
Epoch: [104][200/391]	Time 0.1888 Data 0.0022 Loss 0.0477 (0.0362)	Acc@1 99.219 (99.607)	Acc@5 100.000 (100.000)
Epoch: [104][300/391]	Time 0.1914 Data 0.0023 Loss 0.0215 (0.0364)	Acc@1 100.000 (99.616)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9971, Prec@1: 75.01, Prec@5: 92.49
Epoch time: 82s
Saving models
Epoch: 105  lr: 0.010
Epoch: [105][000/391]	Time 1.2398 Data 0.9634 Loss 0.0319 (0.0319)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [105][100/391]	Time 0.1894 Data 0.0020 Loss 0.0308 (0.0318)	Acc@1 100.000 (99.822)	Acc@5 100.000 (100.000)
Epoch: [105][200/391]	Time 0.1888 Data 0.0020 Loss 0.0294 (0.0329)	Acc@1 100.000 (99.747)	Acc@5 100.000 (100.000)
Epoch: [105][300/391]	Time 0.1892 Data 0.0019 Loss 0.0416 (0.0335)	Acc@1 98.438 (99.733)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9903, Prec@1: 75.23, Prec@5: 92.58
Epoch time: 82s
Saving models
Epoch: 106  lr: 0.010
Epoch: [106][000/391]	Time 1.1562 Data 0.9486 Loss 0.0339 (0.0339)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [106][100/391]	Time 0.1936 Data 0.0020 Loss 0.0342 (0.0317)	Acc@1 100.000 (99.752)	Acc@5 100.000 (100.000)
Epoch: [106][200/391]	Time 0.1892 Data 0.0021 Loss 0.0283 (0.0309)	Acc@1 100.000 (99.782)	Acc@5 100.000 (100.000)
Epoch: [106][300/391]	Time 0.1902 Data 0.0020 Loss 0.0236 (0.0315)	Acc@1 100.000 (99.759)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9934, Prec@1: 75.31, Prec@5: 92.60
Epoch time: 82s
Saving models
Epoch: 107  lr: 0.010
Epoch: [107][000/391]	Time 1.2435 Data 1.0480 Loss 0.0336 (0.0336)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [107][100/391]	Time 0.1903 Data 0.0020 Loss 0.0355 (0.0295)	Acc@1 100.000 (99.783)	Acc@5 100.000 (100.000)
Epoch: [107][200/391]	Time 0.1889 Data 0.0020 Loss 0.0236 (0.0300)	Acc@1 100.000 (99.763)	Acc@5 100.000 (100.000)
Epoch: [107][300/391]	Time 0.1893 Data 0.0022 Loss 0.0256 (0.0305)	Acc@1 100.000 (99.738)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9854, Prec@1: 75.34, Prec@5: 92.56
Epoch time: 82s
Saving models
Epoch: 108  lr: 0.010
Epoch: [108][000/391]	Time 1.2387 Data 0.9998 Loss 0.0214 (0.0214)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [108][100/391]	Time 0.1890 Data 0.0019 Loss 0.0224 (0.0283)	Acc@1 100.000 (99.791)	Acc@5 100.000 (100.000)
Epoch: [108][200/391]	Time 0.1884 Data 0.0021 Loss 0.0291 (0.0286)	Acc@1 100.000 (99.798)	Acc@5 100.000 (100.000)
Epoch: [108][300/391]	Time 0.1911 Data 0.0024 Loss 0.0274 (0.0284)	Acc@1 100.000 (99.803)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9802, Prec@1: 75.44, Prec@5: 92.55
Epoch time: 82s
Saving models
Epoch: 109  lr: 0.010
Epoch: [109][000/391]	Time 1.1664 Data 0.9331 Loss 0.0284 (0.0284)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [109][100/391]	Time 0.1894 Data 0.0020 Loss 0.0222 (0.0265)	Acc@1 100.000 (99.845)	Acc@5 100.000 (100.000)
Epoch: [109][200/391]	Time 0.1899 Data 0.0022 Loss 0.0209 (0.0272)	Acc@1 100.000 (99.852)	Acc@5 100.000 (100.000)
Epoch: [109][300/391]	Time 0.1893 Data 0.0021 Loss 0.0461 (0.0274)	Acc@1 99.219 (99.844)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9767, Prec@1: 75.31, Prec@5: 92.49
Epoch time: 82s
Epoch: 110  lr: 0.010
Epoch: [110][000/391]	Time 1.1697 Data 0.9440 Loss 0.0282 (0.0282)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [110][100/391]	Time 0.1913 Data 0.0020 Loss 0.0263 (0.0265)	Acc@1 100.000 (99.861)	Acc@5 100.000 (100.000)
Epoch: [110][200/391]	Time 0.1920 Data 0.0020 Loss 0.0193 (0.0271)	Acc@1 100.000 (99.856)	Acc@5 100.000 (100.000)
Epoch: [110][300/391]	Time 0.1956 Data 0.0020 Loss 0.0225 (0.0269)	Acc@1 100.000 (99.852)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9769, Prec@1: 75.53, Prec@5: 92.52
Epoch time: 82s
Saving models
Epoch: 111  lr: 0.010
Epoch: [111][000/391]	Time 1.2389 Data 1.0266 Loss 0.0224 (0.0224)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [111][100/391]	Time 0.1889 Data 0.0021 Loss 0.0232 (0.0265)	Acc@1 100.000 (99.814)	Acc@5 100.000 (100.000)
Epoch: [111][200/391]	Time 0.1891 Data 0.0027 Loss 0.0286 (0.0261)	Acc@1 99.219 (99.825)	Acc@5 100.000 (100.000)
Epoch: [111][300/391]	Time 0.1911 Data 0.0021 Loss 0.0292 (0.0258)	Acc@1 100.000 (99.829)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9765, Prec@1: 75.37, Prec@5: 92.65
Epoch time: 81s
Epoch: 112  lr: 0.010
Epoch: [112][000/391]	Time 1.1795 Data 0.9656 Loss 0.0175 (0.0175)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [112][100/391]	Time 0.1983 Data 0.0022 Loss 0.0217 (0.0252)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [112][200/391]	Time 0.1909 Data 0.0025 Loss 0.0310 (0.0254)	Acc@1 100.000 (99.876)	Acc@5 100.000 (100.000)
Epoch: [112][300/391]	Time 0.1932 Data 0.0020 Loss 0.0205 (0.0251)	Acc@1 100.000 (99.883)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9751, Prec@1: 75.32, Prec@5: 92.66
Epoch time: 81s
Epoch: 113  lr: 0.010
Epoch: [113][000/391]	Time 1.2322 Data 1.0602 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [113][100/391]	Time 0.1919 Data 0.0029 Loss 0.0305 (0.0239)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [113][200/391]	Time 0.1938 Data 0.0020 Loss 0.0180 (0.0241)	Acc@1 100.000 (99.926)	Acc@5 100.000 (100.000)
Epoch: [113][300/391]	Time 0.1919 Data 0.0021 Loss 0.0270 (0.0243)	Acc@1 100.000 (99.920)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9699, Prec@1: 75.57, Prec@5: 92.63
Epoch time: 82s
Saving models
Epoch: 114  lr: 0.010
Epoch: [114][000/391]	Time 1.2428 Data 1.0372 Loss 0.0583 (0.0583)	Acc@1 97.656 (97.656)	Acc@5 100.000 (100.000)
Epoch: [114][100/391]	Time 0.1888 Data 0.0021 Loss 0.0298 (0.0230)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [114][200/391]	Time 0.1891 Data 0.0022 Loss 0.0235 (0.0233)	Acc@1 100.000 (99.903)	Acc@5 100.000 (100.000)
Epoch: [114][300/391]	Time 0.1893 Data 0.0023 Loss 0.0232 (0.0233)	Acc@1 99.219 (99.891)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9693, Prec@1: 75.63, Prec@5: 92.65
Epoch time: 82s
Saving models
Epoch: 115  lr: 0.010
Epoch: [115][000/391]	Time 1.2077 Data 0.9476 Loss 0.0230 (0.0230)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [115][100/391]	Time 0.1895 Data 0.0026 Loss 0.0166 (0.0247)	Acc@1 100.000 (99.814)	Acc@5 100.000 (100.000)
Epoch: [115][200/391]	Time 0.1900 Data 0.0021 Loss 0.0181 (0.0242)	Acc@1 100.000 (99.864)	Acc@5 100.000 (100.000)
Epoch: [115][300/391]	Time 0.1894 Data 0.0021 Loss 0.0213 (0.0237)	Acc@1 100.000 (99.883)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9719, Prec@1: 75.43, Prec@5: 92.61
Epoch time: 82s
Epoch: 116  lr: 0.010
Epoch: [116][000/391]	Time 1.1693 Data 0.9162 Loss 0.0361 (0.0361)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [116][100/391]	Time 0.1894 Data 0.0020 Loss 0.0215 (0.0234)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [116][200/391]	Time 0.1898 Data 0.0020 Loss 0.0353 (0.0231)	Acc@1 100.000 (99.903)	Acc@5 100.000 (100.000)
Epoch: [116][300/391]	Time 0.1891 Data 0.0019 Loss 0.0263 (0.0230)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9706, Prec@1: 75.31, Prec@5: 92.64
Epoch time: 82s
Epoch: 117  lr: 0.010
Epoch: [117][000/391]	Time 1.2256 Data 1.0573 Loss 0.0264 (0.0264)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [117][100/391]	Time 0.1888 Data 0.0020 Loss 0.0300 (0.0224)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [117][200/391]	Time 0.1893 Data 0.0020 Loss 0.0148 (0.0225)	Acc@1 100.000 (99.926)	Acc@5 100.000 (100.000)
Epoch: [117][300/391]	Time 0.1893 Data 0.0020 Loss 0.0183 (0.0222)	Acc@1 100.000 (99.933)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9667, Prec@1: 75.53, Prec@5: 92.58
Epoch time: 82s
Epoch: 118  lr: 0.010
Epoch: [118][000/391]	Time 1.1144 Data 0.9123 Loss 0.0289 (0.0289)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [118][100/391]	Time 0.1903 Data 0.0020 Loss 0.0230 (0.0227)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [118][200/391]	Time 0.1895 Data 0.0020 Loss 0.0205 (0.0224)	Acc@1 100.000 (99.918)	Acc@5 100.000 (100.000)
Epoch: [118][300/391]	Time 0.1905 Data 0.0020 Loss 0.0376 (0.0226)	Acc@1 99.219 (99.920)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9625, Prec@1: 75.49, Prec@5: 92.58
Epoch time: 82s
Epoch: 119  lr: 0.010
Epoch: [119][000/391]	Time 1.1626 Data 0.9408 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [119][100/391]	Time 0.1894 Data 0.0020 Loss 0.0273 (0.0214)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [119][200/391]	Time 0.1899 Data 0.0020 Loss 0.0150 (0.0214)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [119][300/391]	Time 0.1892 Data 0.0021 Loss 0.0176 (0.0215)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9641, Prec@1: 75.60, Prec@5: 92.59
Epoch time: 82s
Epoch: 120  lr: 0.010
Epoch: [120][000/391]	Time 1.2131 Data 0.9301 Loss 0.0207 (0.0207)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [120][100/391]	Time 0.1891 Data 0.0019 Loss 0.0248 (0.0208)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [120][200/391]	Time 0.1934 Data 0.0020 Loss 0.0157 (0.0209)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [120][300/391]	Time 0.1936 Data 0.0021 Loss 0.0167 (0.0214)	Acc@1 100.000 (99.927)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9615, Prec@1: 75.52, Prec@5: 92.60
Epoch time: 82s
Epoch: 121  lr: 0.010
Epoch: [121][000/391]	Time 1.1765 Data 0.9587 Loss 0.0122 (0.0122)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [121][100/391]	Time 0.1890 Data 0.0023 Loss 0.0205 (0.0210)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [121][200/391]	Time 0.1893 Data 0.0019 Loss 0.0325 (0.0213)	Acc@1 99.219 (99.918)	Acc@5 100.000 (100.000)
Epoch: [121][300/391]	Time 0.1893 Data 0.0020 Loss 0.0271 (0.0210)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9621, Prec@1: 75.58, Prec@5: 92.62
Epoch time: 82s
Epoch: 122  lr: 0.010
Epoch: [122][000/391]	Time 1.4371 Data 1.2397 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [122][100/391]	Time 0.1937 Data 0.0022 Loss 0.0207 (0.0214)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [122][200/391]	Time 0.1895 Data 0.0020 Loss 0.0191 (0.0210)	Acc@1 100.000 (99.926)	Acc@5 100.000 (100.000)
Epoch: [122][300/391]	Time 0.1896 Data 0.0020 Loss 0.0196 (0.0211)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9607, Prec@1: 75.69, Prec@5: 92.56
Epoch time: 82s
Saving models
Epoch: 123  lr: 0.010
Epoch: [123][000/391]	Time 1.2124 Data 0.9778 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [123][100/391]	Time 0.1896 Data 0.0026 Loss 0.0187 (0.0198)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [123][200/391]	Time 0.1927 Data 0.0020 Loss 0.0145 (0.0198)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [123][300/391]	Time 0.1895 Data 0.0024 Loss 0.0184 (0.0200)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9579, Prec@1: 75.87, Prec@5: 92.54
Epoch time: 82s
Saving models
Epoch: 124  lr: 0.010
Epoch: [124][000/391]	Time 1.1723 Data 0.9360 Loss 0.0166 (0.0166)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [124][100/391]	Time 0.1888 Data 0.0020 Loss 0.0200 (0.0199)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [124][200/391]	Time 0.1896 Data 0.0024 Loss 0.0154 (0.0201)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [124][300/391]	Time 0.1927 Data 0.0020 Loss 0.0215 (0.0201)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9581, Prec@1: 75.88, Prec@5: 92.51
Epoch time: 82s
Saving models
Epoch: 125  lr: 0.010
Epoch: [125][000/391]	Time 1.1749 Data 0.9025 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [125][100/391]	Time 0.1887 Data 0.0020 Loss 0.0156 (0.0191)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [125][200/391]	Time 0.1899 Data 0.0021 Loss 0.0191 (0.0196)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [125][300/391]	Time 0.1942 Data 0.0020 Loss 0.0271 (0.0197)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9577, Prec@1: 75.80, Prec@5: 92.59
Epoch time: 82s
Epoch: 126  lr: 0.010
Epoch: [126][000/391]	Time 1.1861 Data 0.9743 Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [126][100/391]	Time 0.1892 Data 0.0021 Loss 0.0213 (0.0192)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [126][200/391]	Time 0.1915 Data 0.0020 Loss 0.0183 (0.0203)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [126][300/391]	Time 0.1946 Data 0.0026 Loss 0.0210 (0.0201)	Acc@1 100.000 (99.940)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9622, Prec@1: 75.53, Prec@5: 92.52
Epoch time: 81s
Epoch: 127  lr: 0.010
Epoch: [127][000/391]	Time 1.1923 Data 0.9585 Loss 0.0190 (0.0190)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [127][100/391]	Time 0.1891 Data 0.0027 Loss 0.0257 (0.0201)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [127][200/391]	Time 0.1902 Data 0.0025 Loss 0.0164 (0.0200)	Acc@1 100.000 (99.934)	Acc@5 100.000 (100.000)
Epoch: [127][300/391]	Time 0.1900 Data 0.0020 Loss 0.0167 (0.0197)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9580, Prec@1: 75.75, Prec@5: 92.41
Epoch time: 81s
Epoch: 128  lr: 0.010
Epoch: [128][000/391]	Time 1.1879 Data 0.9832 Loss 0.0180 (0.0180)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [128][100/391]	Time 0.1897 Data 0.0022 Loss 0.0185 (0.0198)	Acc@1 99.219 (99.946)	Acc@5 100.000 (100.000)
Epoch: [128][200/391]	Time 0.1908 Data 0.0019 Loss 0.0187 (0.0193)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [128][300/391]	Time 0.1890 Data 0.0019 Loss 0.0231 (0.0194)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9580, Prec@1: 75.61, Prec@5: 92.48
Epoch time: 81s
Epoch: 129  lr: 0.010
Epoch: [129][000/391]	Time 1.1761 Data 0.9541 Loss 0.0220 (0.0220)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [129][100/391]	Time 0.1896 Data 0.0021 Loss 0.0194 (0.0183)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [129][200/391]	Time 0.1910 Data 0.0026 Loss 0.0222 (0.0185)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [129][300/391]	Time 0.1901 Data 0.0020 Loss 0.0241 (0.0188)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9545, Prec@1: 75.96, Prec@5: 92.63
Epoch time: 81s
Saving models
Epoch: 130  lr: 0.010
Epoch: [130][000/391]	Time 1.3254 Data 1.1034 Loss 0.0164 (0.0164)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [130][100/391]	Time 0.1891 Data 0.0021 Loss 0.0152 (0.0189)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [130][200/391]	Time 0.1894 Data 0.0020 Loss 0.0193 (0.0192)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [130][300/391]	Time 0.1885 Data 0.0019 Loss 0.0209 (0.0193)	Acc@1 100.000 (99.940)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9556, Prec@1: 75.91, Prec@5: 92.57
Epoch time: 82s
Epoch: 131  lr: 0.010
Epoch: [131][000/391]	Time 1.2584 Data 1.0779 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [131][100/391]	Time 0.1892 Data 0.0025 Loss 0.0150 (0.0184)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [131][200/391]	Time 0.1885 Data 0.0019 Loss 0.0190 (0.0184)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [131][300/391]	Time 0.1899 Data 0.0020 Loss 0.0185 (0.0188)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9553, Prec@1: 75.92, Prec@5: 92.59
Epoch time: 82s
Epoch: 132  lr: 0.010
Epoch: [132][000/391]	Time 1.1795 Data 0.9743 Loss 0.0245 (0.0245)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [132][100/391]	Time 0.1920 Data 0.0020 Loss 0.0196 (0.0182)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [132][200/391]	Time 0.1937 Data 0.0023 Loss 0.0240 (0.0183)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [132][300/391]	Time 0.1892 Data 0.0021 Loss 0.0142 (0.0186)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9564, Prec@1: 76.13, Prec@5: 92.64
Epoch time: 82s
Saving models
Epoch: 133  lr: 0.010
Epoch: [133][000/391]	Time 1.2300 Data 0.9900 Loss 0.0120 (0.0120)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [133][100/391]	Time 0.1886 Data 0.0022 Loss 0.0207 (0.0193)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [133][200/391]	Time 0.1890 Data 0.0022 Loss 0.0257 (0.0190)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [133][300/391]	Time 0.1906 Data 0.0022 Loss 0.0167 (0.0187)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9551, Prec@1: 75.75, Prec@5: 92.61
Epoch time: 82s
Epoch: 134  lr: 0.010
Epoch: [134][000/391]	Time 1.1853 Data 0.9183 Loss 0.0186 (0.0186)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [134][100/391]	Time 0.1890 Data 0.0020 Loss 0.0165 (0.0177)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [134][200/391]	Time 0.1889 Data 0.0020 Loss 0.0161 (0.0178)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [134][300/391]	Time 0.1891 Data 0.0031 Loss 0.0149 (0.0182)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9558, Prec@1: 75.72, Prec@5: 92.58
Epoch time: 81s
Epoch: 135  lr: 0.010
Epoch: [135][000/391]	Time 1.1895 Data 1.0322 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [135][100/391]	Time 0.1897 Data 0.0020 Loss 0.0147 (0.0179)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [135][200/391]	Time 0.1897 Data 0.0022 Loss 0.0213 (0.0179)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [135][300/391]	Time 0.1943 Data 0.0022 Loss 0.0125 (0.0182)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9486, Prec@1: 76.03, Prec@5: 92.56
Epoch time: 81s
Epoch: 136  lr: 0.010
Epoch: [136][000/391]	Time 1.1264 Data 0.9073 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [136][100/391]	Time 0.1894 Data 0.0019 Loss 0.0170 (0.0183)	Acc@1 100.000 (99.923)	Acc@5 100.000 (100.000)
Epoch: [136][200/391]	Time 0.1893 Data 0.0020 Loss 0.0138 (0.0182)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [136][300/391]	Time 0.1897 Data 0.0024 Loss 0.0310 (0.0183)	Acc@1 99.219 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9539, Prec@1: 76.05, Prec@5: 92.33
Epoch time: 81s
Epoch: 137  lr: 0.010
Epoch: [137][000/391]	Time 1.1940 Data 0.9935 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [137][100/391]	Time 0.1907 Data 0.0022 Loss 0.0137 (0.0174)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [137][200/391]	Time 0.1886 Data 0.0022 Loss 0.0126 (0.0179)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [137][300/391]	Time 0.1943 Data 0.0028 Loss 0.0251 (0.0181)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9519, Prec@1: 75.94, Prec@5: 92.41
Epoch time: 82s
Epoch: 138  lr: 0.010
Epoch: [138][000/391]	Time 1.4184 Data 1.2167 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [138][100/391]	Time 0.1911 Data 0.0022 Loss 0.0183 (0.0184)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [138][200/391]	Time 0.1889 Data 0.0022 Loss 0.0229 (0.0182)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [138][300/391]	Time 0.1896 Data 0.0022 Loss 0.0175 (0.0180)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9540, Prec@1: 75.77, Prec@5: 92.55
Epoch time: 82s
Epoch: 139  lr: 0.010
Epoch: [139][000/391]	Time 1.5281 Data 1.3134 Loss 0.0191 (0.0191)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [139][100/391]	Time 0.1892 Data 0.0021 Loss 0.0135 (0.0174)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [139][200/391]	Time 0.1905 Data 0.0021 Loss 0.0194 (0.0176)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [139][300/391]	Time 0.1895 Data 0.0022 Loss 0.0143 (0.0178)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9533, Prec@1: 75.87, Prec@5: 92.46
Epoch time: 82s
Epoch: 140  lr: 0.010
Epoch: [140][000/391]	Time 1.5160 Data 1.2925 Loss 0.0187 (0.0187)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [140][100/391]	Time 0.1898 Data 0.0025 Loss 0.0128 (0.0174)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [140][200/391]	Time 0.1901 Data 0.0020 Loss 0.0181 (0.0176)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [140][300/391]	Time 0.1907 Data 0.0021 Loss 0.0179 (0.0179)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9498, Prec@1: 76.02, Prec@5: 92.50
Epoch time: 82s
Epoch: 141  lr: 0.010
Epoch: [141][000/391]	Time 1.5106 Data 1.3157 Loss 0.0133 (0.0133)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [141][100/391]	Time 0.1884 Data 0.0021 Loss 0.0208 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [141][200/391]	Time 0.1903 Data 0.0021 Loss 0.0138 (0.0170)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [141][300/391]	Time 0.1892 Data 0.0020 Loss 0.0193 (0.0175)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9505, Prec@1: 76.11, Prec@5: 92.44
Epoch time: 82s
Epoch: 142  lr: 0.010
Epoch: [142][000/391]	Time 1.5427 Data 1.3494 Loss 0.0183 (0.0183)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [142][100/391]	Time 0.1910 Data 0.0022 Loss 0.0330 (0.0169)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Epoch: [142][200/391]	Time 0.1894 Data 0.0019 Loss 0.0173 (0.0172)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [142][300/391]	Time 0.1892 Data 0.0020 Loss 0.0239 (0.0174)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9534, Prec@1: 75.91, Prec@5: 92.58
Epoch time: 82s
Epoch: 143  lr: 0.010
Epoch: [143][000/391]	Time 1.4565 Data 1.2531 Loss 0.0092 (0.0092)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [143][100/391]	Time 0.1887 Data 0.0021 Loss 0.0141 (0.0167)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [143][200/391]	Time 0.1893 Data 0.0021 Loss 0.0251 (0.0172)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Epoch: [143][300/391]	Time 0.1892 Data 0.0025 Loss 0.0166 (0.0173)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9501, Prec@1: 75.94, Prec@5: 92.63
Epoch time: 82s
Epoch: 144  lr: 0.010
Epoch: [144][000/391]	Time 1.4652 Data 1.2438 Loss 0.0236 (0.0236)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [144][100/391]	Time 0.1901 Data 0.0034 Loss 0.0139 (0.0167)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [144][200/391]	Time 0.1897 Data 0.0018 Loss 0.0182 (0.0174)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [144][300/391]	Time 0.1894 Data 0.0021 Loss 0.0134 (0.0175)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9542, Prec@1: 76.12, Prec@5: 92.47
Epoch time: 82s
Epoch: 145  lr: 0.010
Epoch: [145][000/391]	Time 1.4248 Data 1.2185 Loss 0.0143 (0.0143)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [145][100/391]	Time 0.1892 Data 0.0020 Loss 0.0212 (0.0171)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [145][200/391]	Time 0.1893 Data 0.0020 Loss 0.0175 (0.0170)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [145][300/391]	Time 0.1890 Data 0.0020 Loss 0.0195 (0.0171)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9478, Prec@1: 75.96, Prec@5: 92.65
Epoch time: 82s
Epoch: 146  lr: 0.010
Epoch: [146][000/391]	Time 1.4735 Data 1.2507 Loss 0.0188 (0.0188)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [146][100/391]	Time 0.1896 Data 0.0020 Loss 0.0181 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [146][200/391]	Time 0.1890 Data 0.0020 Loss 0.0153 (0.0172)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [146][300/391]	Time 0.1885 Data 0.0018 Loss 0.0139 (0.0171)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9483, Prec@1: 76.00, Prec@5: 92.65
Epoch time: 82s
Epoch: 147  lr: 0.010
Epoch: [147][000/391]	Time 1.5537 Data 1.3323 Loss 0.0182 (0.0182)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [147][100/391]	Time 0.1891 Data 0.0021 Loss 0.0147 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [147][200/391]	Time 0.1893 Data 0.0021 Loss 0.0227 (0.0166)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [147][300/391]	Time 0.1899 Data 0.0024 Loss 0.0256 (0.0171)	Acc@1 99.219 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9507, Prec@1: 76.08, Prec@5: 92.56
Epoch time: 82s
Epoch: 148  lr: 0.010
Epoch: [148][000/391]	Time 1.5338 Data 1.3648 Loss 0.0138 (0.0138)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [148][100/391]	Time 0.1905 Data 0.0019 Loss 0.0193 (0.0169)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [148][200/391]	Time 0.1885 Data 0.0019 Loss 0.0184 (0.0171)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [148][300/391]	Time 0.1888 Data 0.0019 Loss 0.0280 (0.0170)	Acc@1 99.219 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9530, Prec@1: 75.81, Prec@5: 92.47
Epoch time: 82s
Epoch: 149  lr: 0.010
Epoch: [149][000/391]	Time 1.4969 Data 1.3491 Loss 0.0189 (0.0189)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [149][100/391]	Time 0.1890 Data 0.0020 Loss 0.0172 (0.0165)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [149][200/391]	Time 0.1890 Data 0.0020 Loss 0.0169 (0.0167)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [149][300/391]	Time 0.1895 Data 0.0021 Loss 0.0148 (0.0166)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9510, Prec@1: 75.78, Prec@5: 92.74
Epoch time: 82s
Epoch: 150  lr: 0.001
Epoch: [150][000/391]	Time 1.4435 Data 1.2847 Loss 0.0145 (0.0145)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [150][100/391]	Time 0.1893 Data 0.0021 Loss 0.0154 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [150][200/391]	Time 0.1891 Data 0.0021 Loss 0.0140 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [150][300/391]	Time 0.1891 Data 0.0020 Loss 0.0229 (0.0165)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9519, Prec@1: 75.82, Prec@5: 92.65
Epoch time: 82s
Epoch: 151  lr: 0.001
Epoch: [151][000/391]	Time 1.4218 Data 1.2466 Loss 0.0134 (0.0134)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [151][100/391]	Time 0.1963 Data 0.0020 Loss 0.0133 (0.0167)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [151][200/391]	Time 0.1916 Data 0.0021 Loss 0.0167 (0.0165)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [151][300/391]	Time 0.1894 Data 0.0020 Loss 0.0321 (0.0165)	Acc@1 99.219 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9501, Prec@1: 75.87, Prec@5: 92.56
Epoch time: 82s
Epoch: 152  lr: 0.001
Epoch: [152][000/391]	Time 1.5005 Data 1.3438 Loss 0.0177 (0.0177)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [152][100/391]	Time 0.1924 Data 0.0019 Loss 0.0124 (0.0162)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [152][200/391]	Time 0.1890 Data 0.0019 Loss 0.0155 (0.0161)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [152][300/391]	Time 0.1916 Data 0.0020 Loss 0.0207 (0.0164)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9496, Prec@1: 75.99, Prec@5: 92.63
Epoch time: 82s
Epoch: 153  lr: 0.001
Epoch: [153][000/391]	Time 1.5251 Data 1.3239 Loss 0.0175 (0.0175)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [153][100/391]	Time 0.1900 Data 0.0019 Loss 0.0174 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [153][200/391]	Time 0.1886 Data 0.0019 Loss 0.0147 (0.0162)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [153][300/391]	Time 0.1942 Data 0.0022 Loss 0.0275 (0.0162)	Acc@1 99.219 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9506, Prec@1: 76.02, Prec@5: 92.57
Epoch time: 82s
Epoch: 154  lr: 0.001
Epoch: [154][000/391]	Time 1.5182 Data 1.3217 Loss 0.0204 (0.0204)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [154][100/391]	Time 0.1898 Data 0.0021 Loss 0.0173 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [154][200/391]	Time 0.1888 Data 0.0023 Loss 0.0126 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [154][300/391]	Time 0.1899 Data 0.0021 Loss 0.0145 (0.0160)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9496, Prec@1: 75.94, Prec@5: 92.65
Epoch time: 82s
Epoch: 155  lr: 0.001
Epoch: [155][000/391]	Time 1.4283 Data 1.2448 Loss 0.0167 (0.0167)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [155][100/391]	Time 0.1931 Data 0.0020 Loss 0.0195 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [155][200/391]	Time 0.1888 Data 0.0020 Loss 0.0131 (0.0162)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [155][300/391]	Time 0.1894 Data 0.0022 Loss 0.0202 (0.0163)	Acc@1 99.219 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9492, Prec@1: 75.91, Prec@5: 92.56
Epoch time: 82s
Epoch: 156  lr: 0.001
Epoch: [156][000/391]	Time 1.4398 Data 1.2393 Loss 0.0226 (0.0226)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][100/391]	Time 0.1894 Data 0.0020 Loss 0.0121 (0.0166)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [156][200/391]	Time 0.1902 Data 0.0020 Loss 0.0204 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [156][300/391]	Time 0.1888 Data 0.0019 Loss 0.0103 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9510, Prec@1: 75.75, Prec@5: 92.47
Epoch time: 82s
Epoch: 157  lr: 0.001
Epoch: [157][000/391]	Time 1.4709 Data 1.2471 Loss 0.0115 (0.0115)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [157][100/391]	Time 0.1915 Data 0.0020 Loss 0.0165 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [157][200/391]	Time 0.1893 Data 0.0021 Loss 0.0174 (0.0164)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [157][300/391]	Time 0.1892 Data 0.0020 Loss 0.0159 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9515, Prec@1: 75.75, Prec@5: 92.52
Epoch time: 82s
Epoch: 158  lr: 0.001
Epoch: [158][000/391]	Time 1.4278 Data 1.2248 Loss 0.0128 (0.0128)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [158][100/391]	Time 0.1929 Data 0.0064 Loss 0.0159 (0.0158)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [158][200/391]	Time 0.1891 Data 0.0019 Loss 0.0154 (0.0161)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [158][300/391]	Time 0.1891 Data 0.0021 Loss 0.0164 (0.0163)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 75.89, Prec@5: 92.54
Epoch time: 82s
Epoch: 159  lr: 0.001
Epoch: [159][000/391]	Time 1.5042 Data 1.2797 Loss 0.0198 (0.0198)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [159][100/391]	Time 0.1894 Data 0.0020 Loss 0.0183 (0.0164)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [159][200/391]	Time 0.1888 Data 0.0019 Loss 0.0138 (0.0164)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [159][300/391]	Time 0.1904 Data 0.0021 Loss 0.0175 (0.0165)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9505, Prec@1: 76.01, Prec@5: 92.62
Epoch time: 82s
Epoch: 160  lr: 0.001
Epoch: [160][000/391]	Time 1.5163 Data 1.3367 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [160][100/391]	Time 0.1894 Data 0.0020 Loss 0.0195 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [160][200/391]	Time 0.1901 Data 0.0020 Loss 0.0177 (0.0162)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [160][300/391]	Time 0.1896 Data 0.0020 Loss 0.0163 (0.0164)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9505, Prec@1: 75.83, Prec@5: 92.61
Epoch time: 82s
Epoch: 161  lr: 0.001
Epoch: [161][000/391]	Time 1.5159 Data 1.3295 Loss 0.0150 (0.0150)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [161][100/391]	Time 0.1906 Data 0.0020 Loss 0.0185 (0.0162)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [161][200/391]	Time 0.1885 Data 0.0019 Loss 0.0098 (0.0166)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [161][300/391]	Time 0.1896 Data 0.0020 Loss 0.0144 (0.0165)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 75.81, Prec@5: 92.63
Epoch time: 82s
Epoch: 162  lr: 0.001
Epoch: [162][000/391]	Time 1.4382 Data 1.2600 Loss 0.0096 (0.0096)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][100/391]	Time 0.1885 Data 0.0030 Loss 0.0144 (0.0169)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [162][200/391]	Time 0.1889 Data 0.0020 Loss 0.0148 (0.0165)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [162][300/391]	Time 0.1887 Data 0.0020 Loss 0.0179 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9487, Prec@1: 75.92, Prec@5: 92.56
Epoch time: 82s
Epoch: 163  lr: 0.001
Epoch: [163][000/391]	Time 1.4884 Data 1.2679 Loss 0.0118 (0.0118)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [163][100/391]	Time 0.1894 Data 0.0022 Loss 0.0167 (0.0164)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [163][200/391]	Time 0.1889 Data 0.0026 Loss 0.0177 (0.0163)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [163][300/391]	Time 0.1890 Data 0.0020 Loss 0.0235 (0.0165)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9490, Prec@1: 75.95, Prec@5: 92.53
Epoch time: 82s
Epoch: 164  lr: 0.001
Epoch: [164][000/391]	Time 1.4872 Data 1.2884 Loss 0.0190 (0.0190)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [164][100/391]	Time 0.1956 Data 0.0021 Loss 0.0272 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [164][200/391]	Time 0.1904 Data 0.0020 Loss 0.0143 (0.0162)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [164][300/391]	Time 0.1935 Data 0.0020 Loss 0.0138 (0.0162)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9493, Prec@1: 75.94, Prec@5: 92.69
Epoch time: 82s
Epoch: 165  lr: 0.001
Epoch: [165][000/391]	Time 1.4521 Data 1.1967 Loss 0.0165 (0.0165)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][100/391]	Time 0.1894 Data 0.0019 Loss 0.0150 (0.0161)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [165][200/391]	Time 0.1907 Data 0.0019 Loss 0.0166 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [165][300/391]	Time 0.1889 Data 0.0020 Loss 0.0167 (0.0163)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9469, Prec@1: 75.86, Prec@5: 92.56
Epoch time: 82s
Epoch: 166  lr: 0.001
Epoch: [166][000/391]	Time 1.3943 Data 1.2440 Loss 0.0150 (0.0150)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [166][100/391]	Time 0.1906 Data 0.0019 Loss 0.0113 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [166][200/391]	Time 0.1894 Data 0.0020 Loss 0.0148 (0.0159)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [166][300/391]	Time 0.1904 Data 0.0020 Loss 0.0169 (0.0161)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9510, Prec@1: 75.88, Prec@5: 92.49
Epoch time: 82s
Epoch: 167  lr: 0.001
Epoch: [167][000/391]	Time 1.4919 Data 1.2918 Loss 0.0113 (0.0113)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][100/391]	Time 0.1897 Data 0.0023 Loss 0.0119 (0.0166)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [167][200/391]	Time 0.1924 Data 0.0022 Loss 0.0161 (0.0163)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [167][300/391]	Time 0.1899 Data 0.0029 Loss 0.0113 (0.0164)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9519, Prec@1: 75.76, Prec@5: 92.43
Epoch time: 82s
Epoch: 168  lr: 0.001
Epoch: [168][000/391]	Time 1.4291 Data 1.2094 Loss 0.0194 (0.0194)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][100/391]	Time 0.1886 Data 0.0020 Loss 0.0160 (0.0169)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [168][200/391]	Time 0.1898 Data 0.0021 Loss 0.0125 (0.0161)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [168][300/391]	Time 0.1896 Data 0.0019 Loss 0.0164 (0.0162)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9488, Prec@1: 76.03, Prec@5: 92.56
Epoch time: 82s
Epoch: 169  lr: 0.001
Epoch: [169][000/391]	Time 1.4379 Data 1.2630 Loss 0.0148 (0.0148)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][100/391]	Time 0.1890 Data 0.0021 Loss 0.0157 (0.0163)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [169][200/391]	Time 0.1894 Data 0.0019 Loss 0.0195 (0.0163)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [169][300/391]	Time 0.1890 Data 0.0019 Loss 0.0135 (0.0162)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9506, Prec@1: 75.86, Prec@5: 92.49
Epoch time: 82s
Epoch: 170  lr: 0.001
Epoch: [170][000/391]	Time 1.5163 Data 1.2897 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [170][100/391]	Time 0.1911 Data 0.0021 Loss 0.0172 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [170][200/391]	Time 0.1950 Data 0.0020 Loss 0.0175 (0.0163)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [170][300/391]	Time 0.1968 Data 0.0019 Loss 0.0197 (0.0162)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9487, Prec@1: 75.89, Prec@5: 92.47
Epoch time: 82s
Epoch: 171  lr: 0.001
Epoch: [171][000/391]	Time 1.4697 Data 1.3192 Loss 0.0123 (0.0123)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [171][100/391]	Time 0.1890 Data 0.0020 Loss 0.0143 (0.0157)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [171][200/391]	Time 0.1886 Data 0.0020 Loss 0.0181 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [171][300/391]	Time 0.1887 Data 0.0020 Loss 0.0207 (0.0157)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9478, Prec@1: 75.83, Prec@5: 92.55
Epoch time: 82s
Epoch: 172  lr: 0.001
Epoch: [172][000/391]	Time 1.4280 Data 1.2715 Loss 0.0202 (0.0202)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][100/391]	Time 0.1893 Data 0.0020 Loss 0.0179 (0.0169)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [172][200/391]	Time 0.1903 Data 0.0020 Loss 0.0110 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [172][300/391]	Time 0.1891 Data 0.0025 Loss 0.0134 (0.0163)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9500, Prec@1: 75.81, Prec@5: 92.60
Epoch time: 82s
Epoch: 173  lr: 0.001
Epoch: [173][000/391]	Time 1.4784 Data 1.2609 Loss 0.0171 (0.0171)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][100/391]	Time 0.1893 Data 0.0019 Loss 0.0161 (0.0162)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [173][200/391]	Time 0.1890 Data 0.0019 Loss 0.0160 (0.0163)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [173][300/391]	Time 0.1891 Data 0.0021 Loss 0.0123 (0.0162)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9494, Prec@1: 75.92, Prec@5: 92.62
Epoch time: 82s
Epoch: 174  lr: 0.001
Epoch: [174][000/391]	Time 1.4713 Data 1.2717 Loss 0.0153 (0.0153)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][100/391]	Time 0.1899 Data 0.0019 Loss 0.0139 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [174][200/391]	Time 0.1896 Data 0.0021 Loss 0.0176 (0.0158)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [174][300/391]	Time 0.1891 Data 0.0020 Loss 0.0166 (0.0160)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9467, Prec@1: 76.05, Prec@5: 92.56
Epoch time: 82s
Epoch: 175  lr: 0.001
Epoch: [175][000/391]	Time 1.5605 Data 1.3389 Loss 0.0117 (0.0117)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][100/391]	Time 0.1914 Data 0.0023 Loss 0.0184 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [175][200/391]	Time 0.1901 Data 0.0021 Loss 0.0126 (0.0163)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [175][300/391]	Time 0.1889 Data 0.0021 Loss 0.0266 (0.0165)	Acc@1 99.219 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9451, Prec@1: 75.95, Prec@5: 92.57
Epoch time: 82s
Epoch: 176  lr: 0.001
Epoch: [176][000/391]	Time 1.5578 Data 1.3321 Loss 0.0134 (0.0134)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][100/391]	Time 0.1895 Data 0.0020 Loss 0.0170 (0.0159)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [176][200/391]	Time 0.1890 Data 0.0020 Loss 0.0147 (0.0160)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [176][300/391]	Time 0.1901 Data 0.0020 Loss 0.0157 (0.0160)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9489, Prec@1: 75.92, Prec@5: 92.63
Epoch time: 82s
Epoch: 177  lr: 0.001
Epoch: [177][000/391]	Time 1.4081 Data 1.2510 Loss 0.0119 (0.0119)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [177][100/391]	Time 0.1890 Data 0.0020 Loss 0.0172 (0.0164)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [177][200/391]	Time 0.1915 Data 0.0020 Loss 0.0112 (0.0161)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [177][300/391]	Time 0.1897 Data 0.0020 Loss 0.0161 (0.0160)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9504, Prec@1: 75.88, Prec@5: 92.59
Epoch time: 82s
Epoch: 178  lr: 0.001
Epoch: [178][000/391]	Time 1.5067 Data 1.3272 Loss 0.0149 (0.0149)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][100/391]	Time 0.1897 Data 0.0025 Loss 0.0147 (0.0159)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [178][200/391]	Time 0.1905 Data 0.0029 Loss 0.0213 (0.0157)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [178][300/391]	Time 0.1902 Data 0.0029 Loss 0.0094 (0.0159)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9478, Prec@1: 75.92, Prec@5: 92.62
Epoch time: 82s
Epoch: 179  lr: 0.001
Epoch: [179][000/391]	Time 1.5417 Data 1.2700 Loss 0.0162 (0.0162)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][100/391]	Time 0.1917 Data 0.0020 Loss 0.0221 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [179][200/391]	Time 0.1890 Data 0.0020 Loss 0.0129 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [179][300/391]	Time 0.1888 Data 0.0020 Loss 0.0159 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9501, Prec@1: 75.97, Prec@5: 92.53
Epoch time: 82s
Epoch: 180  lr: 0.001
Epoch: [180][000/391]	Time 1.4407 Data 1.2374 Loss 0.0209 (0.0209)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][100/391]	Time 0.1890 Data 0.0020 Loss 0.0160 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [180][200/391]	Time 0.1920 Data 0.0021 Loss 0.0138 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [180][300/391]	Time 0.1894 Data 0.0020 Loss 0.0124 (0.0160)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9501, Prec@1: 75.97, Prec@5: 92.54
Epoch time: 82s
Epoch: 181  lr: 0.001
Epoch: [181][000/391]	Time 1.4177 Data 1.2456 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [181][100/391]	Time 0.1902 Data 0.0021 Loss 0.0136 (0.0157)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [181][200/391]	Time 0.1891 Data 0.0023 Loss 0.0136 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [181][300/391]	Time 0.1894 Data 0.0019 Loss 0.0176 (0.0162)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9486, Prec@1: 75.99, Prec@5: 92.60
Epoch time: 82s
Epoch: 182  lr: 0.001
Epoch: [182][000/391]	Time 1.4322 Data 1.2200 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [182][100/391]	Time 0.1903 Data 0.0019 Loss 0.0185 (0.0156)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [182][200/391]	Time 0.1897 Data 0.0020 Loss 0.0179 (0.0160)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [182][300/391]	Time 0.1955 Data 0.0021 Loss 0.0141 (0.0161)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9492, Prec@1: 76.02, Prec@5: 92.58
Epoch time: 82s
Epoch: 183  lr: 0.001
Epoch: [183][000/391]	Time 1.4687 Data 1.2915 Loss 0.0223 (0.0223)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [183][100/391]	Time 0.1890 Data 0.0020 Loss 0.0151 (0.0162)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [183][200/391]	Time 0.1897 Data 0.0020 Loss 0.0128 (0.0161)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [183][300/391]	Time 0.1914 Data 0.0019 Loss 0.0161 (0.0160)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9487, Prec@1: 76.09, Prec@5: 92.50
Epoch time: 82s
Epoch: 184  lr: 0.001
Epoch: [184][000/391]	Time 1.4556 Data 1.2494 Loss 0.0244 (0.0244)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [184][100/391]	Time 0.1896 Data 0.0024 Loss 0.0172 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [184][200/391]	Time 0.1920 Data 0.0020 Loss 0.0215 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [184][300/391]	Time 0.1939 Data 0.0024 Loss 0.0151 (0.0157)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9483, Prec@1: 75.87, Prec@5: 92.64
Epoch time: 82s
Epoch: 185  lr: 0.001
Epoch: [185][000/391]	Time 1.4707 Data 1.3106 Loss 0.0205 (0.0205)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [185][100/391]	Time 0.1892 Data 0.0024 Loss 0.0162 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [185][200/391]	Time 0.1896 Data 0.0027 Loss 0.0122 (0.0166)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [185][300/391]	Time 0.1894 Data 0.0020 Loss 0.0130 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9483, Prec@1: 75.96, Prec@5: 92.54
Epoch time: 82s
Epoch: 186  lr: 0.001
Epoch: [186][000/391]	Time 1.3997 Data 1.2406 Loss 0.0193 (0.0193)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [186][100/391]	Time 0.1890 Data 0.0020 Loss 0.0166 (0.0162)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [186][200/391]	Time 0.1901 Data 0.0021 Loss 0.0113 (0.0162)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [186][300/391]	Time 0.1893 Data 0.0021 Loss 0.0169 (0.0159)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9483, Prec@1: 75.92, Prec@5: 92.59
Epoch time: 82s
Epoch: 187  lr: 0.001
Epoch: [187][000/391]	Time 1.4364 Data 1.2356 Loss 0.0181 (0.0181)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [187][100/391]	Time 0.1891 Data 0.0019 Loss 0.0110 (0.0157)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [187][200/391]	Time 0.1899 Data 0.0021 Loss 0.0187 (0.0157)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [187][300/391]	Time 0.1895 Data 0.0020 Loss 0.0185 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9484, Prec@1: 76.11, Prec@5: 92.55
Epoch time: 82s
Epoch: 188  lr: 0.001
Epoch: [188][000/391]	Time 1.4590 Data 1.2804 Loss 0.0124 (0.0124)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [188][100/391]	Time 0.1904 Data 0.0024 Loss 0.0140 (0.0156)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [188][200/391]	Time 0.1910 Data 0.0030 Loss 0.0143 (0.0160)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [188][300/391]	Time 0.1902 Data 0.0020 Loss 0.0141 (0.0160)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9486, Prec@1: 75.98, Prec@5: 92.65
Epoch time: 82s
Epoch: 189  lr: 0.001
Epoch: [189][000/391]	Time 1.4709 Data 1.2069 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [189][100/391]	Time 0.1891 Data 0.0019 Loss 0.0151 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [189][200/391]	Time 0.1903 Data 0.0020 Loss 0.0206 (0.0159)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [189][300/391]	Time 0.1887 Data 0.0019 Loss 0.0139 (0.0159)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9470, Prec@1: 76.02, Prec@5: 92.61
Epoch time: 82s
Epoch: 190  lr: 0.001
Epoch: [190][000/391]	Time 1.5362 Data 1.3357 Loss 0.0193 (0.0193)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [190][100/391]	Time 0.1892 Data 0.0019 Loss 0.0238 (0.0166)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Epoch: [190][200/391]	Time 0.1894 Data 0.0021 Loss 0.0160 (0.0162)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [190][300/391]	Time 0.1892 Data 0.0019 Loss 0.0231 (0.0162)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9498, Prec@1: 75.84, Prec@5: 92.65
Epoch time: 82s
Epoch: 191  lr: 0.001
Epoch: [191][000/391]	Time 1.5313 Data 1.3375 Loss 0.0201 (0.0201)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [191][100/391]	Time 0.1894 Data 0.0024 Loss 0.0147 (0.0158)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [191][200/391]	Time 0.1894 Data 0.0020 Loss 0.0144 (0.0158)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [191][300/391]	Time 0.1896 Data 0.0020 Loss 0.0160 (0.0159)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9467, Prec@1: 76.06, Prec@5: 92.61
Epoch time: 82s
Epoch: 192  lr: 0.001
Epoch: [192][000/391]	Time 1.5159 Data 1.3285 Loss 0.0186 (0.0186)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [192][100/391]	Time 0.1919 Data 0.0020 Loss 0.0158 (0.0157)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [192][200/391]	Time 0.1908 Data 0.0021 Loss 0.0137 (0.0157)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [192][300/391]	Time 0.1904 Data 0.0022 Loss 0.0174 (0.0157)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9490, Prec@1: 75.98, Prec@5: 92.52
Epoch time: 82s
Epoch: 193  lr: 0.001
Epoch: [193][000/391]	Time 1.4723 Data 1.2785 Loss 0.0153 (0.0153)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [193][100/391]	Time 0.1888 Data 0.0021 Loss 0.0205 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [193][200/391]	Time 0.1887 Data 0.0019 Loss 0.0193 (0.0162)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [193][300/391]	Time 0.1899 Data 0.0019 Loss 0.0308 (0.0161)	Acc@1 99.219 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9470, Prec@1: 75.98, Prec@5: 92.63
Epoch time: 82s
Epoch: 194  lr: 0.001
Epoch: [194][000/391]	Time 1.4626 Data 1.2000 Loss 0.0143 (0.0143)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [194][100/391]	Time 0.1894 Data 0.0020 Loss 0.0165 (0.0158)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [194][200/391]	Time 0.1893 Data 0.0021 Loss 0.0159 (0.0162)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [194][300/391]	Time 0.1898 Data 0.0021 Loss 0.0108 (0.0160)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9497, Prec@1: 75.74, Prec@5: 92.57
Epoch time: 82s
Epoch: 195  lr: 0.001
Epoch: [195][000/391]	Time 1.4260 Data 1.1693 Loss 0.0135 (0.0135)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [195][100/391]	Time 0.1890 Data 0.0023 Loss 0.0175 (0.0160)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [195][200/391]	Time 0.1890 Data 0.0019 Loss 0.0142 (0.0159)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [195][300/391]	Time 0.1894 Data 0.0020 Loss 0.0127 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9470, Prec@1: 75.89, Prec@5: 92.52
Epoch time: 82s
Epoch: 196  lr: 0.001
Epoch: [196][000/391]	Time 1.4166 Data 1.2593 Loss 0.0108 (0.0108)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [196][100/391]	Time 0.1892 Data 0.0021 Loss 0.0153 (0.0160)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [196][200/391]	Time 0.1887 Data 0.0020 Loss 0.0168 (0.0161)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [196][300/391]	Time 0.1893 Data 0.0019 Loss 0.0171 (0.0161)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9498, Prec@1: 75.75, Prec@5: 92.58
Epoch time: 82s
Epoch: 197  lr: 0.001
Epoch: [197][000/391]	Time 1.4556 Data 1.1910 Loss 0.0263 (0.0263)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [197][100/391]	Time 0.1922 Data 0.0020 Loss 0.0335 (0.0160)	Acc@1 99.219 (99.923)	Acc@5 100.000 (100.000)
Epoch: [197][200/391]	Time 0.1896 Data 0.0022 Loss 0.0266 (0.0162)	Acc@1 99.219 (99.942)	Acc@5 100.000 (100.000)
Epoch: [197][300/391]	Time 0.1980 Data 0.0020 Loss 0.0118 (0.0160)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9476, Prec@1: 75.91, Prec@5: 92.63
Epoch time: 82s
Epoch: 198  lr: 0.001
Epoch: [198][000/391]	Time 1.4751 Data 1.3224 Loss 0.0181 (0.0181)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [198][100/391]	Time 0.1915 Data 0.0021 Loss 0.0188 (0.0158)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [198][200/391]	Time 0.1898 Data 0.0020 Loss 0.0274 (0.0159)	Acc@1 99.219 (99.973)	Acc@5 100.000 (100.000)
Epoch: [198][300/391]	Time 0.1895 Data 0.0020 Loss 0.0181 (0.0158)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9471, Prec@1: 76.00, Prec@5: 92.76
Epoch time: 82s
Epoch: 199  lr: 0.001
Epoch: [199][000/391]	Time 1.4666 Data 1.3084 Loss 0.0157 (0.0157)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [199][100/391]	Time 0.1892 Data 0.0020 Loss 0.0117 (0.0157)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [199][200/391]	Time 0.1896 Data 0.0020 Loss 0.0147 (0.0159)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [199][300/391]	Time 0.1901 Data 0.0035 Loss 0.0117 (0.0161)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9491, Prec@1: 75.78, Prec@5: 92.52
Epoch time: 82s
Epoch: 200  lr: 0.001
Epoch: [200][000/391]	Time 1.4976 Data 1.3015 Loss 0.0097 (0.0097)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [200][100/391]	Time 0.1906 Data 0.0023 Loss 0.0176 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [200][200/391]	Time 0.1893 Data 0.0023 Loss 0.0131 (0.0158)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [200][300/391]	Time 0.1892 Data 0.0022 Loss 0.0109 (0.0158)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9467, Prec@1: 75.97, Prec@5: 92.74
Epoch time: 82s
Epoch: 201  lr: 0.001
Epoch: [201][000/391]	Time 1.4631 Data 1.3128 Loss 0.0150 (0.0150)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [201][100/391]	Time 0.1894 Data 0.0022 Loss 0.0165 (0.0155)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [201][200/391]	Time 0.1886 Data 0.0019 Loss 0.0139 (0.0156)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [201][300/391]	Time 0.1919 Data 0.0020 Loss 0.0179 (0.0159)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9489, Prec@1: 75.86, Prec@5: 92.51
Epoch time: 82s
Epoch: 202  lr: 0.001
Epoch: [202][000/391]	Time 1.3948 Data 1.1758 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [202][100/391]	Time 0.1893 Data 0.0021 Loss 0.0166 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [202][200/391]	Time 0.1898 Data 0.0020 Loss 0.0189 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [202][300/391]	Time 0.1887 Data 0.0020 Loss 0.0148 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9490, Prec@1: 75.85, Prec@5: 92.63
Epoch time: 82s
Epoch: 203  lr: 0.001
Epoch: [203][000/391]	Time 1.5205 Data 1.3018 Loss 0.0086 (0.0086)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [203][100/391]	Time 0.1953 Data 0.0019 Loss 0.0144 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [203][200/391]	Time 0.1915 Data 0.0021 Loss 0.0143 (0.0159)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [203][300/391]	Time 0.1925 Data 0.0021 Loss 0.0113 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9492, Prec@1: 75.93, Prec@5: 92.51
Epoch time: 82s
Epoch: 204  lr: 0.001
Epoch: [204][000/391]	Time 1.4718 Data 1.2591 Loss 0.0162 (0.0162)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [204][100/391]	Time 0.1930 Data 0.0021 Loss 0.0126 (0.0160)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [204][200/391]	Time 0.1946 Data 0.0019 Loss 0.0151 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [204][300/391]	Time 0.1889 Data 0.0020 Loss 0.0144 (0.0160)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9486, Prec@1: 76.00, Prec@5: 92.55
Epoch time: 82s
Epoch: 205  lr: 0.001
Epoch: [205][000/391]	Time 1.5043 Data 1.3440 Loss 0.0159 (0.0159)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [205][100/391]	Time 0.1888 Data 0.0021 Loss 0.0162 (0.0155)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [205][200/391]	Time 0.1892 Data 0.0022 Loss 0.0136 (0.0156)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [205][300/391]	Time 0.1905 Data 0.0030 Loss 0.0131 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9453, Prec@1: 76.18, Prec@5: 92.69
Epoch time: 82s
Saving models
Epoch: 206  lr: 0.001
Epoch: [206][000/391]	Time 1.4575 Data 1.2471 Loss 0.0126 (0.0126)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [206][100/391]	Time 0.1900 Data 0.0023 Loss 0.0169 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [206][200/391]	Time 0.1915 Data 0.0025 Loss 0.0135 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [206][300/391]	Time 0.1939 Data 0.0019 Loss 0.0133 (0.0160)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9484, Prec@1: 75.81, Prec@5: 92.58
Epoch time: 82s
Epoch: 207  lr: 0.001
Epoch: [207][000/391]	Time 1.4444 Data 1.2572 Loss 0.0186 (0.0186)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [207][100/391]	Time 0.1889 Data 0.0019 Loss 0.0129 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [207][200/391]	Time 0.1915 Data 0.0020 Loss 0.0182 (0.0157)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [207][300/391]	Time 0.1890 Data 0.0020 Loss 0.0166 (0.0156)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9470, Prec@1: 76.10, Prec@5: 92.70
Epoch time: 82s
Epoch: 208  lr: 0.001
Epoch: [208][000/391]	Time 1.4723 Data 1.2469 Loss 0.0134 (0.0134)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [208][100/391]	Time 0.1890 Data 0.0021 Loss 0.0173 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [208][200/391]	Time 0.1889 Data 0.0020 Loss 0.0124 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [208][300/391]	Time 0.1914 Data 0.0021 Loss 0.0126 (0.0159)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9459, Prec@1: 76.08, Prec@5: 92.64
Epoch time: 82s
Epoch: 209  lr: 0.001
Epoch: [209][000/391]	Time 1.4649 Data 1.2499 Loss 0.0165 (0.0165)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [209][100/391]	Time 0.1892 Data 0.0019 Loss 0.0181 (0.0157)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [209][200/391]	Time 0.1910 Data 0.0020 Loss 0.0168 (0.0158)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [209][300/391]	Time 0.1898 Data 0.0021 Loss 0.0149 (0.0157)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9480, Prec@1: 75.97, Prec@5: 92.56
Epoch time: 82s
Epoch: 210  lr: 0.001
Epoch: [210][000/391]	Time 1.3777 Data 1.1591 Loss 0.0152 (0.0152)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [210][100/391]	Time 0.1885 Data 0.0022 Loss 0.0215 (0.0160)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [210][200/391]	Time 0.1898 Data 0.0019 Loss 0.0125 (0.0159)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [210][300/391]	Time 0.1884 Data 0.0020 Loss 0.0174 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9491, Prec@1: 76.01, Prec@5: 92.58
Epoch time: 82s
Epoch: 211  lr: 0.001
Epoch: [211][000/391]	Time 1.5155 Data 1.3153 Loss 0.0181 (0.0181)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [211][100/391]	Time 0.1931 Data 0.0028 Loss 0.0174 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [211][200/391]	Time 0.1908 Data 0.0020 Loss 0.0169 (0.0158)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [211][300/391]	Time 0.1889 Data 0.0020 Loss 0.0162 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9490, Prec@1: 75.94, Prec@5: 92.51
Epoch time: 82s
Epoch: 212  lr: 0.001
Epoch: [212][000/391]	Time 1.4433 Data 1.2661 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [212][100/391]	Time 0.1889 Data 0.0023 Loss 0.0131 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [212][200/391]	Time 0.1887 Data 0.0019 Loss 0.0122 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [212][300/391]	Time 0.1908 Data 0.0020 Loss 0.0180 (0.0158)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 76.03, Prec@5: 92.61
Epoch time: 82s
Epoch: 213  lr: 0.001
Epoch: [213][000/391]	Time 1.5393 Data 1.3190 Loss 0.0134 (0.0134)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [213][100/391]	Time 0.1888 Data 0.0019 Loss 0.0140 (0.0154)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [213][200/391]	Time 0.1889 Data 0.0020 Loss 0.0165 (0.0159)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [213][300/391]	Time 0.1892 Data 0.0020 Loss 0.0138 (0.0159)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9496, Prec@1: 75.79, Prec@5: 92.66
Epoch time: 82s
Epoch: 214  lr: 0.001
Epoch: [214][000/391]	Time 1.5421 Data 1.3184 Loss 0.0136 (0.0136)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [214][100/391]	Time 0.1883 Data 0.0020 Loss 0.0102 (0.0157)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [214][200/391]	Time 0.1905 Data 0.0020 Loss 0.0151 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [214][300/391]	Time 0.1887 Data 0.0020 Loss 0.0129 (0.0156)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9482, Prec@1: 75.94, Prec@5: 92.61
Epoch time: 82s
Epoch: 215  lr: 0.001
Epoch: [215][000/391]	Time 1.4443 Data 1.2487 Loss 0.0144 (0.0144)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [215][100/391]	Time 0.1894 Data 0.0020 Loss 0.0230 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [215][200/391]	Time 0.1907 Data 0.0019 Loss 0.0211 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [215][300/391]	Time 0.1906 Data 0.0023 Loss 0.0158 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9549, Prec@1: 75.64, Prec@5: 92.48
Epoch time: 82s
Epoch: 216  lr: 0.001
Epoch: [216][000/391]	Time 1.4767 Data 1.3162 Loss 0.0125 (0.0125)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [216][100/391]	Time 0.1898 Data 0.0019 Loss 0.0130 (0.0153)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [216][200/391]	Time 0.1889 Data 0.0021 Loss 0.0182 (0.0154)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [216][300/391]	Time 0.1925 Data 0.0019 Loss 0.0155 (0.0156)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9478, Prec@1: 76.18, Prec@5: 92.60
Epoch time: 82s
Epoch: 217  lr: 0.001
Epoch: [217][000/391]	Time 1.4663 Data 1.3334 Loss 0.0173 (0.0173)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [217][100/391]	Time 0.1896 Data 0.0021 Loss 0.0172 (0.0148)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [217][200/391]	Time 0.1892 Data 0.0022 Loss 0.0115 (0.0153)	Acc@1 100.000 (99.988)	Acc@5 100.000 (100.000)
Epoch: [217][300/391]	Time 0.1888 Data 0.0019 Loss 0.0132 (0.0155)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 75.92, Prec@5: 92.51
Epoch time: 82s
Epoch: 218  lr: 0.001
Epoch: [218][000/391]	Time 1.4894 Data 1.2356 Loss 0.0133 (0.0133)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [218][100/391]	Time 0.1891 Data 0.0020 Loss 0.0185 (0.0161)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [218][200/391]	Time 0.1906 Data 0.0020 Loss 0.0128 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [218][300/391]	Time 0.1914 Data 0.0063 Loss 0.0184 (0.0160)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9532, Prec@1: 75.65, Prec@5: 92.41
Epoch time: 82s
Epoch: 219  lr: 0.001
Epoch: [219][000/391]	Time 1.2379 Data 0.9719 Loss 0.0204 (0.0204)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [219][100/391]	Time 0.1902 Data 0.0020 Loss 0.0117 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [219][200/391]	Time 0.1890 Data 0.0020 Loss 0.0158 (0.0161)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [219][300/391]	Time 0.1920 Data 0.0021 Loss 0.0138 (0.0159)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9464, Prec@1: 76.05, Prec@5: 92.53
Epoch time: 82s
Epoch: 220  lr: 0.001
Epoch: [220][000/391]	Time 1.5622 Data 1.4017 Loss 0.0179 (0.0179)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [220][100/391]	Time 0.1882 Data 0.0020 Loss 0.0150 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [220][200/391]	Time 0.1914 Data 0.0022 Loss 0.0140 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [220][300/391]	Time 0.1894 Data 0.0021 Loss 0.0181 (0.0158)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9488, Prec@1: 76.10, Prec@5: 92.65
Epoch time: 82s
Epoch: 221  lr: 0.001
Epoch: [221][000/391]	Time 1.4037 Data 1.2425 Loss 0.0194 (0.0194)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [221][100/391]	Time 0.1905 Data 0.0020 Loss 0.0262 (0.0160)	Acc@1 99.219 (99.969)	Acc@5 100.000 (100.000)
Epoch: [221][200/391]	Time 0.1932 Data 0.0021 Loss 0.0137 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [221][300/391]	Time 0.1977 Data 0.0020 Loss 0.0137 (0.0157)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9474, Prec@1: 75.94, Prec@5: 92.65
Epoch time: 82s
Epoch: 222  lr: 0.001
Epoch: [222][000/391]	Time 1.5360 Data 1.3165 Loss 0.0165 (0.0165)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [222][100/391]	Time 0.1893 Data 0.0020 Loss 0.0161 (0.0160)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [222][200/391]	Time 0.1890 Data 0.0019 Loss 0.0178 (0.0158)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [222][300/391]	Time 0.1894 Data 0.0020 Loss 0.0138 (0.0158)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9495, Prec@1: 75.80, Prec@5: 92.50
Epoch time: 82s
Epoch: 223  lr: 0.001
Epoch: [223][000/391]	Time 1.4789 Data 1.3183 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [223][100/391]	Time 0.1892 Data 0.0020 Loss 0.0129 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [223][200/391]	Time 0.1894 Data 0.0019 Loss 0.0109 (0.0155)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [223][300/391]	Time 0.1893 Data 0.0021 Loss 0.0152 (0.0159)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9473, Prec@1: 76.19, Prec@5: 92.65
Epoch time: 82s
Saving models
Epoch: 224  lr: 0.001
Epoch: [224][000/391]	Time 1.5172 Data 1.3271 Loss 0.0125 (0.0125)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [224][100/391]	Time 0.1892 Data 0.0026 Loss 0.0169 (0.0157)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [224][200/391]	Time 0.1898 Data 0.0025 Loss 0.0154 (0.0160)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [224][300/391]	Time 0.1888 Data 0.0023 Loss 0.0254 (0.0158)	Acc@1 99.219 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9497, Prec@1: 75.96, Prec@5: 92.60
Epoch time: 82s
Epoch: 225  lr: 0.001
Epoch: [225][000/391]	Time 1.5025 Data 1.3054 Loss 0.0206 (0.0206)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [225][100/391]	Time 0.1956 Data 0.0021 Loss 0.0162 (0.0154)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [225][200/391]	Time 0.1903 Data 0.0021 Loss 0.0149 (0.0153)	Acc@1 100.000 (99.988)	Acc@5 100.000 (100.000)
Epoch: [225][300/391]	Time 0.1902 Data 0.0024 Loss 0.0108 (0.0154)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9500, Prec@1: 75.94, Prec@5: 92.49
Epoch time: 82s
Epoch: 226  lr: 0.001
Epoch: [226][000/391]	Time 1.4108 Data 1.2167 Loss 0.0201 (0.0201)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [226][100/391]	Time 0.1892 Data 0.0020 Loss 0.0191 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [226][200/391]	Time 0.1894 Data 0.0020 Loss 0.0165 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [226][300/391]	Time 0.1891 Data 0.0021 Loss 0.0126 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9475, Prec@1: 76.06, Prec@5: 92.56
Epoch time: 82s
Epoch: 227  lr: 0.001
Epoch: [227][000/391]	Time 1.5002 Data 1.3481 Loss 0.0189 (0.0189)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [227][100/391]	Time 0.1881 Data 0.0019 Loss 0.0138 (0.0152)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [227][200/391]	Time 0.1891 Data 0.0021 Loss 0.0133 (0.0156)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [227][300/391]	Time 0.1895 Data 0.0020 Loss 0.0213 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9502, Prec@1: 75.78, Prec@5: 92.55
Epoch time: 82s
Epoch: 228  lr: 0.001
Epoch: [228][000/391]	Time 1.4576 Data 1.2760 Loss 0.0101 (0.0101)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [228][100/391]	Time 0.1888 Data 0.0021 Loss 0.0154 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [228][200/391]	Time 0.1915 Data 0.0021 Loss 0.0122 (0.0160)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [228][300/391]	Time 0.1908 Data 0.0020 Loss 0.0233 (0.0159)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9479, Prec@1: 75.90, Prec@5: 92.52
Epoch time: 82s
Epoch: 229  lr: 0.001
Epoch: [229][000/391]	Time 1.4165 Data 1.2169 Loss 0.0132 (0.0132)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [229][100/391]	Time 0.1920 Data 0.0019 Loss 0.0115 (0.0152)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [229][200/391]	Time 0.1908 Data 0.0019 Loss 0.0161 (0.0156)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [229][300/391]	Time 0.1935 Data 0.0020 Loss 0.0142 (0.0157)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9493, Prec@1: 76.00, Prec@5: 92.57
Epoch time: 82s
Epoch: 230  lr: 0.001
Epoch: [230][000/391]	Time 1.5193 Data 1.3306 Loss 0.0152 (0.0152)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [230][100/391]	Time 0.1916 Data 0.0020 Loss 0.0114 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [230][200/391]	Time 0.1899 Data 0.0020 Loss 0.0120 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [230][300/391]	Time 0.1915 Data 0.0023 Loss 0.0105 (0.0156)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9465, Prec@1: 76.13, Prec@5: 92.66
Epoch time: 82s
Epoch: 231  lr: 0.001
Epoch: [231][000/391]	Time 1.4464 Data 1.2632 Loss 0.0239 (0.0239)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [231][100/391]	Time 0.1951 Data 0.0023 Loss 0.0276 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [231][200/391]	Time 0.1941 Data 0.0021 Loss 0.0128 (0.0156)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [231][300/391]	Time 0.1896 Data 0.0020 Loss 0.0158 (0.0156)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9504, Prec@1: 75.93, Prec@5: 92.62
Epoch time: 82s
Epoch: 232  lr: 0.001
Epoch: [232][000/391]	Time 1.4314 Data 1.2849 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [232][100/391]	Time 0.1887 Data 0.0019 Loss 0.0173 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [232][200/391]	Time 0.1889 Data 0.0019 Loss 0.0139 (0.0158)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [232][300/391]	Time 0.1897 Data 0.0021 Loss 0.0123 (0.0158)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9480, Prec@1: 76.10, Prec@5: 92.57
Epoch time: 82s
Epoch: 233  lr: 0.001
Epoch: [233][000/391]	Time 1.4009 Data 1.1846 Loss 0.0133 (0.0133)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [233][100/391]	Time 0.1890 Data 0.0019 Loss 0.0125 (0.0156)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [233][200/391]	Time 0.1898 Data 0.0021 Loss 0.0144 (0.0158)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [233][300/391]	Time 0.1892 Data 0.0020 Loss 0.0135 (0.0156)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9502, Prec@1: 76.02, Prec@5: 92.64
Epoch time: 82s
Epoch: 234  lr: 0.001
Epoch: [234][000/391]	Time 1.4407 Data 1.2455 Loss 0.0164 (0.0164)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [234][100/391]	Time 0.1907 Data 0.0019 Loss 0.0112 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [234][200/391]	Time 0.1894 Data 0.0019 Loss 0.0103 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [234][300/391]	Time 0.1882 Data 0.0019 Loss 0.0165 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9456, Prec@1: 76.15, Prec@5: 92.56
Epoch time: 82s
Epoch: 235  lr: 0.001
Epoch: [235][000/391]	Time 1.4222 Data 1.2612 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [235][100/391]	Time 0.1888 Data 0.0019 Loss 0.0137 (0.0157)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [235][200/391]	Time 0.1895 Data 0.0020 Loss 0.0156 (0.0158)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [235][300/391]	Time 0.1888 Data 0.0020 Loss 0.0181 (0.0158)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9510, Prec@1: 76.01, Prec@5: 92.38
Epoch time: 82s
Epoch: 236  lr: 0.001
Epoch: [236][000/391]	Time 1.5106 Data 1.3658 Loss 0.0186 (0.0186)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [236][100/391]	Time 0.1889 Data 0.0019 Loss 0.0204 (0.0155)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [236][200/391]	Time 0.1895 Data 0.0019 Loss 0.0149 (0.0156)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [236][300/391]	Time 0.1886 Data 0.0019 Loss 0.0171 (0.0157)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9469, Prec@1: 76.07, Prec@5: 92.59
Epoch time: 82s
Epoch: 237  lr: 0.001
Epoch: [237][000/391]	Time 1.4655 Data 1.2497 Loss 0.0135 (0.0135)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [237][100/391]	Time 0.1888 Data 0.0019 Loss 0.0169 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [237][200/391]	Time 0.1893 Data 0.0021 Loss 0.0123 (0.0157)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [237][300/391]	Time 0.1893 Data 0.0020 Loss 0.0122 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9487, Prec@1: 76.01, Prec@5: 92.55
Epoch time: 82s
Epoch: 238  lr: 0.001
Epoch: [238][000/391]	Time 1.4542 Data 1.2439 Loss 0.0121 (0.0121)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [238][100/391]	Time 0.1891 Data 0.0021 Loss 0.0196 (0.0154)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [238][200/391]	Time 0.1895 Data 0.0020 Loss 0.0117 (0.0154)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [238][300/391]	Time 0.1893 Data 0.0024 Loss 0.0143 (0.0155)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 76.03, Prec@5: 92.53
Epoch time: 82s
Epoch: 239  lr: 0.001
Epoch: [239][000/391]	Time 1.5776 Data 1.3404 Loss 0.0161 (0.0161)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [239][100/391]	Time 0.1889 Data 0.0020 Loss 0.0213 (0.0161)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [239][200/391]	Time 0.1900 Data 0.0021 Loss 0.0120 (0.0162)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [239][300/391]	Time 0.1906 Data 0.0020 Loss 0.0150 (0.0160)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9481, Prec@1: 76.19, Prec@5: 92.60
Epoch time: 82s
Epoch: 240  lr: 0.001
Epoch: [240][000/391]	Time 1.4473 Data 1.2455 Loss 0.0120 (0.0120)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [240][100/391]	Time 0.1895 Data 0.0021 Loss 0.0179 (0.0156)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [240][200/391]	Time 0.1897 Data 0.0021 Loss 0.0155 (0.0153)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [240][300/391]	Time 0.1893 Data 0.0022 Loss 0.0129 (0.0155)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9485, Prec@1: 75.95, Prec@5: 92.49
Epoch time: 82s

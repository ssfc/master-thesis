opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=1, distill='kd', epochs=240, log_name='1-1-1-0.txt', lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, noise=0, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
Epoch: [1][000/391]	Time 2.4341 Data 0.8836 Loss 4.8255 (4.8255)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)
Epoch: [1][100/391]	Time 0.1854 Data 0.0020 Loss 4.5625 (5.3681)	Acc@1 4.688 (1.191)	Acc@5 12.500 (5.747)
Epoch: [1][200/391]	Time 0.1893 Data 0.0021 Loss 4.6682 (5.0566)	Acc@1 0.781 (1.088)	Acc@5 5.469 (5.418)
Epoch: [1][300/391]	Time 0.1859 Data 0.0020 Loss 5.0328 (4.9659)	Acc@1 1.562 (1.082)	Acc@5 4.688 (5.427)
Testing the models......
Loss: 5.3761, Prec@1: 1.55, Prec@5: 8.24
Epoch time: 83s
Saving models
Epoch: 2  lr: 0.100
Epoch: [2][000/391]	Time 1.0947 Data 0.9039 Loss 4.5759 (4.5759)	Acc@1 1.562 (1.562)	Acc@5 7.031 (7.031)
Epoch: [2][100/391]	Time 0.1868 Data 0.0020 Loss 4.6755 (4.7406)	Acc@1 3.125 (1.818)	Acc@5 9.375 (8.060)
Epoch: [2][200/391]	Time 0.1876 Data 0.0019 Loss 4.8462 (4.7372)	Acc@1 2.344 (2.223)	Acc@5 10.156 (8.967)
Epoch: [2][300/391]	Time 0.1870 Data 0.0019 Loss 4.6263 (4.6895)	Acc@1 3.906 (2.416)	Acc@5 18.750 (10.148)
Testing the models......
Loss: 4.5603, Prec@1: 3.44, Prec@5: 16.41
Epoch time: 80s
Saving models
Epoch: 3  lr: 0.100
Epoch: [3][000/391]	Time 1.0786 Data 0.8134 Loss 4.2954 (4.2954)	Acc@1 3.906 (3.906)	Acc@5 16.406 (16.406)
Epoch: [3][100/391]	Time 0.1875 Data 0.0021 Loss 4.4752 (4.4188)	Acc@1 4.688 (3.922)	Acc@5 18.750 (17.249)
Epoch: [3][200/391]	Time 0.1870 Data 0.0023 Loss 4.1754 (4.4117)	Acc@1 4.688 (4.124)	Acc@5 19.531 (17.926)
Epoch: [3][300/391]	Time 0.1878 Data 0.0020 Loss 4.2587 (4.3967)	Acc@1 3.906 (4.394)	Acc@5 18.750 (18.740)
Testing the models......
Loss: 4.2612, Prec@1: 6.26, Prec@5: 23.38
Epoch time: 80s
Saving models
Epoch: 4  lr: 0.100
Epoch: [4][000/391]	Time 1.1074 Data 0.8274 Loss 4.1649 (4.1649)	Acc@1 7.031 (7.031)	Acc@5 22.656 (22.656)
Epoch: [4][100/391]	Time 0.1870 Data 0.0022 Loss 4.2956 (4.2733)	Acc@1 4.688 (5.972)	Acc@5 17.969 (22.873)
Epoch: [4][200/391]	Time 0.1870 Data 0.0020 Loss 3.9919 (4.2529)	Acc@1 11.719 (6.526)	Acc@5 35.938 (23.745)
Epoch: [4][300/391]	Time 0.1885 Data 0.0021 Loss 3.9731 (4.2210)	Acc@1 13.281 (6.998)	Acc@5 34.375 (24.956)
Testing the models......
Loss: 4.1436, Prec@1: 9.50, Prec@5: 30.82
Epoch time: 80s
Saving models
Epoch: 5  lr: 0.100
Epoch: [5][000/391]	Time 1.0845 Data 0.8113 Loss 4.3508 (4.3508)	Acc@1 7.812 (7.812)	Acc@5 25.000 (25.000)
Epoch: [5][100/391]	Time 0.1875 Data 0.0020 Loss 4.1016 (4.0153)	Acc@1 16.406 (9.746)	Acc@5 31.250 (31.157)
Epoch: [5][200/391]	Time 0.1875 Data 0.0019 Loss 3.9310 (3.9947)	Acc@1 12.500 (10.557)	Acc@5 31.250 (32.253)
Epoch: [5][300/391]	Time 0.1875 Data 0.0021 Loss 3.7336 (3.9645)	Acc@1 10.156 (10.982)	Acc@5 31.250 (33.233)
Testing the models......
Loss: 3.7462, Prec@1: 14.18, Prec@5: 38.32
Epoch time: 80s
Saving models
Epoch: 6  lr: 0.100
Epoch: [6][000/391]	Time 1.0736 Data 0.9017 Loss 3.8235 (3.8235)	Acc@1 10.938 (10.938)	Acc@5 37.500 (37.500)
Epoch: [6][100/391]	Time 0.1884 Data 0.0026 Loss 3.4787 (3.7097)	Acc@1 13.281 (14.465)	Acc@5 45.312 (39.449)
Epoch: [6][200/391]	Time 0.1871 Data 0.0019 Loss 3.3756 (3.6910)	Acc@1 19.531 (14.929)	Acc@5 50.781 (40.520)
Epoch: [6][300/391]	Time 0.1872 Data 0.0019 Loss 3.3192 (3.6464)	Acc@1 22.656 (15.721)	Acc@5 49.219 (41.679)
Testing the models......
Loss: 3.6662, Prec@1: 20.13, Prec@5: 48.32
Epoch time: 80s
Saving models
Epoch: 7  lr: 0.100
Epoch: [7][000/391]	Time 1.0929 Data 0.8559 Loss 3.2420 (3.2420)	Acc@1 25.781 (25.781)	Acc@5 46.875 (46.875)
Epoch: [7][100/391]	Time 0.1872 Data 0.0020 Loss 3.2401 (3.3949)	Acc@1 17.969 (19.756)	Acc@5 52.344 (47.679)
Epoch: [7][200/391]	Time 0.1883 Data 0.0020 Loss 3.3060 (3.3832)	Acc@1 18.750 (20.044)	Acc@5 51.562 (48.329)
Epoch: [7][300/391]	Time 0.1897 Data 0.0020 Loss 3.0320 (3.3467)	Acc@1 23.438 (20.759)	Acc@5 55.469 (49.362)
Testing the models......
Loss: 3.3821, Prec@1: 24.07, Prec@5: 54.43
Epoch time: 81s
Saving models
Epoch: 8  lr: 0.100
Epoch: [8][000/391]	Time 1.0708 Data 0.7971 Loss 3.2583 (3.2583)	Acc@1 23.438 (23.438)	Acc@5 53.906 (53.906)
Epoch: [8][100/391]	Time 0.1871 Data 0.0019 Loss 3.1579 (3.1106)	Acc@1 27.344 (24.954)	Acc@5 55.469 (55.012)
Epoch: [8][200/391]	Time 0.1883 Data 0.0024 Loss 2.9811 (3.0806)	Acc@1 26.562 (25.245)	Acc@5 57.031 (55.418)
Epoch: [8][300/391]	Time 0.1878 Data 0.0019 Loss 2.9652 (3.0596)	Acc@1 24.219 (25.773)	Acc@5 57.812 (56.224)
Testing the models......
Loss: 3.0827, Prec@1: 28.20, Prec@5: 58.50
Epoch time: 80s
Saving models
Epoch: 9  lr: 0.100
Epoch: [9][000/391]	Time 1.1488 Data 0.9797 Loss 3.0593 (3.0593)	Acc@1 26.562 (26.562)	Acc@5 60.938 (60.938)
Epoch: [9][100/391]	Time 0.1875 Data 0.0021 Loss 2.5405 (2.8250)	Acc@1 39.062 (30.569)	Acc@5 68.750 (61.757)
Epoch: [9][200/391]	Time 0.1875 Data 0.0026 Loss 2.6176 (2.7936)	Acc@1 33.594 (31.044)	Acc@5 68.750 (62.360)
Epoch: [9][300/391]	Time 0.1809 Data 0.0030 Loss 2.6175 (2.7620)	Acc@1 31.250 (31.624)	Acc@5 71.875 (62.949)
Testing the models......
Loss: 2.5581, Prec@1: 36.51, Prec@5: 67.71
Epoch time: 81s
Saving models
Epoch: 10  lr: 0.100
Epoch: [10][000/391]	Time 1.3061 Data 1.1280 Loss 2.2829 (2.2829)	Acc@1 42.969 (42.969)	Acc@5 71.094 (71.094)
Epoch: [10][100/391]	Time 0.1891 Data 0.0024 Loss 2.1681 (2.5334)	Acc@1 44.531 (35.992)	Acc@5 72.656 (68.618)
Epoch: [10][200/391]	Time 0.1876 Data 0.0021 Loss 2.5257 (2.5026)	Acc@1 34.375 (36.633)	Acc@5 71.094 (68.797)
Epoch: [10][300/391]	Time 0.1883 Data 0.0020 Loss 2.3608 (2.4819)	Acc@1 35.938 (37.126)	Acc@5 68.750 (69.303)
Testing the models......
Loss: 2.5263, Prec@1: 37.62, Prec@5: 69.46
Epoch time: 81s
Saving models
Epoch: 11  lr: 0.100
Epoch: [11][000/391]	Time 1.0078 Data 0.7489 Loss 1.9365 (1.9365)	Acc@1 46.875 (46.875)	Acc@5 82.031 (82.031)
Epoch: [11][100/391]	Time 0.1873 Data 0.0020 Loss 2.5205 (2.2438)	Acc@1 36.719 (41.778)	Acc@5 68.750 (73.793)
Epoch: [11][200/391]	Time 0.1883 Data 0.0021 Loss 2.0457 (2.2396)	Acc@1 53.125 (41.667)	Acc@5 75.781 (73.877)
Epoch: [11][300/391]	Time 0.1893 Data 0.0020 Loss 2.3222 (2.2345)	Acc@1 42.188 (41.674)	Acc@5 72.656 (74.016)
Testing the models......
Loss: 2.3352, Prec@1: 41.73, Prec@5: 73.53
Epoch time: 80s
Saving models
Epoch: 12  lr: 0.100
Epoch: [12][000/391]	Time 1.0691 Data 0.8728 Loss 2.0881 (2.0881)	Acc@1 47.656 (47.656)	Acc@5 79.688 (79.688)
Epoch: [12][100/391]	Time 0.1848 Data 0.0027 Loss 2.2577 (2.0522)	Acc@1 39.062 (45.521)	Acc@5 76.562 (77.406)
Epoch: [12][200/391]	Time 0.1886 Data 0.0020 Loss 1.8929 (2.0473)	Acc@1 46.875 (45.775)	Acc@5 77.344 (77.678)
Epoch: [12][300/391]	Time 0.1878 Data 0.0020 Loss 1.9427 (2.0289)	Acc@1 39.062 (46.327)	Acc@5 75.000 (77.868)
Testing the models......
Loss: 2.2222, Prec@1: 44.03, Prec@5: 76.22
Epoch time: 81s
Saving models
Epoch: 13  lr: 0.100
Epoch: [13][000/391]	Time 1.1030 Data 0.8402 Loss 1.9316 (1.9316)	Acc@1 48.438 (48.438)	Acc@5 82.031 (82.031)
Epoch: [13][100/391]	Time 0.1882 Data 0.0021 Loss 2.0446 (1.8799)	Acc@1 42.969 (49.652)	Acc@5 81.250 (80.391)
Epoch: [13][200/391]	Time 0.1882 Data 0.0020 Loss 1.7982 (1.8730)	Acc@1 47.656 (49.514)	Acc@5 83.594 (80.628)
Epoch: [13][300/391]	Time 0.1880 Data 0.0020 Loss 2.0728 (1.8707)	Acc@1 38.281 (49.652)	Acc@5 77.344 (80.744)
Testing the models......
Loss: 2.1004, Prec@1: 46.54, Prec@5: 78.24
Epoch time: 81s
Saving models
Epoch: 14  lr: 0.100
Epoch: [14][000/391]	Time 1.0641 Data 0.8724 Loss 1.7019 (1.7019)	Acc@1 54.688 (54.688)	Acc@5 80.469 (80.469)
Epoch: [14][100/391]	Time 0.1883 Data 0.0025 Loss 1.7723 (1.7304)	Acc@1 49.219 (52.444)	Acc@5 83.594 (83.075)
Epoch: [14][200/391]	Time 0.1878 Data 0.0019 Loss 1.5629 (1.7331)	Acc@1 54.688 (52.554)	Acc@5 85.938 (83.003)
Epoch: [14][300/391]	Time 0.1873 Data 0.0019 Loss 1.6337 (1.7337)	Acc@1 52.344 (52.746)	Acc@5 85.156 (82.792)
Testing the models......
Loss: 1.9211, Prec@1: 50.93, Prec@5: 80.52
Epoch time: 80s
Saving models
Epoch: 15  lr: 0.100
Epoch: [15][000/391]	Time 1.0716 Data 0.8937 Loss 1.5678 (1.5678)	Acc@1 61.719 (61.719)	Acc@5 82.812 (82.812)
Epoch: [15][100/391]	Time 0.1882 Data 0.0019 Loss 1.4922 (1.5895)	Acc@1 48.438 (56.235)	Acc@5 87.500 (85.094)
Epoch: [15][200/391]	Time 0.1874 Data 0.0020 Loss 1.6906 (1.6042)	Acc@1 56.250 (55.749)	Acc@5 85.156 (85.176)
Epoch: [15][300/391]	Time 0.1903 Data 0.0021 Loss 1.9718 (1.6018)	Acc@1 50.000 (55.868)	Acc@5 75.000 (85.078)
Testing the models......
Loss: 1.7552, Prec@1: 53.70, Prec@5: 82.70
Epoch time: 80s
Saving models
Epoch: 16  lr: 0.100
Epoch: [16][000/391]	Time 1.1072 Data 0.8288 Loss 1.3454 (1.3454)	Acc@1 60.938 (60.938)	Acc@5 86.719 (86.719)
Epoch: [16][100/391]	Time 0.1872 Data 0.0019 Loss 1.5851 (1.4720)	Acc@1 58.594 (58.810)	Acc@5 85.156 (86.951)
Epoch: [16][200/391]	Time 0.1883 Data 0.0023 Loss 1.4895 (1.4856)	Acc@1 57.031 (58.423)	Acc@5 85.156 (86.750)
Epoch: [16][300/391]	Time 0.1875 Data 0.0020 Loss 1.3844 (1.4865)	Acc@1 64.062 (58.404)	Acc@5 86.719 (86.729)
Testing the models......
Loss: 1.8389, Prec@1: 53.07, Prec@5: 81.94
Epoch time: 81s
Epoch: 17  lr: 0.100
Epoch: [17][000/391]	Time 1.3416 Data 1.1367 Loss 1.1876 (1.1876)	Acc@1 71.094 (71.094)	Acc@5 91.406 (91.406)
Epoch: [17][100/391]	Time 0.1883 Data 0.0020 Loss 1.4508 (1.3686)	Acc@1 60.156 (60.999)	Acc@5 85.938 (88.838)
Epoch: [17][200/391]	Time 0.1876 Data 0.0020 Loss 1.4662 (1.3807)	Acc@1 51.562 (60.868)	Acc@5 85.938 (88.549)
Epoch: [17][300/391]	Time 0.1872 Data 0.0020 Loss 1.4554 (1.3916)	Acc@1 62.500 (60.714)	Acc@5 88.281 (88.351)
Testing the models......
Loss: 1.6537, Prec@1: 56.60, Prec@5: 84.65
Epoch time: 81s
Saving models
Epoch: 18  lr: 0.100
Epoch: [18][000/391]	Time 1.0609 Data 0.7894 Loss 1.1825 (1.1825)	Acc@1 64.844 (64.844)	Acc@5 89.844 (89.844)
Epoch: [18][100/391]	Time 0.1891 Data 0.0020 Loss 1.3210 (1.2885)	Acc@1 60.156 (63.815)	Acc@5 87.500 (89.604)
Epoch: [18][200/391]	Time 0.1874 Data 0.0031 Loss 1.4885 (1.3065)	Acc@1 60.938 (63.021)	Acc@5 86.719 (89.513)
Epoch: [18][300/391]	Time 0.1872 Data 0.0020 Loss 1.5953 (1.3131)	Acc@1 59.375 (62.814)	Acc@5 88.281 (89.413)
Testing the models......
Loss: 1.6985, Prec@1: 57.74, Prec@5: 84.49
Epoch time: 80s
Saving models
Epoch: 19  lr: 0.100
Epoch: [19][000/391]	Time 1.1192 Data 0.9292 Loss 1.1972 (1.1972)	Acc@1 60.938 (60.938)	Acc@5 92.188 (92.188)
Epoch: [19][100/391]	Time 0.1877 Data 0.0021 Loss 1.2836 (1.2058)	Acc@1 65.625 (64.774)	Acc@5 87.500 (90.950)
Epoch: [19][200/391]	Time 0.1886 Data 0.0028 Loss 1.4500 (1.2326)	Acc@1 57.031 (64.117)	Acc@5 87.500 (90.582)
Epoch: [19][300/391]	Time 0.1872 Data 0.0020 Loss 1.2242 (1.2336)	Acc@1 62.500 (64.262)	Acc@5 93.750 (90.513)
Testing the models......
Loss: 1.6001, Prec@1: 56.76, Prec@5: 85.19
Epoch time: 80s
Epoch: 20  lr: 0.100
Epoch: [20][000/391]	Time 1.1306 Data 0.8620 Loss 1.2377 (1.2377)	Acc@1 62.500 (62.500)	Acc@5 92.969 (92.969)
Epoch: [20][100/391]	Time 0.1874 Data 0.0020 Loss 1.0739 (1.1184)	Acc@1 71.094 (67.157)	Acc@5 90.625 (92.033)
Epoch: [20][200/391]	Time 0.1926 Data 0.0020 Loss 1.3988 (1.1242)	Acc@1 59.375 (67.176)	Acc@5 89.844 (91.772)
Epoch: [20][300/391]	Time 0.1936 Data 0.0021 Loss 1.3419 (1.1405)	Acc@1 60.938 (66.616)	Acc@5 87.500 (91.572)
Testing the models......
Loss: 1.4726, Prec@1: 59.95, Prec@5: 87.08
Epoch time: 80s
Saving models
Epoch: 21  lr: 0.100
Epoch: [21][000/391]	Time 1.1133 Data 0.9056 Loss 0.9489 (0.9489)	Acc@1 71.875 (71.875)	Acc@5 94.531 (94.531)
Epoch: [21][100/391]	Time 0.1874 Data 0.0019 Loss 1.0172 (1.0375)	Acc@1 69.531 (69.268)	Acc@5 93.750 (92.976)
Epoch: [21][200/391]	Time 0.1873 Data 0.0021 Loss 1.0813 (1.0677)	Acc@1 67.969 (68.664)	Acc@5 93.750 (92.530)
Epoch: [21][300/391]	Time 0.1883 Data 0.0029 Loss 1.0714 (1.0822)	Acc@1 66.406 (68.161)	Acc@5 93.750 (92.387)
Testing the models......
Loss: 1.5070, Prec@1: 60.48, Prec@5: 86.85
Epoch time: 80s
Saving models
Epoch: 22  lr: 0.100
Epoch: [22][000/391]	Time 1.0991 Data 0.8895 Loss 1.1793 (1.1793)	Acc@1 62.500 (62.500)	Acc@5 92.188 (92.188)
Epoch: [22][100/391]	Time 0.1870 Data 0.0019 Loss 0.7818 (0.9829)	Acc@1 75.781 (70.166)	Acc@5 96.094 (93.719)
Epoch: [22][200/391]	Time 0.1870 Data 0.0019 Loss 1.1512 (0.9974)	Acc@1 64.062 (69.912)	Acc@5 92.969 (93.482)
Epoch: [22][300/391]	Time 0.1888 Data 0.0020 Loss 1.1775 (1.0165)	Acc@1 67.969 (69.700)	Acc@5 90.625 (93.208)
Testing the models......
Loss: 1.5251, Prec@1: 59.70, Prec@5: 86.55
Epoch time: 80s
Epoch: 23  lr: 0.100
Epoch: [23][000/391]	Time 0.9978 Data 0.7952 Loss 1.0346 (1.0346)	Acc@1 72.656 (72.656)	Acc@5 93.750 (93.750)
Epoch: [23][100/391]	Time 0.1879 Data 0.0020 Loss 0.6835 (0.9268)	Acc@1 79.688 (72.192)	Acc@5 95.312 (94.655)
Epoch: [23][200/391]	Time 0.1875 Data 0.0020 Loss 0.9416 (0.9553)	Acc@1 72.656 (71.412)	Acc@5 92.188 (94.201)
Epoch: [23][300/391]	Time 0.1884 Data 0.0020 Loss 0.9791 (0.9786)	Acc@1 74.219 (70.681)	Acc@5 93.750 (93.882)
Testing the models......
Loss: 1.5264, Prec@1: 60.48, Prec@5: 86.70
Epoch time: 81s
Epoch: 24  lr: 0.100
Epoch: [24][000/391]	Time 1.0591 Data 0.8406 Loss 0.9605 (0.9605)	Acc@1 71.094 (71.094)	Acc@5 95.312 (95.312)
Epoch: [24][100/391]	Time 0.1874 Data 0.0019 Loss 0.8801 (0.8617)	Acc@1 72.656 (73.909)	Acc@5 95.312 (95.088)
Epoch: [24][200/391]	Time 0.1880 Data 0.0020 Loss 0.9251 (0.8864)	Acc@1 67.969 (73.231)	Acc@5 97.656 (94.799)
Epoch: [24][300/391]	Time 0.1875 Data 0.0020 Loss 0.7899 (0.9105)	Acc@1 78.125 (72.488)	Acc@5 96.094 (94.562)
Testing the models......
Loss: 1.5277, Prec@1: 60.08, Prec@5: 86.71
Epoch time: 80s
Epoch: 25  lr: 0.100
Epoch: [25][000/391]	Time 1.0580 Data 0.8623 Loss 0.7815 (0.7815)	Acc@1 75.781 (75.781)	Acc@5 95.312 (95.312)
Epoch: [25][100/391]	Time 0.1874 Data 0.0019 Loss 0.8121 (0.8145)	Acc@1 78.125 (74.814)	Acc@5 96.094 (95.831)
Epoch: [25][200/391]	Time 0.1882 Data 0.0024 Loss 1.0963 (0.8548)	Acc@1 72.656 (73.756)	Acc@5 92.188 (95.161)
Epoch: [25][300/391]	Time 0.1880 Data 0.0021 Loss 0.6346 (0.8709)	Acc@1 77.344 (73.450)	Acc@5 97.656 (94.921)
Testing the models......
Loss: 1.5699, Prec@1: 59.91, Prec@5: 86.45
Epoch time: 81s
Epoch: 26  lr: 0.100
Epoch: [26][000/391]	Time 1.0765 Data 0.8058 Loss 0.8776 (0.8776)	Acc@1 71.094 (71.094)	Acc@5 96.875 (96.875)
Epoch: [26][100/391]	Time 0.1903 Data 0.0027 Loss 0.8458 (0.7893)	Acc@1 75.000 (76.091)	Acc@5 93.750 (95.777)
Epoch: [26][200/391]	Time 0.1878 Data 0.0019 Loss 1.1083 (0.8177)	Acc@1 67.969 (75.179)	Acc@5 91.406 (95.468)
Epoch: [26][300/391]	Time 0.1878 Data 0.0019 Loss 1.0944 (0.8351)	Acc@1 68.750 (74.779)	Acc@5 93.750 (95.331)
Testing the models......
Loss: 1.4584, Prec@1: 62.51, Prec@5: 87.55
Epoch time: 81s
Saving models
Epoch: 27  lr: 0.100
Epoch: [27][000/391]	Time 1.0850 Data 0.8776 Loss 0.6441 (0.6441)	Acc@1 76.562 (76.562)	Acc@5 99.219 (99.219)
Epoch: [27][100/391]	Time 0.1912 Data 0.0034 Loss 0.7698 (0.7249)	Acc@1 77.344 (77.754)	Acc@5 96.094 (96.651)
Epoch: [27][200/391]	Time 0.1874 Data 0.0024 Loss 0.6451 (0.7631)	Acc@1 78.906 (76.757)	Acc@5 96.875 (96.210)
Epoch: [27][300/391]	Time 0.1887 Data 0.0028 Loss 0.6476 (0.7877)	Acc@1 79.688 (75.966)	Acc@5 96.875 (95.852)
Testing the models......
Loss: 1.5027, Prec@1: 61.49, Prec@5: 87.28
Epoch time: 81s
Epoch: 28  lr: 0.100
Epoch: [28][000/391]	Time 1.2091 Data 1.0041 Loss 0.6122 (0.6122)	Acc@1 80.469 (80.469)	Acc@5 96.875 (96.875)
Epoch: [28][100/391]	Time 0.1919 Data 0.0021 Loss 0.5819 (0.7013)	Acc@1 82.812 (78.543)	Acc@5 97.656 (96.558)
Epoch: [28][200/391]	Time 0.1940 Data 0.0019 Loss 0.9134 (0.7309)	Acc@1 73.438 (77.903)	Acc@5 94.531 (96.226)
Epoch: [28][300/391]	Time 0.1879 Data 0.0020 Loss 0.8683 (0.7509)	Acc@1 75.000 (77.061)	Acc@5 92.969 (96.122)
Testing the models......
Loss: 1.4620, Prec@1: 61.82, Prec@5: 87.53
Epoch time: 81s
Epoch: 29  lr: 0.100
Epoch: [29][000/391]	Time 1.0505 Data 0.8414 Loss 0.6964 (0.6964)	Acc@1 78.125 (78.125)	Acc@5 96.875 (96.875)
Epoch: [29][100/391]	Time 0.1877 Data 0.0020 Loss 0.6957 (0.6624)	Acc@1 80.469 (79.216)	Acc@5 96.875 (97.161)
Epoch: [29][200/391]	Time 0.1895 Data 0.0023 Loss 0.8200 (0.6918)	Acc@1 73.438 (78.397)	Acc@5 93.750 (96.852)
Epoch: [29][300/391]	Time 0.1890 Data 0.0025 Loss 0.8062 (0.7199)	Acc@1 75.000 (77.743)	Acc@5 95.312 (96.602)
Testing the models......
Loss: 1.5370, Prec@1: 61.20, Prec@5: 87.10
Epoch time: 81s
Epoch: 30  lr: 0.100
Epoch: [30][000/391]	Time 1.0262 Data 0.7409 Loss 0.6957 (0.6957)	Acc@1 82.812 (82.812)	Acc@5 96.875 (96.875)
Epoch: [30][100/391]	Time 0.1887 Data 0.0038 Loss 0.7666 (0.6507)	Acc@1 78.125 (79.896)	Acc@5 94.531 (97.177)
opt = Namespace(T=2, alpha=0.1, batch_size=128, beta=1e-05, cuda=1, dataset='cifar100', decay_fea=1, decay_kd=1, decay_loss=1, distill='kd', epochs=240, log_name='1-1-1-0.txt', lr=0.1, model='multi_resnet50_kd', model_name='multi_resnet50_kd_cifar100_selfkd_origin', model_path='../save/models', momentum=0.9, noise=0, num_workers=8, print_freq=100, save_folder='../save/models/multi_resnet50_kd_cifar100_selfkd_origin', save_freq=40, seed=2, tb_folder='../save/tensorboard/multi_resnet50_kd_cifar100_selfkd_origin', tb_freq=500, tb_path='../save/tensorboard', weight_decay=0.0001)
----------- Network Initialization --------------
model = Multi_ResNet(
  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (layer1): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer2): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer3): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (3): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (4): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (5): BottleneckBlock(
      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (layer4): Sequential(
    (0): BottleneckBlock(
      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
    (2): BottleneckBlock(
      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    )
  )
  (downsample1_1): Sequential(
    (0): Conv2d(256, 2048, kernel_size=(1, 1), stride=(8, 8), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck1_1): Sequential(
    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(8, 8), stride=(8, 8))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool1): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc1): Linear(in_features=2048, out_features=100, bias=True)
  (downsample2_1): Sequential(
    (0): Conv2d(512, 2048, kernel_size=(1, 1), stride=(4, 4), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck2_1): Sequential(
    (0): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(4, 4), stride=(4, 4))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool2): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc2): Linear(in_features=2048, out_features=100, bias=True)
  (downsample3_1): Sequential(
    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)
    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  )
  (bottleneck3_1): Sequential(
    (0): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))
    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
    (3): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))
    (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (5): ReLU()
    (6): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1))
    (7): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (8): ReLU()
  )
  (avgpool3): AdaptiveAvgPool2d(output_size=(1, 1))
  (middle_fc3): Linear(in_features=2048, out_features=100, bias=True)
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (fc): Linear(in_features=2048, out_features=100, bias=True)
)
param size = 54.113232MB
-----------------------------------------------
 Save initial parameters
Epoch: 1  lr: 0.100
Epoch: [1][000/391]	Time 2.5737 Data 1.0461 Loss 4.8249 (4.8249)	Acc@1 0.000 (0.000)	Acc@5 3.125 (3.125)
Epoch: [1][100/391]	Time 0.1881 Data 0.0035 Loss 4.9367 (5.4066)	Acc@1 5.469 (1.586)	Acc@5 10.156 (6.675)
Epoch: [1][200/391]	Time 0.1868 Data 0.0019 Loss 4.7171 (5.1078)	Acc@1 1.562 (1.590)	Acc@5 8.594 (7.027)
Epoch: [1][300/391]	Time 0.1868 Data 0.0019 Loss 4.4486 (5.0022)	Acc@1 3.906 (1.666)	Acc@5 9.375 (7.309)
Testing the models......
Loss: 4.5871, Prec@1: 2.01, Prec@5: 10.36
Epoch time: 83s
Saving models
Epoch: 2  lr: 0.100
Epoch: [2][000/391]	Time 1.3031 Data 1.0378 Loss 4.6233 (4.6233)	Acc@1 3.125 (3.125)	Acc@5 9.375 (9.375)
Epoch: [2][100/391]	Time 0.1875 Data 0.0020 Loss 4.5441 (4.6880)	Acc@1 4.688 (2.259)	Acc@5 15.625 (10.396)
Epoch: [2][200/391]	Time 0.1881 Data 0.0024 Loss 4.5934 (4.6978)	Acc@1 1.562 (2.491)	Acc@5 10.938 (10.856)
Epoch: [2][300/391]	Time 0.1878 Data 0.0019 Loss 4.5260 (4.6725)	Acc@1 3.906 (2.632)	Acc@5 16.406 (11.241)
Testing the models......
Loss: 4.8798, Prec@1: 3.61, Prec@5: 16.48
Epoch time: 81s
Saving models
Epoch: 3  lr: 0.100
Epoch: [3][000/391]	Time 1.0284 Data 0.8260 Loss 4.2659 (4.2659)	Acc@1 2.344 (2.344)	Acc@5 14.844 (14.844)
Epoch: [3][100/391]	Time 0.1866 Data 0.0021 Loss 4.5462 (4.4215)	Acc@1 4.688 (4.053)	Acc@5 18.750 (17.899)
Epoch: [3][200/391]	Time 0.1871 Data 0.0019 Loss 4.5201 (4.4052)	Acc@1 3.906 (4.291)	Acc@5 16.406 (18.210)
Epoch: [3][300/391]	Time 0.1875 Data 0.0020 Loss 7.0724 (4.3802)	Acc@1 2.344 (4.607)	Acc@5 22.656 (19.337)
Testing the models......
Loss: 4.2753, Prec@1: 7.41, Prec@5: 25.78
Epoch time: 80s
Saving models
Epoch: 4  lr: 0.100
Epoch: [4][000/391]	Time 1.1864 Data 0.9563 Loss 4.0328 (4.0328)	Acc@1 7.031 (7.031)	Acc@5 24.219 (24.219)
Epoch: [4][100/391]	Time 0.1885 Data 0.0020 Loss 3.9807 (4.1674)	Acc@1 10.938 (7.364)	Acc@5 28.906 (26.191)
Epoch: [4][200/391]	Time 0.1876 Data 0.0020 Loss 3.8885 (4.1518)	Acc@1 14.062 (7.894)	Acc@5 35.156 (27.406)
Epoch: [4][300/391]	Time 0.1873 Data 0.0019 Loss 3.7035 (4.1257)	Acc@1 13.281 (8.236)	Acc@5 34.375 (27.946)
Testing the models......
Loss: 3.9296, Prec@1: 10.01, Prec@5: 33.37
Epoch time: 81s
Saving models
Epoch: 5  lr: 0.100
Epoch: [5][000/391]	Time 1.2710 Data 1.0719 Loss 4.2351 (4.2351)	Acc@1 6.250 (6.250)	Acc@5 25.781 (25.781)
Epoch: [5][100/391]	Time 0.1883 Data 0.0026 Loss 4.0143 (3.9626)	Acc@1 11.719 (10.063)	Acc@5 34.375 (32.743)
Epoch: [5][200/391]	Time 0.1878 Data 0.0020 Loss 3.8844 (3.9615)	Acc@1 12.500 (10.743)	Acc@5 32.812 (33.438)
Epoch: [5][300/391]	Time 0.1870 Data 0.0021 Loss 3.6606 (3.9329)	Acc@1 14.062 (11.254)	Acc@5 37.500 (34.474)
Testing the models......
Loss: 3.8848, Prec@1: 14.48, Prec@5: 39.82
Epoch time: 81s
Saving models
Epoch: 6  lr: 0.100
Epoch: [6][000/391]	Time 1.2002 Data 0.9399 Loss 3.7632 (3.7632)	Acc@1 12.500 (12.500)	Acc@5 40.625 (40.625)
Epoch: [6][100/391]	Time 0.1877 Data 0.0020 Loss 3.5986 (3.6777)	Acc@1 15.625 (15.292)	Acc@5 45.312 (41.615)
Epoch: [6][200/391]	Time 0.1871 Data 0.0020 Loss 3.5494 (3.6578)	Acc@1 15.625 (15.850)	Acc@5 46.875 (42.572)
Epoch: [6][300/391]	Time 0.1899 Data 0.0022 Loss 3.1107 (3.6055)	Acc@1 20.312 (16.648)	Acc@5 48.438 (43.732)
Testing the models......
Loss: 3.4757, Prec@1: 20.35, Prec@5: 49.74
Epoch time: 81s
Saving models
Epoch: 7  lr: 0.100
Epoch: [7][000/391]	Time 1.1492 Data 0.9486 Loss 3.1367 (3.1367)	Acc@1 25.781 (25.781)	Acc@5 47.656 (47.656)
Epoch: [7][100/391]	Time 0.1870 Data 0.0019 Loss 3.1503 (3.3842)	Acc@1 20.312 (20.251)	Acc@5 53.906 (49.033)
Epoch: [7][200/391]	Time 0.1865 Data 0.0020 Loss 3.1839 (3.3799)	Acc@1 25.000 (20.534)	Acc@5 56.250 (49.254)
Epoch: [7][300/391]	Time 0.1879 Data 0.0020 Loss 3.0912 (3.3367)	Acc@1 23.438 (21.460)	Acc@5 53.125 (50.407)
Testing the models......
Loss: 3.1565, Prec@1: 25.87, Prec@5: 56.30
Epoch time: 80s
Saving models
Epoch: 8  lr: 0.100
Epoch: [8][000/391]	Time 1.1214 Data 0.8544 Loss 3.2457 (3.2457)	Acc@1 21.094 (21.094)	Acc@5 56.250 (56.250)
Epoch: [8][100/391]	Time 0.1868 Data 0.0021 Loss 3.0669 (3.0699)	Acc@1 28.906 (26.153)	Acc@5 57.812 (56.544)
Epoch: [8][200/391]	Time 0.1907 Data 0.0019 Loss 2.7487 (3.0416)	Acc@1 32.812 (26.504)	Acc@5 58.594 (56.829)
Epoch: [8][300/391]	Time 0.1875 Data 0.0019 Loss 3.0908 (3.0200)	Acc@1 21.094 (26.915)	Acc@5 55.469 (57.615)
Testing the models......
Loss: 2.9730, Prec@1: 29.61, Prec@5: 60.73
Epoch time: 80s
Saving models
Epoch: 9  lr: 0.100
Epoch: [9][000/391]	Time 1.2327 Data 0.9914 Loss 2.8675 (2.8675)	Acc@1 34.375 (34.375)	Acc@5 65.625 (65.625)
Epoch: [9][100/391]	Time 0.1874 Data 0.0019 Loss 2.3580 (2.8023)	Acc@1 36.719 (31.644)	Acc@5 69.531 (63.359)
Epoch: [9][200/391]	Time 0.1871 Data 0.0019 Loss 2.5067 (2.7600)	Acc@1 36.719 (32.160)	Acc@5 67.969 (63.658)
Epoch: [9][300/391]	Time 0.1873 Data 0.0023 Loss 2.5443 (2.7275)	Acc@1 33.594 (32.703)	Acc@5 67.969 (64.078)
Testing the models......
Loss: 2.7308, Prec@1: 33.58, Prec@5: 65.35
Epoch time: 81s
Saving models
Epoch: 10  lr: 0.100
Epoch: [10][000/391]	Time 1.1714 Data 0.8863 Loss 2.4776 (2.4776)	Acc@1 36.719 (36.719)	Acc@5 70.312 (70.312)
Epoch: [10][100/391]	Time 0.1888 Data 0.0029 Loss 2.2224 (2.4879)	Acc@1 44.531 (36.518)	Acc@5 75.000 (69.485)
Epoch: [10][200/391]	Time 0.1875 Data 0.0020 Loss 2.5847 (2.4890)	Acc@1 37.500 (36.859)	Acc@5 64.844 (69.197)
Epoch: [10][300/391]	Time 0.1876 Data 0.0021 Loss 2.3058 (2.4649)	Acc@1 39.844 (37.383)	Acc@5 68.750 (69.687)
Testing the models......
Loss: 2.4951, Prec@1: 37.33, Prec@5: 69.75
Epoch time: 81s
Saving models
Epoch: 11  lr: 0.100
Epoch: [11][000/391]	Time 1.2727 Data 1.0236 Loss 2.1649 (2.1649)	Acc@1 42.188 (42.188)	Acc@5 71.094 (71.094)
Epoch: [11][100/391]	Time 0.1900 Data 0.0024 Loss 2.5583 (2.2342)	Acc@1 32.812 (41.561)	Acc@5 68.750 (73.809)
Epoch: [11][200/391]	Time 0.1873 Data 0.0021 Loss 1.9991 (2.2442)	Acc@1 50.000 (41.433)	Acc@5 74.219 (73.842)
Epoch: [11][300/391]	Time 0.1876 Data 0.0020 Loss 2.2888 (2.2442)	Acc@1 40.625 (41.484)	Acc@5 71.094 (73.723)
Testing the models......
Loss: 2.2982, Prec@1: 42.05, Prec@5: 74.18
Epoch time: 81s
Saving models
Epoch: 12  lr: 0.100
Epoch: [12][000/391]	Time 1.1187 Data 0.8529 Loss 2.0266 (2.0266)	Acc@1 43.750 (43.750)	Acc@5 77.344 (77.344)
Epoch: [12][100/391]	Time 0.1919 Data 0.0023 Loss 2.3524 (2.0635)	Acc@1 33.594 (45.575)	Acc@5 74.219 (77.181)
Epoch: [12][200/391]	Time 0.1877 Data 0.0019 Loss 1.9009 (2.0586)	Acc@1 45.312 (45.651)	Acc@5 78.125 (77.414)
Epoch: [12][300/391]	Time 0.1872 Data 0.0044 Loss 1.9357 (2.0421)	Acc@1 43.750 (46.060)	Acc@5 77.344 (77.679)
Testing the models......
Loss: 2.3032, Prec@1: 42.68, Prec@5: 75.39
Epoch time: 81s
Saving models
Epoch: 13  lr: 0.100
Epoch: [13][000/391]	Time 1.1561 Data 0.9384 Loss 1.8875 (1.8875)	Acc@1 45.312 (45.312)	Acc@5 78.906 (78.906)
Epoch: [13][100/391]	Time 0.1882 Data 0.0024 Loss 2.1676 (1.8943)	Acc@1 44.531 (49.095)	Acc@5 72.656 (79.804)
Epoch: [13][200/391]	Time 0.1883 Data 0.0020 Loss 1.6890 (1.8682)	Acc@1 51.562 (49.157)	Acc@5 82.031 (80.302)
Epoch: [13][300/391]	Time 0.1873 Data 0.0021 Loss 2.1075 (1.8561)	Acc@1 43.750 (49.429)	Acc@5 73.438 (80.474)
Testing the models......
Loss: 2.0436, Prec@1: 45.89, Prec@5: 78.17
Epoch time: 81s
Saving models
Epoch: 14  lr: 0.100
Epoch: [14][000/391]	Time 1.3896 Data 1.1817 Loss 1.6731 (1.6731)	Acc@1 54.688 (54.688)	Acc@5 82.031 (82.031)
Epoch: [14][100/391]	Time 0.1879 Data 0.0020 Loss 1.7031 (1.6727)	Acc@1 50.000 (53.195)	Acc@5 82.031 (83.292)
Epoch: [14][200/391]	Time 0.1869 Data 0.0020 Loss 1.5990 (1.6760)	Acc@1 56.250 (53.172)	Acc@5 85.156 (83.275)
Epoch: [14][300/391]	Time 0.1871 Data 0.0020 Loss 1.5935 (1.6763)	Acc@1 57.812 (53.314)	Acc@5 86.719 (83.384)
Testing the models......
Loss: 1.7458, Prec@1: 52.32, Prec@5: 82.42
Epoch time: 81s
Saving models
Epoch: 15  lr: 0.100
Epoch: [15][000/391]	Time 1.4566 Data 1.2431 Loss 1.4452 (1.4452)	Acc@1 60.156 (60.156)	Acc@5 85.156 (85.156)
Epoch: [15][100/391]	Time 0.1919 Data 0.0020 Loss 1.5513 (1.5358)	Acc@1 60.938 (56.946)	Acc@5 86.719 (85.999)
Epoch: [15][200/391]	Time 0.1874 Data 0.0019 Loss 1.4961 (1.5553)	Acc@1 59.375 (56.417)	Acc@5 85.156 (85.879)
Epoch: [15][300/391]	Time 0.1879 Data 0.0020 Loss 1.8821 (1.5555)	Acc@1 51.562 (56.401)	Acc@5 78.125 (85.748)
Testing the models......
Loss: 1.7828, Prec@1: 52.94, Prec@5: 82.41
Epoch time: 81s
Saving models
Epoch: 16  lr: 0.100
Epoch: [16][000/391]	Time 1.0808 Data 0.8804 Loss 1.3364 (1.3364)	Acc@1 63.281 (63.281)	Acc@5 84.375 (84.375)
Epoch: [16][100/391]	Time 0.1888 Data 0.0024 Loss 1.3468 (1.4249)	Acc@1 65.625 (59.499)	Acc@5 89.844 (87.763)
Epoch: [16][200/391]	Time 0.1881 Data 0.0020 Loss 1.4433 (1.4305)	Acc@1 54.688 (59.410)	Acc@5 89.062 (87.574)
Epoch: [16][300/391]	Time 0.1873 Data 0.0020 Loss 1.2877 (1.4336)	Acc@1 59.375 (59.365)	Acc@5 91.406 (87.386)
Testing the models......
Loss: 1.7637, Prec@1: 53.70, Prec@5: 82.16
Epoch time: 80s
Saving models
Epoch: 17  lr: 0.100
Epoch: [17][000/391]	Time 1.1927 Data 0.9139 Loss 1.2979 (1.2979)	Acc@1 60.156 (60.156)	Acc@5 89.062 (89.062)
Epoch: [17][100/391]	Time 0.1872 Data 0.0020 Loss 1.4605 (1.3392)	Acc@1 58.594 (61.255)	Acc@5 85.156 (88.861)
Epoch: [17][200/391]	Time 0.1870 Data 0.0024 Loss 1.5151 (1.3404)	Acc@1 53.906 (61.416)	Acc@5 88.281 (88.915)
Epoch: [17][300/391]	Time 0.1875 Data 0.0021 Loss 1.4915 (1.3498)	Acc@1 59.375 (61.319)	Acc@5 89.844 (88.728)
Testing the models......
Loss: 1.5771, Prec@1: 57.02, Prec@5: 85.20
Epoch time: 80s
Saving models
Epoch: 18  lr: 0.100
Epoch: [18][000/391]	Time 1.1570 Data 0.8931 Loss 1.1428 (1.1428)	Acc@1 67.969 (67.969)	Acc@5 89.062 (89.062)
Epoch: [18][100/391]	Time 0.1874 Data 0.0020 Loss 1.2484 (1.2260)	Acc@1 65.625 (64.558)	Acc@5 92.188 (90.215)
Epoch: [18][200/391]	Time 0.1883 Data 0.0026 Loss 1.3492 (1.2458)	Acc@1 62.500 (63.934)	Acc@5 89.062 (90.003)
Epoch: [18][300/391]	Time 0.1885 Data 0.0020 Loss 1.2739 (1.2588)	Acc@1 60.938 (63.593)	Acc@5 91.406 (89.911)
Testing the models......
Loss: 1.5972, Prec@1: 56.70, Prec@5: 84.81
Epoch time: 80s
Epoch: 19  lr: 0.100
Epoch: [19][000/391]	Time 1.1744 Data 0.9745 Loss 1.1080 (1.1080)	Acc@1 72.656 (72.656)	Acc@5 90.625 (90.625)
Epoch: [19][100/391]	Time 0.1873 Data 0.0019 Loss 1.2848 (1.1652)	Acc@1 61.719 (65.903)	Acc@5 88.281 (91.105)
Epoch: [19][200/391]	Time 0.1884 Data 0.0023 Loss 1.2707 (1.1833)	Acc@1 66.406 (65.462)	Acc@5 91.406 (90.975)
Epoch: [19][300/391]	Time 0.1875 Data 0.0022 Loss 1.2101 (1.1919)	Acc@1 66.406 (65.306)	Acc@5 89.844 (90.830)
Testing the models......
Loss: 1.5430, Prec@1: 57.62, Prec@5: 86.14
Epoch time: 81s
Saving models
Epoch: 20  lr: 0.100
Epoch: [20][000/391]	Time 1.1310 Data 0.9180 Loss 1.1308 (1.1308)	Acc@1 68.750 (68.750)	Acc@5 94.531 (94.531)
Epoch: [20][100/391]	Time 0.1877 Data 0.0020 Loss 1.0934 (1.0945)	Acc@1 63.281 (67.899)	Acc@5 95.312 (92.358)
Epoch: [20][200/391]	Time 0.1872 Data 0.0020 Loss 1.3511 (1.0972)	Acc@1 62.500 (67.868)	Acc@5 87.500 (92.168)
Epoch: [20][300/391]	Time 0.1906 Data 0.0020 Loss 1.1618 (1.1092)	Acc@1 65.625 (67.393)	Acc@5 90.625 (92.045)
Testing the models......
Loss: 1.4248, Prec@1: 60.98, Prec@5: 87.41
Epoch time: 81s
Saving models
Epoch: 21  lr: 0.100
Epoch: [21][000/391]	Time 1.2116 Data 1.0015 Loss 0.9684 (0.9684)	Acc@1 69.531 (69.531)	Acc@5 96.094 (96.094)
Epoch: [21][100/391]	Time 0.1855 Data 0.0020 Loss 0.8867 (1.0245)	Acc@1 72.656 (69.779)	Acc@5 92.969 (93.085)
Epoch: [21][200/391]	Time 0.1879 Data 0.0020 Loss 1.0640 (1.0436)	Acc@1 71.094 (69.213)	Acc@5 92.188 (92.747)
Epoch: [21][300/391]	Time 0.1878 Data 0.0020 Loss 1.0543 (1.0593)	Acc@1 72.656 (68.802)	Acc@5 94.531 (92.569)
Testing the models......
Loss: 1.5265, Prec@1: 59.24, Prec@5: 86.65
Epoch time: 80s
Epoch: 22  lr: 0.100
Epoch: [22][000/391]	Time 1.2056 Data 0.9903 Loss 1.1815 (1.1815)	Acc@1 64.062 (64.062)	Acc@5 91.406 (91.406)
Epoch: [22][100/391]	Time 0.1875 Data 0.0022 Loss 0.9030 (0.9711)	Acc@1 67.969 (70.630)	Acc@5 96.875 (93.657)
Epoch: [22][200/391]	Time 0.1878 Data 0.0020 Loss 1.0417 (0.9774)	Acc@1 67.969 (70.402)	Acc@5 90.625 (93.633)
Epoch: [22][300/391]	Time 0.1893 Data 0.0021 Loss 1.2795 (0.9983)	Acc@1 65.625 (69.954)	Acc@5 90.625 (93.426)
Testing the models......
Loss: 1.4253, Prec@1: 61.62, Prec@5: 87.66
Epoch time: 81s
Saving models
Epoch: 23  lr: 0.100
Epoch: [23][000/391]	Time 1.2139 Data 1.0343 Loss 0.9412 (0.9412)	Acc@1 76.562 (76.562)	Acc@5 92.969 (92.969)
Epoch: [23][100/391]	Time 0.1877 Data 0.0019 Loss 0.8664 (0.9059)	Acc@1 77.344 (72.973)	Acc@5 94.531 (94.647)
Epoch: [23][200/391]	Time 0.1877 Data 0.0020 Loss 0.9629 (0.9292)	Acc@1 68.750 (72.283)	Acc@5 92.969 (94.384)
Epoch: [23][300/391]	Time 0.1875 Data 0.0020 Loss 0.9806 (0.9586)	Acc@1 67.969 (71.400)	Acc@5 92.969 (93.978)
Testing the models......
Loss: 1.4420, Prec@1: 61.55, Prec@5: 87.50
Epoch time: 81s
Epoch: 24  lr: 0.100
Epoch: [24][000/391]	Time 1.0864 Data 0.8870 Loss 0.8299 (0.8299)	Acc@1 75.781 (75.781)	Acc@5 94.531 (94.531)
Epoch: [24][100/391]	Time 0.1881 Data 0.0027 Loss 0.7828 (0.8283)	Acc@1 73.438 (74.520)	Acc@5 97.656 (95.189)
Epoch: [24][200/391]	Time 0.1886 Data 0.0020 Loss 0.7859 (0.8686)	Acc@1 75.781 (73.783)	Acc@5 95.312 (94.741)
Epoch: [24][300/391]	Time 0.1880 Data 0.0020 Loss 0.9102 (0.8951)	Acc@1 72.656 (73.017)	Acc@5 93.750 (94.479)
Testing the models......
Loss: 1.4823, Prec@1: 61.17, Prec@5: 86.95
Epoch time: 81s
Epoch: 25  lr: 0.100
Epoch: [25][000/391]	Time 1.1018 Data 0.8873 Loss 0.6156 (0.6156)	Acc@1 82.812 (82.812)	Acc@5 96.094 (96.094)
Epoch: [25][100/391]	Time 0.1879 Data 0.0019 Loss 0.7493 (0.7961)	Acc@1 75.781 (75.317)	Acc@5 96.094 (95.761)
Epoch: [25][200/391]	Time 0.1876 Data 0.0020 Loss 1.0876 (0.8374)	Acc@1 72.656 (74.545)	Acc@5 90.625 (95.231)
Epoch: [25][300/391]	Time 0.1898 Data 0.0019 Loss 0.6277 (0.8517)	Acc@1 80.469 (74.177)	Acc@5 96.094 (95.128)
Testing the models......
Loss: 1.5059, Prec@1: 60.98, Prec@5: 87.33
Epoch time: 81s
Epoch: 26  lr: 0.100
Epoch: [26][000/391]	Time 1.0601 Data 0.8999 Loss 0.8262 (0.8262)	Acc@1 74.219 (74.219)	Acc@5 96.094 (96.094)
Epoch: [26][100/391]	Time 0.1872 Data 0.0020 Loss 0.7081 (0.7595)	Acc@1 76.562 (77.212)	Acc@5 97.656 (96.233)
Epoch: [26][200/391]	Time 0.1870 Data 0.0020 Loss 1.0765 (0.7922)	Acc@1 70.312 (76.290)	Acc@5 93.750 (95.814)
Epoch: [26][300/391]	Time 0.1876 Data 0.0020 Loss 0.9468 (0.8138)	Acc@1 71.875 (75.511)	Acc@5 94.531 (95.507)
Testing the models......
Loss: 1.3847, Prec@1: 63.51, Prec@5: 88.72
Epoch time: 81s
Saving models
Epoch: 27  lr: 0.100
Epoch: [27][000/391]	Time 1.1342 Data 0.8452 Loss 0.6156 (0.6156)	Acc@1 79.688 (79.688)	Acc@5 99.219 (99.219)
Epoch: [27][100/391]	Time 0.1874 Data 0.0020 Loss 0.7388 (0.7193)	Acc@1 76.562 (78.110)	Acc@5 97.656 (96.535)
Epoch: [27][200/391]	Time 0.1872 Data 0.0019 Loss 0.6797 (0.7502)	Acc@1 81.250 (77.048)	Acc@5 99.219 (96.257)
Epoch: [27][300/391]	Time 0.1872 Data 0.0020 Loss 0.6550 (0.7768)	Acc@1 80.469 (76.448)	Acc@5 95.312 (95.946)
Testing the models......
Loss: 1.5861, Prec@1: 60.05, Prec@5: 86.43
Epoch time: 80s
Epoch: 28  lr: 0.100
Epoch: [28][000/391]	Time 1.1734 Data 0.9452 Loss 0.7304 (0.7304)	Acc@1 78.906 (78.906)	Acc@5 94.531 (94.531)
Epoch: [28][100/391]	Time 0.1876 Data 0.0020 Loss 0.5823 (0.6965)	Acc@1 81.250 (78.349)	Acc@5 100.000 (96.875)
Epoch: [28][200/391]	Time 0.1905 Data 0.0026 Loss 0.9007 (0.7258)	Acc@1 70.312 (77.530)	Acc@5 95.312 (96.517)
Epoch: [28][300/391]	Time 0.1869 Data 0.0021 Loss 0.8910 (0.7480)	Acc@1 71.875 (76.905)	Acc@5 95.312 (96.224)
Testing the models......
Loss: 1.4223, Prec@1: 63.42, Prec@5: 88.42
Epoch time: 80s
Epoch: 29  lr: 0.100
Epoch: [29][000/391]	Time 1.0805 Data 0.8676 Loss 0.7202 (0.7202)	Acc@1 75.000 (75.000)	Acc@5 96.875 (96.875)
Epoch: [29][100/391]	Time 0.1868 Data 0.0020 Loss 0.8151 (0.6559)	Acc@1 74.219 (79.107)	Acc@5 94.531 (97.300)
Epoch: [29][200/391]	Time 0.1870 Data 0.0019 Loss 0.7993 (0.6808)	Acc@1 80.469 (78.486)	Acc@5 94.531 (96.902)
Epoch: [29][300/391]	Time 0.1866 Data 0.0020 Loss 0.9038 (0.7093)	Acc@1 72.656 (77.839)	Acc@5 92.969 (96.569)
Testing the models......
Loss: 1.5597, Prec@1: 61.21, Prec@5: 86.86
Epoch time: 80s
Epoch: 30  lr: 0.100
Epoch: [30][000/391]	Time 1.1527 Data 0.9366 Loss 0.7694 (0.7694)	Acc@1 76.562 (76.562)	Acc@5 97.656 (97.656)
Epoch: [30][100/391]	Time 0.1865 Data 0.0020 Loss 0.6391 (0.6472)	Acc@1 79.688 (79.664)	Acc@5 96.094 (97.246)
Epoch: [30][200/391]	Time 0.1868 Data 0.0019 Loss 0.6071 (0.6598)	Acc@1 81.250 (79.190)	Acc@5 98.438 (97.182)
Epoch: [30][300/391]	Time 0.1874 Data 0.0019 Loss 0.7438 (0.6858)	Acc@1 79.688 (78.608)	Acc@5 99.219 (96.909)
Testing the models......
Loss: 1.5114, Prec@1: 61.62, Prec@5: 87.17
Epoch time: 80s
Epoch: 31  lr: 0.100
Epoch: [31][000/391]	Time 1.1488 Data 0.9492 Loss 0.5553 (0.5553)	Acc@1 82.812 (82.812)	Acc@5 99.219 (99.219)
Epoch: [31][100/391]	Time 0.1874 Data 0.0025 Loss 0.7253 (0.6001)	Acc@1 79.688 (81.041)	Acc@5 97.656 (97.687)
Epoch: [31][200/391]	Time 0.1865 Data 0.0019 Loss 0.7088 (0.6379)	Acc@1 71.094 (80.006)	Acc@5 100.000 (97.299)
Epoch: [31][300/391]	Time 0.1862 Data 0.0020 Loss 0.7440 (0.6521)	Acc@1 75.781 (79.563)	Acc@5 95.312 (97.129)
Testing the models......
Loss: 1.4649, Prec@1: 63.18, Prec@5: 88.22
Epoch time: 80s
Epoch: 32  lr: 0.100
Epoch: [32][000/391]	Time 1.1348 Data 0.8584 Loss 0.6859 (0.6859)	Acc@1 78.906 (78.906)	Acc@5 96.094 (96.094)
Epoch: [32][100/391]	Time 0.1873 Data 0.0020 Loss 0.5197 (0.5886)	Acc@1 82.812 (81.219)	Acc@5 98.438 (97.757)
Epoch: [32][200/391]	Time 0.1872 Data 0.0020 Loss 0.5113 (0.6045)	Acc@1 84.375 (81.137)	Acc@5 98.438 (97.606)
Epoch: [32][300/391]	Time 0.1867 Data 0.0019 Loss 0.7007 (0.6212)	Acc@1 75.781 (80.593)	Acc@5 97.656 (97.371)
Testing the models......
Loss: 1.5112, Prec@1: 62.22, Prec@5: 87.57
Epoch time: 80s
Epoch: 33  lr: 0.100
Epoch: [33][000/391]	Time 1.0854 Data 0.8836 Loss 0.5584 (0.5584)	Acc@1 82.031 (82.031)	Acc@5 97.656 (97.656)
Epoch: [33][100/391]	Time 0.1875 Data 0.0018 Loss 0.6615 (0.5739)	Acc@1 77.344 (81.706)	Acc@5 98.438 (97.989)
Epoch: [33][200/391]	Time 0.1865 Data 0.0019 Loss 0.6383 (0.5929)	Acc@1 81.250 (81.172)	Acc@5 96.875 (97.800)
Epoch: [33][300/391]	Time 0.1879 Data 0.0024 Loss 0.6333 (0.6112)	Acc@1 78.906 (80.679)	Acc@5 100.000 (97.687)
Testing the models......
Loss: 1.4704, Prec@1: 64.05, Prec@5: 87.95
Epoch time: 80s
Saving models
Epoch: 34  lr: 0.100
Epoch: [34][000/391]	Time 1.3633 Data 1.1391 Loss 0.4428 (0.4428)	Acc@1 84.375 (84.375)	Acc@5 100.000 (100.000)
Epoch: [34][100/391]	Time 0.1865 Data 0.0020 Loss 0.6532 (0.5409)	Acc@1 78.906 (82.611)	Acc@5 98.438 (98.035)
Epoch: [34][200/391]	Time 0.1869 Data 0.0019 Loss 0.6691 (0.5564)	Acc@1 80.469 (82.377)	Acc@5 94.531 (97.971)
Epoch: [34][300/391]	Time 0.1882 Data 0.0025 Loss 0.7676 (0.5807)	Acc@1 77.344 (81.647)	Acc@5 95.312 (97.760)
Testing the models......
Loss: 1.3731, Prec@1: 65.23, Prec@5: 89.38
Epoch time: 81s
Saving models
Epoch: 35  lr: 0.100
Epoch: [35][000/391]	Time 1.3663 Data 1.1112 Loss 0.5330 (0.5330)	Acc@1 83.594 (83.594)	Acc@5 98.438 (98.438)
Epoch: [35][100/391]	Time 0.1895 Data 0.0019 Loss 0.3715 (0.5083)	Acc@1 88.281 (83.903)	Acc@5 97.656 (98.461)
Epoch: [35][200/391]	Time 0.1871 Data 0.0019 Loss 0.6919 (0.5434)	Acc@1 78.125 (82.847)	Acc@5 96.875 (98.193)
Epoch: [35][300/391]	Time 0.1873 Data 0.0020 Loss 0.8466 (0.5593)	Acc@1 78.906 (82.421)	Acc@5 97.656 (98.038)
Testing the models......
Loss: 1.4136, Prec@1: 64.90, Prec@5: 88.60
Epoch time: 81s
Epoch: 36  lr: 0.100
Epoch: [36][000/391]	Time 1.1205 Data 0.9456 Loss 0.5092 (0.5092)	Acc@1 85.156 (85.156)	Acc@5 96.875 (96.875)
Epoch: [36][100/391]	Time 0.1870 Data 0.0019 Loss 0.5929 (0.5003)	Acc@1 82.031 (84.421)	Acc@5 98.438 (98.337)
Epoch: [36][200/391]	Time 0.1875 Data 0.0021 Loss 0.4809 (0.5270)	Acc@1 85.938 (83.372)	Acc@5 97.656 (98.259)
Epoch: [36][300/391]	Time 0.1874 Data 0.0023 Loss 0.5849 (0.5503)	Acc@1 79.688 (82.587)	Acc@5 97.656 (98.097)
Testing the models......
Loss: 1.4796, Prec@1: 65.25, Prec@5: 87.99
Epoch time: 80s
Saving models
Epoch: 37  lr: 0.100
Epoch: [37][000/391]	Time 1.1350 Data 0.9350 Loss 0.4282 (0.4282)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [37][100/391]	Time 0.1873 Data 0.0019 Loss 0.3758 (0.4708)	Acc@1 89.844 (85.280)	Acc@5 99.219 (98.577)
Epoch: [37][200/391]	Time 0.1873 Data 0.0020 Loss 0.4883 (0.4953)	Acc@1 83.594 (84.523)	Acc@5 98.438 (98.418)
Epoch: [37][300/391]	Time 0.1870 Data 0.0020 Loss 0.7209 (0.5208)	Acc@1 73.438 (83.765)	Acc@5 98.438 (98.290)
Testing the models......
Loss: 1.5091, Prec@1: 63.04, Prec@5: 88.07
Epoch time: 80s
Epoch: 38  lr: 0.100
Epoch: [38][000/391]	Time 1.1171 Data 0.8458 Loss 0.7392 (0.7392)	Acc@1 78.906 (78.906)	Acc@5 96.875 (96.875)
Epoch: [38][100/391]	Time 0.1873 Data 0.0019 Loss 0.3314 (0.4790)	Acc@1 89.844 (85.048)	Acc@5 100.000 (98.584)
Epoch: [38][200/391]	Time 0.1893 Data 0.0020 Loss 0.4908 (0.4950)	Acc@1 79.688 (84.383)	Acc@5 99.219 (98.449)
Epoch: [38][300/391]	Time 0.1880 Data 0.0025 Loss 0.6586 (0.5183)	Acc@1 80.469 (83.661)	Acc@5 96.875 (98.341)
Testing the models......
Loss: 1.5185, Prec@1: 64.29, Prec@5: 88.07
Epoch time: 80s
Epoch: 39  lr: 0.100
Epoch: [39][000/391]	Time 1.0735 Data 0.8077 Loss 0.4940 (0.4940)	Acc@1 85.156 (85.156)	Acc@5 99.219 (99.219)
Epoch: [39][100/391]	Time 0.1874 Data 0.0019 Loss 0.4386 (0.4480)	Acc@1 89.844 (86.038)	Acc@5 96.875 (98.639)
Epoch: [39][200/391]	Time 0.1874 Data 0.0020 Loss 0.5279 (0.4783)	Acc@1 81.250 (85.148)	Acc@5 100.000 (98.476)
Epoch: [39][300/391]	Time 0.1886 Data 0.0020 Loss 0.5069 (0.4947)	Acc@1 86.719 (84.577)	Acc@5 99.219 (98.367)
Testing the models......
Loss: 1.4815, Prec@1: 64.20, Prec@5: 88.76
Epoch time: 80s
Epoch: 40  lr: 0.100
Epoch: [40][000/391]	Time 1.1109 Data 0.9190 Loss 0.4519 (0.4519)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [40][100/391]	Time 0.1883 Data 0.0020 Loss 0.4624 (0.4293)	Acc@1 85.156 (86.580)	Acc@5 98.438 (98.832)
Epoch: [40][200/391]	Time 0.1879 Data 0.0019 Loss 0.4828 (0.4595)	Acc@1 85.938 (85.662)	Acc@5 100.000 (98.787)
Epoch: [40][300/391]	Time 0.1878 Data 0.0019 Loss 0.5139 (0.4805)	Acc@1 82.031 (84.936)	Acc@5 98.438 (98.583)
Testing the models......
Loss: 1.4901, Prec@1: 64.39, Prec@5: 88.47
Epoch time: 80s
Epoch: 41  lr: 0.100
Epoch: [41][000/391]	Time 1.0330 Data 0.8275 Loss 0.3810 (0.3810)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [41][100/391]	Time 0.1878 Data 0.0023 Loss 0.4855 (0.4264)	Acc@1 84.375 (86.332)	Acc@5 99.219 (98.902)
Epoch: [41][200/391]	Time 0.1868 Data 0.0020 Loss 0.4196 (0.4465)	Acc@1 86.719 (85.665)	Acc@5 99.219 (98.807)
Epoch: [41][300/391]	Time 0.1901 Data 0.0020 Loss 0.7485 (0.4735)	Acc@1 84.375 (84.829)	Acc@5 96.875 (98.630)
Testing the models......
Loss: 1.4981, Prec@1: 64.55, Prec@5: 88.07
Epoch time: 80s
Epoch: 42  lr: 0.100
Epoch: [42][000/391]	Time 1.1264 Data 0.9690 Loss 0.3221 (0.3221)	Acc@1 91.406 (91.406)	Acc@5 98.438 (98.438)
Epoch: [42][100/391]	Time 0.1878 Data 0.0020 Loss 0.4888 (0.4277)	Acc@1 85.938 (86.688)	Acc@5 99.219 (98.824)
Epoch: [42][200/391]	Time 0.1875 Data 0.0023 Loss 0.5955 (0.4412)	Acc@1 78.125 (86.116)	Acc@5 98.438 (98.748)
Epoch: [42][300/391]	Time 0.1877 Data 0.0019 Loss 0.4653 (0.4570)	Acc@1 85.938 (85.548)	Acc@5 97.656 (98.674)
Testing the models......
Loss: 1.5552, Prec@1: 63.99, Prec@5: 87.88
Epoch time: 81s
Epoch: 43  lr: 0.100
Epoch: [43][000/391]	Time 1.0829 Data 0.8573 Loss 0.4249 (0.4249)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [43][100/391]	Time 0.1880 Data 0.0019 Loss 0.3595 (0.4289)	Acc@1 89.844 (86.317)	Acc@5 100.000 (98.847)
Epoch: [43][200/391]	Time 0.1882 Data 0.0021 Loss 0.3655 (0.4377)	Acc@1 91.406 (86.105)	Acc@5 99.219 (98.846)
Epoch: [43][300/391]	Time 0.1887 Data 0.0027 Loss 0.6133 (0.4591)	Acc@1 76.562 (85.504)	Acc@5 96.875 (98.663)
Testing the models......
Loss: 1.5434, Prec@1: 64.72, Prec@5: 87.88
Epoch time: 81s
Epoch: 44  lr: 0.100
Epoch: [44][000/391]	Time 1.0476 Data 0.8473 Loss 0.3026 (0.3026)	Acc@1 87.500 (87.500)	Acc@5 100.000 (100.000)
Epoch: [44][100/391]	Time 0.1875 Data 0.0020 Loss 0.4469 (0.3941)	Acc@1 86.719 (87.345)	Acc@5 96.875 (99.049)
Epoch: [44][200/391]	Time 0.1878 Data 0.0020 Loss 0.4156 (0.4091)	Acc@1 85.938 (87.037)	Acc@5 99.219 (98.986)
Epoch: [44][300/391]	Time 0.1875 Data 0.0020 Loss 0.4971 (0.4322)	Acc@1 83.594 (86.298)	Acc@5 100.000 (98.819)
Testing the models......
Loss: 1.5382, Prec@1: 63.91, Prec@5: 87.76
Epoch time: 80s
Epoch: 45  lr: 0.100
Epoch: [45][000/391]	Time 1.0783 Data 0.8673 Loss 0.2371 (0.2371)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [45][100/391]	Time 0.1920 Data 0.0023 Loss 0.2511 (0.3729)	Acc@1 92.188 (88.204)	Acc@5 99.219 (99.257)
Epoch: [45][200/391]	Time 0.1874 Data 0.0022 Loss 0.5126 (0.3977)	Acc@1 86.719 (87.368)	Acc@5 98.438 (99.106)
Epoch: [45][300/391]	Time 0.1882 Data 0.0019 Loss 0.3941 (0.4098)	Acc@1 85.156 (87.077)	Acc@5 100.000 (98.959)
Testing the models......
Loss: 1.4362, Prec@1: 66.12, Prec@5: 89.12
Epoch time: 81s
Saving models
Epoch: 46  lr: 0.100
Epoch: [46][000/391]	Time 1.1327 Data 0.8948 Loss 0.3459 (0.3459)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [46][100/391]	Time 0.1866 Data 0.0019 Loss 0.3646 (0.3618)	Acc@1 85.938 (88.668)	Acc@5 100.000 (99.281)
Epoch: [46][200/391]	Time 0.1873 Data 0.0020 Loss 0.4513 (0.3789)	Acc@1 87.500 (88.106)	Acc@5 100.000 (99.219)
Epoch: [46][300/391]	Time 0.1889 Data 0.0020 Loss 0.4997 (0.4066)	Acc@1 81.250 (87.178)	Acc@5 99.219 (99.076)
Testing the models......
Loss: 1.6490, Prec@1: 62.96, Prec@5: 86.86
Epoch time: 80s
Epoch: 47  lr: 0.100
Epoch: [47][000/391]	Time 1.0785 Data 0.8626 Loss 0.3488 (0.3488)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [47][100/391]	Time 0.1878 Data 0.0020 Loss 0.4625 (0.3806)	Acc@1 85.156 (87.840)	Acc@5 98.438 (99.172)
Epoch: [47][200/391]	Time 0.1872 Data 0.0020 Loss 0.4925 (0.4047)	Acc@1 87.500 (87.193)	Acc@5 99.219 (99.063)
Epoch: [47][300/391]	Time 0.1877 Data 0.0022 Loss 0.4586 (0.4219)	Acc@1 83.594 (86.602)	Acc@5 99.219 (98.954)
Testing the models......
Loss: 1.4545, Prec@1: 65.32, Prec@5: 88.91
Epoch time: 80s
Epoch: 48  lr: 0.100
Epoch: [48][000/391]	Time 1.1236 Data 0.8386 Loss 0.3237 (0.3237)	Acc@1 87.500 (87.500)	Acc@5 99.219 (99.219)
Epoch: [48][100/391]	Time 0.1876 Data 0.0024 Loss 0.3340 (0.3813)	Acc@1 90.625 (88.026)	Acc@5 100.000 (99.196)
Epoch: [48][200/391]	Time 0.1874 Data 0.0019 Loss 0.4147 (0.3874)	Acc@1 90.625 (87.823)	Acc@5 100.000 (99.188)
Epoch: [48][300/391]	Time 0.1881 Data 0.0019 Loss 0.4539 (0.3951)	Acc@1 82.031 (87.477)	Acc@5 97.656 (99.143)
Testing the models......
Loss: 1.5590, Prec@1: 63.98, Prec@5: 87.61
Epoch time: 80s
Epoch: 49  lr: 0.100
Epoch: [49][000/391]	Time 1.1257 Data 0.9113 Loss 0.2983 (0.2983)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [49][100/391]	Time 0.1874 Data 0.0020 Loss 0.2642 (0.3460)	Acc@1 89.062 (89.155)	Acc@5 100.000 (99.350)
Epoch: [49][200/391]	Time 0.1897 Data 0.0020 Loss 0.3791 (0.3618)	Acc@1 89.844 (88.647)	Acc@5 98.438 (99.273)
Epoch: [49][300/391]	Time 0.1876 Data 0.0024 Loss 0.4131 (0.3832)	Acc@1 87.500 (87.827)	Acc@5 99.219 (99.131)
Testing the models......
Loss: 1.4979, Prec@1: 64.73, Prec@5: 88.57
Epoch time: 80s
Epoch: 50  lr: 0.100
Epoch: [50][000/391]	Time 1.3265 Data 1.1204 Loss 0.4139 (0.4139)	Acc@1 88.281 (88.281)	Acc@5 98.438 (98.438)
Epoch: [50][100/391]	Time 0.1886 Data 0.0023 Loss 0.2385 (0.3475)	Acc@1 95.312 (89.101)	Acc@5 100.000 (99.165)
Epoch: [50][200/391]	Time 0.1873 Data 0.0021 Loss 0.3850 (0.3625)	Acc@1 86.719 (88.569)	Acc@5 99.219 (99.203)
Epoch: [50][300/391]	Time 0.1904 Data 0.0023 Loss 0.4312 (0.3846)	Acc@1 85.156 (87.967)	Acc@5 100.000 (99.037)
Testing the models......
Loss: 1.5207, Prec@1: 65.18, Prec@5: 88.32
Epoch time: 81s
Epoch: 51  lr: 0.100
Epoch: [51][000/391]	Time 1.1294 Data 0.9324 Loss 0.5357 (0.5357)	Acc@1 85.156 (85.156)	Acc@5 96.094 (96.094)
Epoch: [51][100/391]	Time 0.1885 Data 0.0021 Loss 0.2917 (0.3492)	Acc@1 89.844 (88.598)	Acc@5 100.000 (99.312)
Epoch: [51][200/391]	Time 0.1868 Data 0.0019 Loss 0.3778 (0.3598)	Acc@1 86.719 (88.437)	Acc@5 99.219 (99.246)
Epoch: [51][300/391]	Time 0.1871 Data 0.0021 Loss 0.2938 (0.3826)	Acc@1 89.062 (87.856)	Acc@5 100.000 (99.141)
Testing the models......
Loss: 1.4887, Prec@1: 66.19, Prec@5: 89.13
Epoch time: 80s
Saving models
Epoch: 52  lr: 0.100
Epoch: [52][000/391]	Time 1.1775 Data 0.9093 Loss 0.3265 (0.3265)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [52][100/391]	Time 0.1870 Data 0.0020 Loss 0.4657 (0.3444)	Acc@1 86.719 (88.923)	Acc@5 99.219 (99.358)
Epoch: [52][200/391]	Time 0.1872 Data 0.0019 Loss 0.4762 (0.3547)	Acc@1 81.250 (88.744)	Acc@5 100.000 (99.281)
Epoch: [52][300/391]	Time 0.1869 Data 0.0021 Loss 0.3895 (0.3745)	Acc@1 85.156 (88.185)	Acc@5 100.000 (99.185)
Testing the models......
Loss: 1.5296, Prec@1: 64.82, Prec@5: 88.42
Epoch time: 80s
Epoch: 53  lr: 0.100
Epoch: [53][000/391]	Time 1.1677 Data 0.9031 Loss 0.3577 (0.3577)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [53][100/391]	Time 0.1869 Data 0.0020 Loss 0.4221 (0.3352)	Acc@1 85.938 (89.666)	Acc@5 100.000 (99.350)
Epoch: [53][200/391]	Time 0.1885 Data 0.0019 Loss 0.3391 (0.3487)	Acc@1 90.625 (89.183)	Acc@5 98.438 (99.250)
Epoch: [53][300/391]	Time 0.1869 Data 0.0020 Loss 0.4019 (0.3637)	Acc@1 87.500 (88.600)	Acc@5 97.656 (99.201)
Testing the models......
Loss: 1.5567, Prec@1: 64.47, Prec@5: 88.54
Epoch time: 80s
Epoch: 54  lr: 0.100
Epoch: [54][000/391]	Time 1.1346 Data 0.9306 Loss 0.2988 (0.2988)	Acc@1 89.844 (89.844)	Acc@5 98.438 (98.438)
Epoch: [54][100/391]	Time 0.1871 Data 0.0020 Loss 0.3978 (0.3353)	Acc@1 88.281 (89.209)	Acc@5 99.219 (99.343)
Epoch: [54][200/391]	Time 0.1874 Data 0.0019 Loss 0.3495 (0.3425)	Acc@1 86.719 (89.039)	Acc@5 100.000 (99.269)
Epoch: [54][300/391]	Time 0.1877 Data 0.0020 Loss 0.3742 (0.3541)	Acc@1 88.281 (88.847)	Acc@5 100.000 (99.206)
Testing the models......
Loss: 1.5339, Prec@1: 64.77, Prec@5: 88.03
Epoch time: 80s
Epoch: 55  lr: 0.100
Epoch: [55][000/391]	Time 1.1561 Data 0.9644 Loss 0.3658 (0.3658)	Acc@1 91.406 (91.406)	Acc@5 98.438 (98.438)
Epoch: [55][100/391]	Time 0.1869 Data 0.0022 Loss 0.2477 (0.3261)	Acc@1 94.531 (89.991)	Acc@5 100.000 (99.373)
Epoch: [55][200/391]	Time 0.1876 Data 0.0020 Loss 0.4959 (0.3476)	Acc@1 85.938 (89.140)	Acc@5 98.438 (99.339)
Epoch: [55][300/391]	Time 0.1875 Data 0.0020 Loss 0.2516 (0.3660)	Acc@1 92.188 (88.538)	Acc@5 100.000 (99.252)
Testing the models......
Loss: 1.5706, Prec@1: 63.96, Prec@5: 87.99
Epoch time: 80s
Epoch: 56  lr: 0.100
Epoch: [56][000/391]	Time 1.1422 Data 0.8733 Loss 0.4138 (0.4138)	Acc@1 85.156 (85.156)	Acc@5 98.438 (98.438)
Epoch: [56][100/391]	Time 0.1875 Data 0.0020 Loss 0.2571 (0.3408)	Acc@1 91.406 (89.364)	Acc@5 100.000 (99.226)
Epoch: [56][200/391]	Time 0.1878 Data 0.0020 Loss 0.3779 (0.3405)	Acc@1 89.062 (89.354)	Acc@5 99.219 (99.277)
Epoch: [56][300/391]	Time 0.1884 Data 0.0020 Loss 0.4465 (0.3622)	Acc@1 85.156 (88.569)	Acc@5 98.438 (99.208)
Testing the models......
Loss: 1.5705, Prec@1: 65.31, Prec@5: 87.89
Epoch time: 80s
Epoch: 57  lr: 0.100
Epoch: [57][000/391]	Time 1.0550 Data 0.8319 Loss 0.3202 (0.3202)	Acc@1 89.062 (89.062)	Acc@5 100.000 (100.000)
Epoch: [57][100/391]	Time 0.1891 Data 0.0030 Loss 0.3671 (0.3368)	Acc@1 86.719 (89.264)	Acc@5 99.219 (99.451)
Epoch: [57][200/391]	Time 0.1872 Data 0.0019 Loss 0.3671 (0.3482)	Acc@1 89.844 (88.961)	Acc@5 97.656 (99.382)
Epoch: [57][300/391]	Time 0.1880 Data 0.0020 Loss 0.3743 (0.3610)	Acc@1 89.062 (88.523)	Acc@5 100.000 (99.294)
Testing the models......
Loss: 1.4670, Prec@1: 66.68, Prec@5: 89.25
Epoch time: 80s
Saving models
Epoch: 58  lr: 0.100
Epoch: [58][000/391]	Time 1.1078 Data 0.8395 Loss 0.2619 (0.2619)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [58][100/391]	Time 0.1876 Data 0.0020 Loss 0.4003 (0.3033)	Acc@1 87.500 (90.285)	Acc@5 100.000 (99.497)
Epoch: [58][200/391]	Time 0.1873 Data 0.0021 Loss 0.3631 (0.3183)	Acc@1 89.844 (89.949)	Acc@5 97.656 (99.429)
Epoch: [58][300/391]	Time 0.1879 Data 0.0019 Loss 0.3766 (0.3359)	Acc@1 87.500 (89.392)	Acc@5 100.000 (99.385)
Testing the models......
Loss: 1.5947, Prec@1: 64.80, Prec@5: 88.09
Epoch time: 80s
Epoch: 59  lr: 0.100
Epoch: [59][000/391]	Time 1.1432 Data 0.9326 Loss 0.4284 (0.4284)	Acc@1 85.938 (85.938)	Acc@5 98.438 (98.438)
Epoch: [59][100/391]	Time 0.1873 Data 0.0019 Loss 0.2954 (0.2918)	Acc@1 92.969 (91.166)	Acc@5 99.219 (99.551)
Epoch: [59][200/391]	Time 0.1883 Data 0.0020 Loss 0.4040 (0.3000)	Acc@1 86.719 (90.687)	Acc@5 100.000 (99.541)
Epoch: [59][300/391]	Time 0.1879 Data 0.0020 Loss 0.3986 (0.3236)	Acc@1 88.281 (89.896)	Acc@5 98.438 (99.416)
Testing the models......
Loss: 1.5167, Prec@1: 65.43, Prec@5: 88.79
Epoch time: 80s
Epoch: 60  lr: 0.100
Epoch: [60][000/391]	Time 1.1002 Data 0.9072 Loss 0.2913 (0.2913)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [60][100/391]	Time 0.1897 Data 0.0019 Loss 0.3878 (0.3106)	Acc@1 88.281 (90.432)	Acc@5 96.875 (99.381)
Epoch: [60][200/391]	Time 0.1874 Data 0.0019 Loss 0.3260 (0.3158)	Acc@1 89.062 (90.096)	Acc@5 99.219 (99.390)
Epoch: [60][300/391]	Time 0.1880 Data 0.0021 Loss 0.3307 (0.3252)	Acc@1 88.281 (89.704)	Acc@5 99.219 (99.390)
Testing the models......
Loss: 1.5768, Prec@1: 64.34, Prec@5: 87.41
Epoch time: 80s
Epoch: 61  lr: 0.100
Epoch: [61][000/391]	Time 1.1629 Data 1.0025 Loss 0.3075 (0.3075)	Acc@1 88.281 (88.281)	Acc@5 99.219 (99.219)
Epoch: [61][100/391]	Time 0.1878 Data 0.0020 Loss 0.3077 (0.3168)	Acc@1 92.188 (89.929)	Acc@5 100.000 (99.443)
Epoch: [61][200/391]	Time 0.1892 Data 0.0020 Loss 0.2608 (0.3124)	Acc@1 89.062 (89.953)	Acc@5 100.000 (99.421)
Epoch: [61][300/391]	Time 0.1866 Data 0.0020 Loss 0.4522 (0.3263)	Acc@1 86.719 (89.540)	Acc@5 97.656 (99.395)
Testing the models......
Loss: 1.4906, Prec@1: 66.64, Prec@5: 89.10
Epoch time: 81s
Epoch: 62  lr: 0.100
Epoch: [62][000/391]	Time 1.1073 Data 0.8916 Loss 0.2706 (0.2706)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [62][100/391]	Time 0.1875 Data 0.0021 Loss 0.2394 (0.2886)	Acc@1 92.969 (90.911)	Acc@5 100.000 (99.559)
Epoch: [62][200/391]	Time 0.1883 Data 0.0021 Loss 0.3213 (0.2966)	Acc@1 91.406 (90.738)	Acc@5 100.000 (99.475)
Epoch: [62][300/391]	Time 0.1883 Data 0.0019 Loss 0.3860 (0.3214)	Acc@1 88.281 (89.999)	Acc@5 99.219 (99.338)
Testing the models......
Loss: 1.5490, Prec@1: 65.13, Prec@5: 88.79
Epoch time: 80s
Epoch: 63  lr: 0.100
Epoch: [63][000/391]	Time 1.1260 Data 0.9136 Loss 0.3335 (0.3335)	Acc@1 90.625 (90.625)	Acc@5 99.219 (99.219)
Epoch: [63][100/391]	Time 0.1874 Data 0.0019 Loss 0.2282 (0.3071)	Acc@1 92.188 (90.176)	Acc@5 100.000 (99.528)
Epoch: [63][200/391]	Time 0.1872 Data 0.0019 Loss 0.5564 (0.3138)	Acc@1 82.812 (90.019)	Acc@5 98.438 (99.491)
Epoch: [63][300/391]	Time 0.1873 Data 0.0022 Loss 0.3560 (0.3233)	Acc@1 90.625 (89.771)	Acc@5 97.656 (99.445)
Testing the models......
Loss: 1.6398, Prec@1: 63.01, Prec@5: 87.06
Epoch time: 81s
Epoch: 64  lr: 0.100
Epoch: [64][000/391]	Time 1.1000 Data 0.8903 Loss 0.2895 (0.2895)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [64][100/391]	Time 0.1874 Data 0.0019 Loss 0.2341 (0.2941)	Acc@1 91.406 (90.934)	Acc@5 100.000 (99.474)
Epoch: [64][200/391]	Time 0.1878 Data 0.0020 Loss 0.4097 (0.3107)	Acc@1 89.062 (90.322)	Acc@5 100.000 (99.464)
Epoch: [64][300/391]	Time 0.1886 Data 0.0023 Loss 0.3456 (0.3234)	Acc@1 88.281 (89.883)	Acc@5 99.219 (99.369)
Testing the models......
Loss: 1.4686, Prec@1: 67.05, Prec@5: 89.32
Epoch time: 81s
Saving models
Epoch: 65  lr: 0.100
Epoch: [65][000/391]	Time 1.1445 Data 0.8882 Loss 0.2221 (0.2221)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [65][100/391]	Time 0.1883 Data 0.0019 Loss 0.2360 (0.3048)	Acc@1 91.406 (89.937)	Acc@5 100.000 (99.489)
Epoch: [65][200/391]	Time 0.1871 Data 0.0020 Loss 0.3417 (0.3096)	Acc@1 86.719 (89.875)	Acc@5 100.000 (99.429)
Epoch: [65][300/391]	Time 0.1880 Data 0.0020 Loss 0.5000 (0.3285)	Acc@1 85.156 (89.392)	Acc@5 100.000 (99.356)
Testing the models......
Loss: 1.6090, Prec@1: 65.51, Prec@5: 87.99
Epoch time: 80s
Epoch: 66  lr: 0.100
Epoch: [66][000/391]	Time 1.1398 Data 0.9212 Loss 0.2632 (0.2632)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [66][100/391]	Time 0.1900 Data 0.0020 Loss 0.3431 (0.2782)	Acc@1 89.062 (91.344)	Acc@5 100.000 (99.466)
Epoch: [66][200/391]	Time 0.1872 Data 0.0019 Loss 0.2269 (0.2980)	Acc@1 94.531 (90.617)	Acc@5 100.000 (99.479)
Epoch: [66][300/391]	Time 0.1874 Data 0.0019 Loss 0.3273 (0.3177)	Acc@1 90.625 (89.979)	Acc@5 99.219 (99.413)
Testing the models......
Loss: 1.5477, Prec@1: 65.76, Prec@5: 88.63
Epoch time: 80s
Epoch: 67  lr: 0.100
Epoch: [67][000/391]	Time 1.1518 Data 0.9323 Loss 0.2477 (0.2477)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [67][100/391]	Time 0.1874 Data 0.0021 Loss 0.3161 (0.2860)	Acc@1 89.844 (90.973)	Acc@5 99.219 (99.536)
Epoch: [67][200/391]	Time 0.1874 Data 0.0020 Loss 0.2095 (0.2917)	Acc@1 94.531 (90.784)	Acc@5 100.000 (99.468)
Epoch: [67][300/391]	Time 0.1871 Data 0.0020 Loss 0.3290 (0.3071)	Acc@1 89.844 (90.267)	Acc@5 99.219 (99.400)
Testing the models......
Loss: 1.5412, Prec@1: 66.67, Prec@5: 88.82
Epoch time: 80s
Epoch: 68  lr: 0.100
Epoch: [68][000/391]	Time 1.4617 Data 1.2954 Loss 0.2385 (0.2385)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [68][100/391]	Time 0.1872 Data 0.0021 Loss 0.2881 (0.2795)	Acc@1 92.188 (90.934)	Acc@5 99.219 (99.636)
Epoch: [68][200/391]	Time 0.1889 Data 0.0020 Loss 0.2083 (0.2901)	Acc@1 92.188 (90.854)	Acc@5 100.000 (99.537)
Epoch: [68][300/391]	Time 0.1872 Data 0.0019 Loss 0.3796 (0.3066)	Acc@1 89.062 (90.417)	Acc@5 98.438 (99.447)
Testing the models......
Loss: 1.7145, Prec@1: 63.66, Prec@5: 86.40
Epoch time: 81s
Epoch: 69  lr: 0.100
Epoch: [69][000/391]	Time 1.4418 Data 1.1720 Loss 0.3155 (0.3155)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [69][100/391]	Time 0.1878 Data 0.0020 Loss 0.2650 (0.2897)	Acc@1 92.188 (90.687)	Acc@5 99.219 (99.575)
Epoch: [69][200/391]	Time 0.1871 Data 0.0019 Loss 0.2626 (0.2953)	Acc@1 92.188 (90.757)	Acc@5 100.000 (99.553)
Epoch: [69][300/391]	Time 0.1900 Data 0.0023 Loss 0.5857 (0.3124)	Acc@1 81.250 (90.202)	Acc@5 97.656 (99.481)
Testing the models......
Loss: 1.5460, Prec@1: 66.19, Prec@5: 88.20
Epoch time: 81s
Epoch: 70  lr: 0.100
Epoch: [70][000/391]	Time 1.4623 Data 1.2919 Loss 0.2695 (0.2695)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [70][100/391]	Time 0.1874 Data 0.0021 Loss 0.2258 (0.2801)	Acc@1 96.094 (91.174)	Acc@5 100.000 (99.629)
Epoch: [70][200/391]	Time 0.1867 Data 0.0021 Loss 0.2150 (0.2842)	Acc@1 95.312 (91.165)	Acc@5 99.219 (99.580)
Epoch: [70][300/391]	Time 0.1868 Data 0.0020 Loss 0.2613 (0.2960)	Acc@1 92.188 (90.817)	Acc@5 100.000 (99.509)
Testing the models......
Loss: 1.7027, Prec@1: 63.88, Prec@5: 86.73
Epoch time: 81s
Epoch: 71  lr: 0.100
Epoch: [71][000/391]	Time 1.1274 Data 0.9008 Loss 0.2883 (0.2883)	Acc@1 89.844 (89.844)	Acc@5 100.000 (100.000)
Epoch: [71][100/391]	Time 0.1863 Data 0.0019 Loss 0.2714 (0.2793)	Acc@1 92.969 (91.545)	Acc@5 100.000 (99.582)
Epoch: [71][200/391]	Time 0.1873 Data 0.0020 Loss 0.2691 (0.2878)	Acc@1 90.625 (91.060)	Acc@5 100.000 (99.499)
Epoch: [71][300/391]	Time 0.1906 Data 0.0021 Loss 0.3688 (0.3017)	Acc@1 87.500 (90.568)	Acc@5 98.438 (99.419)
Testing the models......
Loss: 1.6276, Prec@1: 64.54, Prec@5: 87.82
Epoch time: 80s
Epoch: 72  lr: 0.100
Epoch: [72][000/391]	Time 1.0993 Data 0.9400 Loss 0.3642 (0.3642)	Acc@1 85.938 (85.938)	Acc@5 100.000 (100.000)
Epoch: [72][100/391]	Time 0.1889 Data 0.0022 Loss 0.2680 (0.3074)	Acc@1 90.625 (90.671)	Acc@5 100.000 (99.466)
Epoch: [72][200/391]	Time 0.1878 Data 0.0022 Loss 0.2682 (0.3014)	Acc@1 91.406 (90.668)	Acc@5 99.219 (99.444)
Epoch: [72][300/391]	Time 0.1879 Data 0.0020 Loss 0.2866 (0.3129)	Acc@1 92.188 (90.251)	Acc@5 99.219 (99.419)
Testing the models......
Loss: 1.5989, Prec@1: 65.44, Prec@5: 88.25
Epoch time: 81s
Epoch: 73  lr: 0.100
Epoch: [73][000/391]	Time 1.3617 Data 1.1305 Loss 0.2512 (0.2512)	Acc@1 90.625 (90.625)	Acc@5 100.000 (100.000)
Epoch: [73][100/391]	Time 0.1882 Data 0.0023 Loss 0.3897 (0.2836)	Acc@1 86.719 (91.027)	Acc@5 100.000 (99.598)
Epoch: [73][200/391]	Time 0.1903 Data 0.0023 Loss 0.3201 (0.2897)	Acc@1 86.719 (90.936)	Acc@5 100.000 (99.580)
Epoch: [73][300/391]	Time 0.1882 Data 0.0032 Loss 0.2852 (0.2991)	Acc@1 92.188 (90.524)	Acc@5 99.219 (99.515)
Testing the models......
Loss: 1.6102, Prec@1: 65.16, Prec@5: 87.78
Epoch time: 81s
Epoch: 74  lr: 0.100
Epoch: [74][000/391]	Time 1.0559 Data 0.8643 Loss 0.4296 (0.4296)	Acc@1 82.031 (82.031)	Acc@5 100.000 (100.000)
Epoch: [74][100/391]	Time 0.1869 Data 0.0020 Loss 0.2635 (0.2726)	Acc@1 89.062 (91.476)	Acc@5 100.000 (99.660)
Epoch: [74][200/391]	Time 0.1871 Data 0.0018 Loss 0.3565 (0.2837)	Acc@1 90.625 (91.204)	Acc@5 100.000 (99.576)
Epoch: [74][300/391]	Time 0.1876 Data 0.0019 Loss 0.2789 (0.2962)	Acc@1 91.406 (90.794)	Acc@5 100.000 (99.504)
Testing the models......
Loss: 1.5751, Prec@1: 65.62, Prec@5: 88.13
Epoch time: 80s
Epoch: 75  lr: 0.100
Epoch: [75][000/391]	Time 1.1123 Data 0.8985 Loss 0.3367 (0.3367)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [75][100/391]	Time 0.1956 Data 0.0021 Loss 0.2256 (0.2740)	Acc@1 92.969 (91.515)	Acc@5 100.000 (99.551)
Epoch: [75][200/391]	Time 0.1867 Data 0.0019 Loss 0.3419 (0.2698)	Acc@1 88.281 (91.721)	Acc@5 99.219 (99.545)
Epoch: [75][300/391]	Time 0.1880 Data 0.0027 Loss 0.3985 (0.2898)	Acc@1 85.156 (91.045)	Acc@5 100.000 (99.471)
Testing the models......
Loss: 1.5907, Prec@1: 64.84, Prec@5: 88.09
Epoch time: 81s
Epoch: 76  lr: 0.100
Epoch: [76][000/391]	Time 1.3394 Data 1.1314 Loss 0.1773 (0.1773)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [76][100/391]	Time 0.1877 Data 0.0024 Loss 0.3636 (0.2756)	Acc@1 87.500 (91.352)	Acc@5 100.000 (99.606)
Epoch: [76][200/391]	Time 0.1884 Data 0.0025 Loss 0.2666 (0.2742)	Acc@1 92.969 (91.332)	Acc@5 100.000 (99.604)
Epoch: [76][300/391]	Time 0.1903 Data 0.0019 Loss 0.3101 (0.2897)	Acc@1 88.281 (90.830)	Acc@5 99.219 (99.538)
Testing the models......
Loss: 1.5676, Prec@1: 65.91, Prec@5: 88.38
Epoch time: 81s
Epoch: 77  lr: 0.100
Epoch: [77][000/391]	Time 1.0772 Data 0.8101 Loss 0.2239 (0.2239)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [77][100/391]	Time 0.1905 Data 0.0026 Loss 0.2233 (0.2524)	Acc@1 95.312 (92.226)	Acc@5 100.000 (99.551)
Epoch: [77][200/391]	Time 0.1877 Data 0.0020 Loss 0.2968 (0.2665)	Acc@1 89.844 (91.639)	Acc@5 100.000 (99.569)
Epoch: [77][300/391]	Time 0.1876 Data 0.0019 Loss 0.4629 (0.2888)	Acc@1 85.156 (90.981)	Acc@5 97.656 (99.460)
Testing the models......
Loss: 1.5728, Prec@1: 65.81, Prec@5: 88.22
Epoch time: 81s
Epoch: 78  lr: 0.100
Epoch: [78][000/391]	Time 1.1240 Data 0.9555 Loss 0.3236 (0.3236)	Acc@1 92.188 (92.188)	Acc@5 99.219 (99.219)
Epoch: [78][100/391]	Time 0.1880 Data 0.0022 Loss 0.3627 (0.2675)	Acc@1 91.406 (91.584)	Acc@5 100.000 (99.598)
Epoch: [78][200/391]	Time 0.1897 Data 0.0023 Loss 0.4180 (0.2822)	Acc@1 88.281 (91.157)	Acc@5 100.000 (99.561)
Epoch: [78][300/391]	Time 0.1911 Data 0.0023 Loss 0.2928 (0.2927)	Acc@1 89.844 (90.789)	Acc@5 98.438 (99.491)
Testing the models......
Loss: 1.5207, Prec@1: 66.25, Prec@5: 88.35
Epoch time: 81s
Epoch: 79  lr: 0.100
Epoch: [79][000/391]	Time 1.3761 Data 1.1791 Loss 0.2426 (0.2426)	Acc@1 93.750 (93.750)	Acc@5 99.219 (99.219)
Epoch: [79][100/391]	Time 0.1912 Data 0.0023 Loss 0.2604 (0.2678)	Acc@1 92.188 (91.522)	Acc@5 100.000 (99.629)
Epoch: [79][200/391]	Time 0.1877 Data 0.0020 Loss 0.3102 (0.2897)	Acc@1 93.750 (90.920)	Acc@5 100.000 (99.553)
Epoch: [79][300/391]	Time 0.1892 Data 0.0023 Loss 0.3959 (0.3004)	Acc@1 87.500 (90.638)	Acc@5 99.219 (99.530)
Testing the models......
Loss: 1.5736, Prec@1: 65.05, Prec@5: 88.03
Epoch time: 81s
Epoch: 80  lr: 0.100
Epoch: [80][000/391]	Time 1.3159 Data 1.1153 Loss 0.2873 (0.2873)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [80][100/391]	Time 0.1907 Data 0.0022 Loss 0.3311 (0.2851)	Acc@1 90.625 (90.857)	Acc@5 100.000 (99.528)
Epoch: [80][200/391]	Time 0.1877 Data 0.0028 Loss 0.4534 (0.2880)	Acc@1 88.281 (91.068)	Acc@5 96.875 (99.483)
Epoch: [80][300/391]	Time 0.1874 Data 0.0020 Loss 0.3202 (0.3024)	Acc@1 89.844 (90.594)	Acc@5 100.000 (99.452)
Testing the models......
Loss: 1.4979, Prec@1: 66.86, Prec@5: 89.35
Epoch time: 81s
Epoch: 81  lr: 0.100
Epoch: [81][000/391]	Time 1.1430 Data 0.8826 Loss 0.2231 (0.2231)	Acc@1 93.750 (93.750)	Acc@5 100.000 (100.000)
Epoch: [81][100/391]	Time 0.1882 Data 0.0025 Loss 0.2281 (0.2707)	Acc@1 94.531 (91.700)	Acc@5 99.219 (99.575)
Epoch: [81][200/391]	Time 0.1875 Data 0.0025 Loss 0.3995 (0.2777)	Acc@1 87.500 (91.453)	Acc@5 98.438 (99.510)
Epoch: [81][300/391]	Time 0.1888 Data 0.0023 Loss 0.1654 (0.2833)	Acc@1 95.312 (91.253)	Acc@5 100.000 (99.496)
Testing the models......
Loss: 1.4739, Prec@1: 66.48, Prec@5: 88.68
Epoch time: 81s
Epoch: 82  lr: 0.100
Epoch: [82][000/391]	Time 1.3189 Data 1.0960 Loss 0.2264 (0.2264)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [82][100/391]	Time 0.1908 Data 0.0024 Loss 0.4677 (0.2724)	Acc@1 85.156 (91.429)	Acc@5 96.875 (99.528)
Epoch: [82][200/391]	Time 0.1886 Data 0.0020 Loss 0.3872 (0.2798)	Acc@1 86.719 (91.189)	Acc@5 99.219 (99.553)
Epoch: [82][300/391]	Time 0.1910 Data 0.0024 Loss 0.3756 (0.2913)	Acc@1 85.156 (90.770)	Acc@5 99.219 (99.522)
Testing the models......
Loss: 1.6973, Prec@1: 64.30, Prec@5: 86.93
Epoch time: 81s
Epoch: 83  lr: 0.100
Epoch: [83][000/391]	Time 1.3690 Data 1.2208 Loss 0.2434 (0.2434)	Acc@1 92.188 (92.188)	Acc@5 100.000 (100.000)
Epoch: [83][100/391]	Time 0.1891 Data 0.0028 Loss 0.2792 (0.2381)	Acc@1 91.406 (92.652)	Acc@5 100.000 (99.706)
Epoch: [83][200/391]	Time 0.1886 Data 0.0020 Loss 0.2290 (0.2520)	Acc@1 89.844 (92.094)	Acc@5 100.000 (99.642)
Epoch: [83][300/391]	Time 0.1891 Data 0.0023 Loss 0.2423 (0.2694)	Acc@1 89.844 (91.632)	Acc@5 100.000 (99.569)
Testing the models......
Loss: 1.6259, Prec@1: 65.71, Prec@5: 88.59
Epoch time: 81s
Epoch: 84  lr: 0.100
Epoch: [84][000/391]	Time 1.3660 Data 1.2031 Loss 0.3245 (0.3245)	Acc@1 88.281 (88.281)	Acc@5 100.000 (100.000)
Epoch: [84][100/391]	Time 0.1901 Data 0.0024 Loss 0.2126 (0.2527)	Acc@1 93.750 (91.963)	Acc@5 100.000 (99.606)
Epoch: [84][200/391]	Time 0.1886 Data 0.0024 Loss 0.3285 (0.2639)	Acc@1 90.625 (91.741)	Acc@5 99.219 (99.604)
Epoch: [84][300/391]	Time 0.1885 Data 0.0023 Loss 0.2922 (0.2746)	Acc@1 90.625 (91.362)	Acc@5 99.219 (99.538)
Testing the models......
Loss: 1.5594, Prec@1: 66.01, Prec@5: 88.18
Epoch time: 81s
Epoch: 85  lr: 0.100
Epoch: [85][000/391]	Time 1.1725 Data 0.9532 Loss 0.2593 (0.2593)	Acc@1 92.969 (92.969)	Acc@5 99.219 (99.219)
Epoch: [85][100/391]	Time 0.1923 Data 0.0023 Loss 0.2785 (0.2483)	Acc@1 91.406 (92.505)	Acc@5 99.219 (99.551)
Epoch: [85][200/391]	Time 0.1905 Data 0.0020 Loss 0.2271 (0.2540)	Acc@1 93.750 (92.145)	Acc@5 100.000 (99.569)
Epoch: [85][300/391]	Time 0.1877 Data 0.0020 Loss 0.3057 (0.2709)	Acc@1 91.406 (91.700)	Acc@5 100.000 (99.522)
Testing the models......
Loss: 1.6251, Prec@1: 65.33, Prec@5: 87.63
Epoch time: 81s
Epoch: 86  lr: 0.100
Epoch: [86][000/391]	Time 1.0952 Data 0.8609 Loss 0.2975 (0.2975)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [86][100/391]	Time 0.1874 Data 0.0020 Loss 0.2901 (0.2605)	Acc@1 91.406 (91.870)	Acc@5 99.219 (99.582)
Epoch: [86][200/391]	Time 0.1878 Data 0.0020 Loss 0.3832 (0.2695)	Acc@1 86.719 (91.585)	Acc@5 100.000 (99.611)
Epoch: [86][300/391]	Time 0.1877 Data 0.0022 Loss 0.2522 (0.2873)	Acc@1 93.750 (90.988)	Acc@5 100.000 (99.525)
Testing the models......
Loss: 1.7043, Prec@1: 64.09, Prec@5: 87.71
Epoch time: 81s
Epoch: 87  lr: 0.100
Epoch: [87][000/391]	Time 1.1258 Data 0.9150 Loss 0.3034 (0.3034)	Acc@1 91.406 (91.406)	Acc@5 100.000 (100.000)
Epoch: [87][100/391]	Time 0.1869 Data 0.0020 Loss 0.3395 (0.2776)	Acc@1 89.844 (91.368)	Acc@5 98.438 (99.551)
Epoch: [87][200/391]	Time 0.1872 Data 0.0024 Loss 0.3629 (0.2808)	Acc@1 89.844 (91.239)	Acc@5 99.219 (99.522)
Epoch: [87][300/391]	Time 0.1888 Data 0.0021 Loss 0.2034 (0.2892)	Acc@1 92.969 (90.973)	Acc@5 100.000 (99.494)
Testing the models......
Loss: 1.5441, Prec@1: 66.55, Prec@5: 89.13
Epoch time: 81s
Epoch: 88  lr: 0.100
Epoch: [88][000/391]	Time 1.0917 Data 0.8670 Loss 0.1724 (0.1724)	Acc@1 96.094 (96.094)	Acc@5 100.000 (100.000)
Epoch: [88][100/391]	Time 0.1896 Data 0.0020 Loss 0.3043 (0.2702)	Acc@1 89.062 (91.708)	Acc@5 100.000 (99.575)
Epoch: [88][200/391]	Time 0.1875 Data 0.0021 Loss 0.4467 (0.2830)	Acc@1 85.938 (91.262)	Acc@5 99.219 (99.545)
Epoch: [88][300/391]	Time 0.1875 Data 0.0020 Loss 0.3676 (0.2926)	Acc@1 89.062 (90.895)	Acc@5 99.219 (99.512)
Testing the models......
Loss: 1.6477, Prec@1: 64.14, Prec@5: 87.08
Epoch time: 81s
Epoch: 89  lr: 0.100
Epoch: [89][000/391]	Time 1.1901 Data 0.9890 Loss 0.1687 (0.1687)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [89][100/391]	Time 0.1875 Data 0.0020 Loss 0.2689 (0.2581)	Acc@1 92.969 (92.048)	Acc@5 100.000 (99.551)
Epoch: [89][200/391]	Time 0.1887 Data 0.0023 Loss 0.2232 (0.2635)	Acc@1 92.188 (91.752)	Acc@5 100.000 (99.565)
Epoch: [89][300/391]	Time 0.1885 Data 0.0030 Loss 0.3121 (0.2732)	Acc@1 89.062 (91.404)	Acc@5 99.219 (99.546)
Testing the models......
Loss: 1.6222, Prec@1: 65.24, Prec@5: 87.87
Epoch time: 81s
Epoch: 90  lr: 0.100
Epoch: [90][000/391]	Time 1.1795 Data 0.9743 Loss 0.2053 (0.2053)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [90][100/391]	Time 0.1883 Data 0.0023 Loss 0.1898 (0.2568)	Acc@1 92.188 (91.909)	Acc@5 100.000 (99.652)
Epoch: [90][200/391]	Time 0.1892 Data 0.0027 Loss 0.3423 (0.2598)	Acc@1 86.719 (91.842)	Acc@5 99.219 (99.580)
Epoch: [90][300/391]	Time 0.1875 Data 0.0021 Loss 0.3166 (0.2718)	Acc@1 90.625 (91.471)	Acc@5 99.219 (99.559)
Testing the models......
Loss: 1.6014, Prec@1: 65.80, Prec@5: 88.23
Epoch time: 81s
Epoch: 91  lr: 0.100
Epoch: [91][000/391]	Time 1.3677 Data 1.1484 Loss 0.3489 (0.3489)	Acc@1 89.844 (89.844)	Acc@5 98.438 (98.438)
Epoch: [91][100/391]	Time 0.1881 Data 0.0022 Loss 0.1846 (0.2411)	Acc@1 93.750 (92.582)	Acc@5 99.219 (99.660)
Epoch: [91][200/391]	Time 0.1874 Data 0.0021 Loss 0.3043 (0.2525)	Acc@1 90.625 (92.226)	Acc@5 100.000 (99.639)
Epoch: [91][300/391]	Time 0.1870 Data 0.0020 Loss 0.3039 (0.2669)	Acc@1 89.844 (91.764)	Acc@5 100.000 (99.577)
Testing the models......
Loss: 1.5864, Prec@1: 66.23, Prec@5: 88.28
Epoch time: 81s
Epoch: 92  lr: 0.100
Epoch: [92][000/391]	Time 1.2678 Data 1.0653 Loss 0.2789 (0.2789)	Acc@1 92.188 (92.188)	Acc@5 98.438 (98.438)
Epoch: [92][100/391]	Time 0.1892 Data 0.0022 Loss 0.3202 (0.2468)	Acc@1 90.625 (92.528)	Acc@5 100.000 (99.582)
Epoch: [92][200/391]	Time 0.1874 Data 0.0023 Loss 0.1534 (0.2600)	Acc@1 94.531 (92.071)	Acc@5 100.000 (99.557)
Epoch: [92][300/391]	Time 0.1878 Data 0.0022 Loss 0.2309 (0.2753)	Acc@1 93.750 (91.562)	Acc@5 98.438 (99.517)
Testing the models......
Loss: 1.6849, Prec@1: 64.70, Prec@5: 87.17
Epoch time: 81s
Epoch: 93  lr: 0.100
Epoch: [93][000/391]	Time 1.4363 Data 1.2852 Loss 0.3752 (0.3752)	Acc@1 91.406 (91.406)	Acc@5 97.656 (97.656)
Epoch: [93][100/391]	Time 0.1915 Data 0.0022 Loss 0.1834 (0.2617)	Acc@1 93.750 (92.133)	Acc@5 100.000 (99.629)
Epoch: [93][200/391]	Time 0.1898 Data 0.0024 Loss 0.2195 (0.2560)	Acc@1 92.969 (92.335)	Acc@5 100.000 (99.623)
Epoch: [93][300/391]	Time 0.1876 Data 0.0027 Loss 0.2592 (0.2596)	Acc@1 93.750 (92.099)	Acc@5 99.219 (99.592)
Testing the models......
Loss: 1.4969, Prec@1: 67.58, Prec@5: 88.76
Epoch time: 81s
Saving models
Epoch: 94  lr: 0.100
Epoch: [94][000/391]	Time 1.3281 Data 1.1718 Loss 0.2577 (0.2577)	Acc@1 91.406 (91.406)	Acc@5 99.219 (99.219)
Epoch: [94][100/391]	Time 0.1871 Data 0.0020 Loss 0.1296 (0.2315)	Acc@1 96.094 (92.915)	Acc@5 100.000 (99.698)
Epoch: [94][200/391]	Time 0.1920 Data 0.0021 Loss 0.1691 (0.2264)	Acc@1 96.094 (93.190)	Acc@5 99.219 (99.681)
Epoch: [94][300/391]	Time 0.1872 Data 0.0021 Loss 0.1745 (0.2394)	Acc@1 96.094 (92.668)	Acc@5 99.219 (99.652)
Testing the models......
Loss: 1.6202, Prec@1: 65.78, Prec@5: 87.68
Epoch time: 81s
Epoch: 95  lr: 0.100
Epoch: [95][000/391]	Time 1.1284 Data 0.9447 Loss 0.1522 (0.1522)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [95][100/391]	Time 0.1883 Data 0.0020 Loss 0.2253 (0.2516)	Acc@1 93.750 (92.133)	Acc@5 100.000 (99.652)
Epoch: [95][200/391]	Time 0.1877 Data 0.0019 Loss 0.3061 (0.2675)	Acc@1 89.062 (91.461)	Acc@5 99.219 (99.565)
Epoch: [95][300/391]	Time 0.1874 Data 0.0020 Loss 0.3045 (0.2891)	Acc@1 92.969 (90.882)	Acc@5 98.438 (99.483)
Testing the models......
Loss: 1.5972, Prec@1: 66.05, Prec@5: 87.87
Epoch time: 80s
Epoch: 96  lr: 0.100
Epoch: [96][000/391]	Time 1.1433 Data 0.8828 Loss 0.3398 (0.3398)	Acc@1 89.062 (89.062)	Acc@5 99.219 (99.219)
Epoch: [96][100/391]	Time 0.1871 Data 0.0020 Loss 0.2086 (0.2511)	Acc@1 94.531 (92.373)	Acc@5 100.000 (99.582)
Epoch: [96][200/391]	Time 0.1894 Data 0.0019 Loss 0.2393 (0.2519)	Acc@1 94.531 (92.347)	Acc@5 99.219 (99.565)
Epoch: [96][300/391]	Time 0.1874 Data 0.0022 Loss 0.1634 (0.2634)	Acc@1 94.531 (91.910)	Acc@5 100.000 (99.541)
Testing the models......
Loss: 1.6776, Prec@1: 64.00, Prec@5: 87.36
Epoch time: 80s
Epoch: 97  lr: 0.100
Epoch: [97][000/391]	Time 1.1609 Data 0.9593 Loss 0.3203 (0.3203)	Acc@1 91.406 (91.406)	Acc@5 97.656 (97.656)
Epoch: [97][100/391]	Time 0.1878 Data 0.0020 Loss 0.2333 (0.2495)	Acc@1 92.188 (92.172)	Acc@5 100.000 (99.652)
Epoch: [97][200/391]	Time 0.1872 Data 0.0019 Loss 0.3275 (0.2528)	Acc@1 90.625 (92.086)	Acc@5 98.438 (99.607)
Epoch: [97][300/391]	Time 0.1879 Data 0.0019 Loss 0.2587 (0.2629)	Acc@1 91.406 (91.788)	Acc@5 100.000 (99.561)
Testing the models......
Loss: 1.5326, Prec@1: 66.14, Prec@5: 88.45
Epoch time: 80s
Epoch: 98  lr: 0.100
Epoch: [98][000/391]	Time 1.1338 Data 0.9029 Loss 0.1686 (0.1686)	Acc@1 96.875 (96.875)	Acc@5 100.000 (100.000)
Epoch: [98][100/391]	Time 0.1880 Data 0.0021 Loss 0.2802 (0.2542)	Acc@1 91.406 (92.257)	Acc@5 99.219 (99.606)
Epoch: [98][200/391]	Time 0.1867 Data 0.0019 Loss 0.2907 (0.2500)	Acc@1 91.406 (92.351)	Acc@5 98.438 (99.611)
Epoch: [98][300/391]	Time 0.1870 Data 0.0020 Loss 0.2403 (0.2591)	Acc@1 92.188 (92.034)	Acc@5 100.000 (99.590)
Testing the models......
Loss: 1.6200, Prec@1: 64.66, Prec@5: 88.15
Epoch time: 81s
Epoch: 99  lr: 0.100
Epoch: [99][000/391]	Time 1.1627 Data 0.9665 Loss 0.2364 (0.2364)	Acc@1 92.969 (92.969)	Acc@5 100.000 (100.000)
Epoch: [99][100/391]	Time 0.1877 Data 0.0020 Loss 0.3289 (0.2421)	Acc@1 89.062 (92.389)	Acc@5 100.000 (99.644)
Epoch: [99][200/391]	Time 0.1894 Data 0.0029 Loss 0.2179 (0.2637)	Acc@1 92.188 (91.787)	Acc@5 100.000 (99.545)
Epoch: [99][300/391]	Time 0.1870 Data 0.0020 Loss 0.2672 (0.2742)	Acc@1 92.969 (91.448)	Acc@5 100.000 (99.509)
Testing the models......
Loss: 1.6145, Prec@1: 65.78, Prec@5: 88.03
Epoch time: 81s
Epoch: 100  lr: 0.010
Epoch: [100][000/391]	Time 1.4092 Data 1.2457 Loss 0.2407 (0.2407)	Acc@1 94.531 (94.531)	Acc@5 100.000 (100.000)
Epoch: [100][100/391]	Time 0.1875 Data 0.0020 Loss 0.1549 (0.1455)	Acc@1 94.531 (95.970)	Acc@5 100.000 (99.868)
Epoch: [100][200/391]	Time 0.1872 Data 0.0020 Loss 0.0245 (0.1159)	Acc@1 100.000 (96.964)	Acc@5 100.000 (99.926)
Epoch: [100][300/391]	Time 0.1927 Data 0.0020 Loss 0.0919 (0.1025)	Acc@1 97.656 (97.386)	Acc@5 100.000 (99.943)
Testing the models......
Loss: 1.0599, Prec@1: 73.93, Prec@5: 92.44
Epoch time: 81s
Saving models
Epoch: 101  lr: 0.010
Epoch: [101][000/391]	Time 1.0752 Data 0.8601 Loss 0.0439 (0.0439)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [101][100/391]	Time 0.1876 Data 0.0019 Loss 0.0580 (0.0547)	Acc@1 98.438 (99.149)	Acc@5 100.000 (100.000)
Epoch: [101][200/391]	Time 0.1871 Data 0.0019 Loss 0.0963 (0.0533)	Acc@1 97.656 (99.137)	Acc@5 100.000 (100.000)
Epoch: [101][300/391]	Time 0.1882 Data 0.0020 Loss 0.0493 (0.0529)	Acc@1 99.219 (99.141)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0230, Prec@1: 74.56, Prec@5: 92.89
Epoch time: 80s
Saving models
Epoch: 102  lr: 0.010
Epoch: [102][000/391]	Time 0.9701 Data 0.7877 Loss 0.0317 (0.0317)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [102][100/391]	Time 0.1893 Data 0.0020 Loss 0.0306 (0.0434)	Acc@1 100.000 (99.381)	Acc@5 100.000 (100.000)
Epoch: [102][200/391]	Time 0.1879 Data 0.0019 Loss 0.0562 (0.0428)	Acc@1 97.656 (99.409)	Acc@5 100.000 (100.000)
Epoch: [102][300/391]	Time 0.1873 Data 0.0019 Loss 0.0235 (0.0431)	Acc@1 100.000 (99.416)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 1.0107, Prec@1: 74.74, Prec@5: 92.86
Epoch time: 80s
Saving models
Epoch: 103  lr: 0.010
Epoch: [103][000/391]	Time 1.0325 Data 0.8015 Loss 0.0194 (0.0194)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [103][100/391]	Time 0.1870 Data 0.0019 Loss 0.0369 (0.0373)	Acc@1 100.000 (99.636)	Acc@5 100.000 (100.000)
Epoch: [103][200/391]	Time 0.1873 Data 0.0020 Loss 0.0236 (0.0370)	Acc@1 100.000 (99.642)	Acc@5 100.000 (99.996)
Epoch: [103][300/391]	Time 0.1878 Data 0.0030 Loss 0.0542 (0.0369)	Acc@1 98.438 (99.637)	Acc@5 100.000 (99.997)
Testing the models......
Loss: 0.9930, Prec@1: 74.88, Prec@5: 92.88
Epoch time: 80s
Saving models
Epoch: 104  lr: 0.010
Epoch: [104][000/391]	Time 1.0650 Data 0.8698 Loss 0.0280 (0.0280)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [104][100/391]	Time 0.1876 Data 0.0020 Loss 0.0471 (0.0342)	Acc@1 100.000 (99.644)	Acc@5 100.000 (100.000)
Epoch: [104][200/391]	Time 0.1878 Data 0.0019 Loss 0.0346 (0.0340)	Acc@1 99.219 (99.650)	Acc@5 100.000 (100.000)
Epoch: [104][300/391]	Time 0.1877 Data 0.0020 Loss 0.0382 (0.0337)	Acc@1 99.219 (99.665)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9808, Prec@1: 74.94, Prec@5: 93.00
Epoch time: 80s
Saving models
Epoch: 105  lr: 0.010
Epoch: [105][000/391]	Time 1.1780 Data 0.9428 Loss 0.0393 (0.0393)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [105][100/391]	Time 0.1884 Data 0.0021 Loss 0.0337 (0.0304)	Acc@1 99.219 (99.822)	Acc@5 100.000 (100.000)
Epoch: [105][200/391]	Time 0.1876 Data 0.0020 Loss 0.0363 (0.0309)	Acc@1 99.219 (99.802)	Acc@5 100.000 (100.000)
Epoch: [105][300/391]	Time 0.1873 Data 0.0019 Loss 0.0258 (0.0312)	Acc@1 100.000 (99.782)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9787, Prec@1: 75.17, Prec@5: 93.02
Epoch time: 81s
Saving models
Epoch: 106  lr: 0.010
Epoch: [106][000/391]	Time 1.0895 Data 0.8951 Loss 0.0301 (0.0301)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [106][100/391]	Time 0.1882 Data 0.0027 Loss 0.0323 (0.0297)	Acc@1 100.000 (99.706)	Acc@5 100.000 (100.000)
Epoch: [106][200/391]	Time 0.1880 Data 0.0021 Loss 0.0276 (0.0294)	Acc@1 99.219 (99.736)	Acc@5 100.000 (100.000)
Epoch: [106][300/391]	Time 0.1874 Data 0.0020 Loss 0.0210 (0.0293)	Acc@1 100.000 (99.733)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9748, Prec@1: 75.26, Prec@5: 92.94
Epoch time: 80s
Saving models
Epoch: 107  lr: 0.010
Epoch: [107][000/391]	Time 1.1409 Data 0.9417 Loss 0.0448 (0.0448)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [107][100/391]	Time 0.1874 Data 0.0020 Loss 0.0317 (0.0281)	Acc@1 100.000 (99.807)	Acc@5 100.000 (100.000)
Epoch: [107][200/391]	Time 0.1885 Data 0.0028 Loss 0.0183 (0.0279)	Acc@1 100.000 (99.841)	Acc@5 100.000 (100.000)
Epoch: [107][300/391]	Time 0.1879 Data 0.0020 Loss 0.0248 (0.0280)	Acc@1 100.000 (99.829)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9710, Prec@1: 75.19, Prec@5: 92.97
Epoch time: 81s
Epoch: 108  lr: 0.010
Epoch: [108][000/391]	Time 1.0589 Data 0.8547 Loss 0.0220 (0.0220)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [108][100/391]	Time 0.1871 Data 0.0020 Loss 0.0192 (0.0271)	Acc@1 100.000 (99.838)	Acc@5 100.000 (100.000)
Epoch: [108][200/391]	Time 0.1882 Data 0.0026 Loss 0.0258 (0.0273)	Acc@1 100.000 (99.848)	Acc@5 100.000 (100.000)
Epoch: [108][300/391]	Time 0.1881 Data 0.0020 Loss 0.0152 (0.0270)	Acc@1 100.000 (99.844)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9686, Prec@1: 75.18, Prec@5: 92.98
Epoch time: 80s
Epoch: 109  lr: 0.010
Epoch: [109][000/391]	Time 1.1406 Data 0.9320 Loss 0.0272 (0.0272)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [109][100/391]	Time 0.1872 Data 0.0020 Loss 0.0283 (0.0247)	Acc@1 100.000 (99.884)	Acc@5 100.000 (100.000)
Epoch: [109][200/391]	Time 0.1887 Data 0.0026 Loss 0.0230 (0.0253)	Acc@1 100.000 (99.899)	Acc@5 100.000 (100.000)
Epoch: [109][300/391]	Time 0.1878 Data 0.0019 Loss 0.0493 (0.0256)	Acc@1 99.219 (99.878)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9647, Prec@1: 75.50, Prec@5: 92.89
Epoch time: 81s
Saving models
Epoch: 110  lr: 0.010
Epoch: [110][000/391]	Time 1.1516 Data 0.9538 Loss 0.0173 (0.0173)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [110][100/391]	Time 0.1873 Data 0.0021 Loss 0.0244 (0.0256)	Acc@1 100.000 (99.814)	Acc@5 100.000 (100.000)
Epoch: [110][200/391]	Time 0.1868 Data 0.0020 Loss 0.0151 (0.0260)	Acc@1 100.000 (99.829)	Acc@5 100.000 (100.000)
Epoch: [110][300/391]	Time 0.1875 Data 0.0036 Loss 0.0302 (0.0255)	Acc@1 100.000 (99.860)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9623, Prec@1: 75.79, Prec@5: 92.98
Epoch time: 80s
Saving models
Epoch: 111  lr: 0.010
Epoch: [111][000/391]	Time 1.1190 Data 0.9106 Loss 0.0227 (0.0227)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [111][100/391]	Time 0.1904 Data 0.0024 Loss 0.0191 (0.0243)	Acc@1 100.000 (99.868)	Acc@5 100.000 (100.000)
Epoch: [111][200/391]	Time 0.1871 Data 0.0020 Loss 0.0275 (0.0247)	Acc@1 99.219 (99.876)	Acc@5 100.000 (100.000)
Epoch: [111][300/391]	Time 0.1886 Data 0.0027 Loss 0.0153 (0.0245)	Acc@1 100.000 (99.875)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9609, Prec@1: 75.59, Prec@5: 93.04
Epoch time: 80s
Epoch: 112  lr: 0.010
Epoch: [112][000/391]	Time 1.2898 Data 1.0696 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [112][100/391]	Time 0.1868 Data 0.0020 Loss 0.0255 (0.0234)	Acc@1 100.000 (99.892)	Acc@5 100.000 (100.000)
Epoch: [112][200/391]	Time 0.1871 Data 0.0024 Loss 0.0242 (0.0237)	Acc@1 100.000 (99.899)	Acc@5 100.000 (100.000)
Epoch: [112][300/391]	Time 0.1866 Data 0.0026 Loss 0.0282 (0.0234)	Acc@1 99.219 (99.914)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9633, Prec@1: 75.57, Prec@5: 93.06
Epoch time: 81s
Epoch: 113  lr: 0.010
Epoch: [113][000/391]	Time 1.2054 Data 0.9882 Loss 0.0194 (0.0194)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [113][100/391]	Time 0.1865 Data 0.0019 Loss 0.0264 (0.0231)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [113][200/391]	Time 0.1882 Data 0.0019 Loss 0.0198 (0.0235)	Acc@1 100.000 (99.899)	Acc@5 100.000 (100.000)
Epoch: [113][300/391]	Time 0.1871 Data 0.0020 Loss 0.0168 (0.0234)	Acc@1 100.000 (99.899)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9560, Prec@1: 75.63, Prec@5: 93.11
Epoch time: 81s
Epoch: 114  lr: 0.010
Epoch: [114][000/391]	Time 1.3207 Data 1.1243 Loss 0.0340 (0.0340)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [114][100/391]	Time 0.1903 Data 0.0023 Loss 0.0263 (0.0226)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [114][200/391]	Time 0.1874 Data 0.0021 Loss 0.0161 (0.0231)	Acc@1 100.000 (99.918)	Acc@5 100.000 (100.000)
Epoch: [114][300/391]	Time 0.1920 Data 0.0020 Loss 0.0185 (0.0227)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9544, Prec@1: 75.66, Prec@5: 93.12
Epoch time: 81s
Epoch: 115  lr: 0.010
Epoch: [115][000/391]	Time 1.1144 Data 0.8985 Loss 0.0197 (0.0197)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [115][100/391]	Time 0.1885 Data 0.0024 Loss 0.0199 (0.0242)	Acc@1 100.000 (99.876)	Acc@5 100.000 (100.000)
Epoch: [115][200/391]	Time 0.1909 Data 0.0023 Loss 0.0211 (0.0233)	Acc@1 100.000 (99.903)	Acc@5 100.000 (100.000)
Epoch: [115][300/391]	Time 0.1878 Data 0.0024 Loss 0.0246 (0.0228)	Acc@1 100.000 (99.920)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9535, Prec@1: 75.64, Prec@5: 92.95
Epoch time: 81s
Epoch: 116  lr: 0.010
Epoch: [116][000/391]	Time 1.3843 Data 1.1882 Loss 0.0203 (0.0203)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [116][100/391]	Time 0.1888 Data 0.0023 Loss 0.0204 (0.0219)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [116][200/391]	Time 0.1906 Data 0.0020 Loss 0.0244 (0.0215)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [116][300/391]	Time 0.1870 Data 0.0020 Loss 0.0210 (0.0217)	Acc@1 100.000 (99.933)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9532, Prec@1: 75.76, Prec@5: 93.09
Epoch time: 81s
Epoch: 117  lr: 0.010
Epoch: [117][000/391]	Time 1.0541 Data 0.8308 Loss 0.0288 (0.0288)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [117][100/391]	Time 0.1880 Data 0.0020 Loss 0.0193 (0.0201)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [117][200/391]	Time 0.1884 Data 0.0019 Loss 0.0220 (0.0206)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [117][300/391]	Time 0.1869 Data 0.0020 Loss 0.0168 (0.0207)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9489, Prec@1: 75.90, Prec@5: 93.05
Epoch time: 81s
Saving models
Epoch: 118  lr: 0.010
Epoch: [118][000/391]	Time 1.1705 Data 0.9535 Loss 0.0185 (0.0185)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [118][100/391]	Time 0.1880 Data 0.0020 Loss 0.0235 (0.0210)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [118][200/391]	Time 0.1869 Data 0.0019 Loss 0.0224 (0.0213)	Acc@1 100.000 (99.934)	Acc@5 100.000 (100.000)
Epoch: [118][300/391]	Time 0.1875 Data 0.0020 Loss 0.0306 (0.0215)	Acc@1 99.219 (99.922)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9461, Prec@1: 75.90, Prec@5: 93.14
Epoch time: 81s
Epoch: 119  lr: 0.010
Epoch: [119][000/391]	Time 1.1003 Data 0.8884 Loss 0.0282 (0.0282)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [119][100/391]	Time 0.1876 Data 0.0022 Loss 0.0296 (0.0204)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [119][200/391]	Time 0.1874 Data 0.0019 Loss 0.0146 (0.0204)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [119][300/391]	Time 0.1875 Data 0.0019 Loss 0.0164 (0.0205)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9499, Prec@1: 75.86, Prec@5: 92.99
Epoch time: 81s
Epoch: 120  lr: 0.010
Epoch: [120][000/391]	Time 1.0946 Data 0.8816 Loss 0.0260 (0.0260)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [120][100/391]	Time 0.1889 Data 0.0025 Loss 0.0192 (0.0201)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [120][200/391]	Time 0.1886 Data 0.0024 Loss 0.0125 (0.0201)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [120][300/391]	Time 0.1876 Data 0.0020 Loss 0.0144 (0.0203)	Acc@1 100.000 (99.927)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9474, Prec@1: 75.93, Prec@5: 93.03
Epoch time: 81s
Saving models
Epoch: 121  lr: 0.010
Epoch: [121][000/391]	Time 1.1659 Data 0.8868 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [121][100/391]	Time 0.1872 Data 0.0020 Loss 0.0249 (0.0204)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [121][200/391]	Time 0.1869 Data 0.0021 Loss 0.0225 (0.0204)	Acc@1 100.000 (99.922)	Acc@5 100.000 (100.000)
Epoch: [121][300/391]	Time 0.1878 Data 0.0020 Loss 0.0145 (0.0201)	Acc@1 100.000 (99.935)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9473, Prec@1: 75.81, Prec@5: 93.04
Epoch time: 80s
Epoch: 122  lr: 0.010
Epoch: [122][000/391]	Time 1.1062 Data 0.8389 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [122][100/391]	Time 0.1876 Data 0.0020 Loss 0.0189 (0.0202)	Acc@1 100.000 (99.907)	Acc@5 100.000 (100.000)
Epoch: [122][200/391]	Time 0.1871 Data 0.0020 Loss 0.0285 (0.0199)	Acc@1 100.000 (99.926)	Acc@5 100.000 (100.000)
Epoch: [122][300/391]	Time 0.1876 Data 0.0020 Loss 0.0191 (0.0199)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9436, Prec@1: 76.02, Prec@5: 93.10
Epoch time: 80s
Saving models
Epoch: 123  lr: 0.010
Epoch: [123][000/391]	Time 1.0967 Data 0.9038 Loss 0.0177 (0.0177)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [123][100/391]	Time 0.1960 Data 0.0019 Loss 0.0224 (0.0192)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [123][200/391]	Time 0.1873 Data 0.0020 Loss 0.0189 (0.0192)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [123][300/391]	Time 0.1876 Data 0.0020 Loss 0.0146 (0.0193)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9451, Prec@1: 76.06, Prec@5: 93.03
Epoch time: 80s
Saving models
Epoch: 124  lr: 0.010
Epoch: [124][000/391]	Time 1.1574 Data 0.9303 Loss 0.0168 (0.0168)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [124][100/391]	Time 0.1873 Data 0.0020 Loss 0.0139 (0.0189)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [124][200/391]	Time 0.1873 Data 0.0019 Loss 0.0151 (0.0192)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [124][300/391]	Time 0.1881 Data 0.0022 Loss 0.0135 (0.0191)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9460, Prec@1: 75.96, Prec@5: 92.88
Epoch time: 81s
Epoch: 125  lr: 0.010
Epoch: [125][000/391]	Time 1.0677 Data 0.8615 Loss 0.0154 (0.0154)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [125][100/391]	Time 0.1874 Data 0.0020 Loss 0.0161 (0.0190)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [125][200/391]	Time 0.1876 Data 0.0019 Loss 0.0233 (0.0192)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [125][300/391]	Time 0.1874 Data 0.0020 Loss 0.0148 (0.0190)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9411, Prec@1: 75.95, Prec@5: 92.94
Epoch time: 80s
Epoch: 126  lr: 0.010
Epoch: [126][000/391]	Time 1.1397 Data 0.9016 Loss 0.0128 (0.0128)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [126][100/391]	Time 0.1921 Data 0.0019 Loss 0.0186 (0.0190)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [126][200/391]	Time 0.1876 Data 0.0019 Loss 0.0131 (0.0192)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [126][300/391]	Time 0.1878 Data 0.0019 Loss 0.0193 (0.0192)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9489, Prec@1: 76.00, Prec@5: 92.99
Epoch time: 80s
Epoch: 127  lr: 0.010
Epoch: [127][000/391]	Time 1.0855 Data 0.8632 Loss 0.0144 (0.0144)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [127][100/391]	Time 0.1872 Data 0.0018 Loss 0.0134 (0.0182)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [127][200/391]	Time 0.1875 Data 0.0020 Loss 0.0195 (0.0189)	Acc@1 100.000 (99.934)	Acc@5 100.000 (100.000)
Epoch: [127][300/391]	Time 0.1900 Data 0.0020 Loss 0.0164 (0.0188)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9417, Prec@1: 75.92, Prec@5: 92.94
Epoch time: 80s
Epoch: 128  lr: 0.010
Epoch: [128][000/391]	Time 1.1261 Data 0.9160 Loss 0.0214 (0.0214)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [128][100/391]	Time 0.1883 Data 0.0019 Loss 0.0144 (0.0182)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [128][200/391]	Time 0.1868 Data 0.0021 Loss 0.0140 (0.0182)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [128][300/391]	Time 0.1870 Data 0.0020 Loss 0.0190 (0.0185)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9425, Prec@1: 76.02, Prec@5: 93.00
Epoch time: 80s
Epoch: 129  lr: 0.010
Epoch: [129][000/391]	Time 1.0694 Data 0.8571 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [129][100/391]	Time 0.1875 Data 0.0019 Loss 0.0283 (0.0179)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Epoch: [129][200/391]	Time 0.1867 Data 0.0020 Loss 0.0307 (0.0180)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [129][300/391]	Time 0.1870 Data 0.0021 Loss 0.0202 (0.0181)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9397, Prec@1: 76.16, Prec@5: 92.95
Epoch time: 80s
Saving models
Epoch: 130  lr: 0.010
Epoch: [130][000/391]	Time 1.1250 Data 0.8592 Loss 0.0115 (0.0115)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [130][100/391]	Time 0.1870 Data 0.0019 Loss 0.0148 (0.0181)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [130][200/391]	Time 0.1872 Data 0.0020 Loss 0.0201 (0.0184)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [130][300/391]	Time 0.1881 Data 0.0021 Loss 0.0227 (0.0185)	Acc@1 100.000 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9395, Prec@1: 76.15, Prec@5: 92.98
Epoch time: 80s
Epoch: 131  lr: 0.010
Epoch: [131][000/391]	Time 1.0816 Data 0.8723 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [131][100/391]	Time 0.1873 Data 0.0021 Loss 0.0177 (0.0180)	Acc@1 100.000 (99.915)	Acc@5 100.000 (100.000)
Epoch: [131][200/391]	Time 0.1872 Data 0.0020 Loss 0.0146 (0.0180)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [131][300/391]	Time 0.1925 Data 0.0027 Loss 0.0188 (0.0182)	Acc@1 100.000 (99.930)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9393, Prec@1: 76.01, Prec@5: 93.00
Epoch time: 80s
Epoch: 132  lr: 0.010
Epoch: [132][000/391]	Time 1.2105 Data 1.0409 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [132][100/391]	Time 0.1874 Data 0.0019 Loss 0.0201 (0.0176)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [132][200/391]	Time 0.1875 Data 0.0020 Loss 0.0292 (0.0178)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [132][300/391]	Time 0.1871 Data 0.0020 Loss 0.0147 (0.0179)	Acc@1 100.000 (99.943)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9394, Prec@1: 76.39, Prec@5: 93.08
Epoch time: 80s
Saving models
Epoch: 133  lr: 0.010
Epoch: [133][000/391]	Time 1.1159 Data 0.9107 Loss 0.0169 (0.0169)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [133][100/391]	Time 0.1922 Data 0.0019 Loss 0.0166 (0.0174)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [133][200/391]	Time 0.1868 Data 0.0019 Loss 0.0229 (0.0176)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [133][300/391]	Time 0.1874 Data 0.0019 Loss 0.0172 (0.0177)	Acc@1 100.000 (99.940)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9363, Prec@1: 75.94, Prec@5: 92.95
Epoch time: 80s
Epoch: 134  lr: 0.010
Epoch: [134][000/391]	Time 1.1430 Data 0.8763 Loss 0.0201 (0.0201)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [134][100/391]	Time 0.1886 Data 0.0019 Loss 0.0141 (0.0173)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [134][200/391]	Time 0.1871 Data 0.0019 Loss 0.0129 (0.0174)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [134][300/391]	Time 0.1871 Data 0.0019 Loss 0.0143 (0.0176)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9385, Prec@1: 76.21, Prec@5: 92.93
Epoch time: 80s
Epoch: 135  lr: 0.010
Epoch: [135][000/391]	Time 1.3630 Data 1.1647 Loss 0.0165 (0.0165)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [135][100/391]	Time 0.1871 Data 0.0022 Loss 0.0154 (0.0174)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [135][200/391]	Time 0.1871 Data 0.0020 Loss 0.0162 (0.0174)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [135][300/391]	Time 0.1873 Data 0.0022 Loss 0.0131 (0.0177)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9372, Prec@1: 76.25, Prec@5: 92.95
Epoch time: 81s
Epoch: 136  lr: 0.010
Epoch: [136][000/391]	Time 1.1813 Data 0.9137 Loss 0.0186 (0.0186)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [136][100/391]	Time 0.1869 Data 0.0019 Loss 0.0203 (0.0178)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [136][200/391]	Time 0.1888 Data 0.0023 Loss 0.0248 (0.0177)	Acc@1 99.219 (99.942)	Acc@5 100.000 (100.000)
Epoch: [136][300/391]	Time 0.1910 Data 0.0020 Loss 0.0272 (0.0178)	Acc@1 99.219 (99.948)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9368, Prec@1: 76.19, Prec@5: 92.90
Epoch time: 81s
Epoch: 137  lr: 0.010
Epoch: [137][000/391]	Time 1.1702 Data 0.9516 Loss 0.0157 (0.0157)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [137][100/391]	Time 0.1871 Data 0.0021 Loss 0.0168 (0.0171)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [137][200/391]	Time 0.1872 Data 0.0020 Loss 0.0091 (0.0175)	Acc@1 100.000 (99.942)	Acc@5 100.000 (100.000)
Epoch: [137][300/391]	Time 0.1878 Data 0.0023 Loss 0.0169 (0.0176)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9375, Prec@1: 76.32, Prec@5: 93.01
Epoch time: 81s
Epoch: 138  lr: 0.010
Epoch: [138][000/391]	Time 1.1983 Data 0.9821 Loss 0.0152 (0.0152)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [138][100/391]	Time 0.1873 Data 0.0021 Loss 0.0199 (0.0174)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [138][200/391]	Time 0.1874 Data 0.0019 Loss 0.0200 (0.0176)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [138][300/391]	Time 0.1878 Data 0.0021 Loss 0.0132 (0.0173)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9350, Prec@1: 76.33, Prec@5: 92.94
Epoch time: 81s
Epoch: 139  lr: 0.010
Epoch: [139][000/391]	Time 1.1063 Data 0.9049 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [139][100/391]	Time 0.1876 Data 0.0019 Loss 0.0138 (0.0161)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [139][200/391]	Time 0.1897 Data 0.0022 Loss 0.0155 (0.0167)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [139][300/391]	Time 0.1870 Data 0.0020 Loss 0.0162 (0.0166)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9401, Prec@1: 76.25, Prec@5: 93.00
Epoch time: 81s
Epoch: 140  lr: 0.010
Epoch: [140][000/391]	Time 1.1864 Data 0.9175 Loss 0.0210 (0.0210)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [140][100/391]	Time 0.1886 Data 0.0023 Loss 0.0167 (0.0165)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [140][200/391]	Time 0.1878 Data 0.0020 Loss 0.0225 (0.0169)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [140][300/391]	Time 0.1869 Data 0.0019 Loss 0.0276 (0.0169)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9359, Prec@1: 76.39, Prec@5: 92.94
Epoch time: 81s
Epoch: 141  lr: 0.010
Epoch: [141][000/391]	Time 1.1400 Data 0.8789 Loss 0.0165 (0.0165)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [141][100/391]	Time 0.1888 Data 0.0020 Loss 0.0174 (0.0159)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [141][200/391]	Time 0.1871 Data 0.0021 Loss 0.0165 (0.0165)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [141][300/391]	Time 0.1877 Data 0.0020 Loss 0.0299 (0.0167)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9366, Prec@1: 76.26, Prec@5: 92.88
Epoch time: 81s
Epoch: 142  lr: 0.010
Epoch: [142][000/391]	Time 1.1281 Data 0.8727 Loss 0.0158 (0.0158)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [142][100/391]	Time 0.1868 Data 0.0019 Loss 0.0207 (0.0163)	Acc@1 99.219 (99.946)	Acc@5 100.000 (100.000)
Epoch: [142][200/391]	Time 0.1873 Data 0.0023 Loss 0.0135 (0.0167)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [142][300/391]	Time 0.1876 Data 0.0020 Loss 0.0208 (0.0167)	Acc@1 100.000 (99.945)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9428, Prec@1: 76.26, Prec@5: 92.89
Epoch time: 81s
Epoch: 143  lr: 0.010
Epoch: [143][000/391]	Time 1.0746 Data 0.8619 Loss 0.0123 (0.0123)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [143][100/391]	Time 0.1873 Data 0.0020 Loss 0.0124 (0.0163)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [143][200/391]	Time 0.1877 Data 0.0020 Loss 0.0195 (0.0164)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [143][300/391]	Time 0.1878 Data 0.0020 Loss 0.0138 (0.0165)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9356, Prec@1: 76.26, Prec@5: 92.96
Epoch time: 81s
Epoch: 144  lr: 0.010
Epoch: [144][000/391]	Time 1.1333 Data 0.9198 Loss 0.0238 (0.0238)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [144][100/391]	Time 0.1934 Data 0.0019 Loss 0.0139 (0.0164)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [144][200/391]	Time 0.1896 Data 0.0023 Loss 0.0156 (0.0167)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [144][300/391]	Time 0.1877 Data 0.0022 Loss 0.0141 (0.0167)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9390, Prec@1: 76.33, Prec@5: 92.91
Epoch time: 81s
Epoch: 145  lr: 0.010
Epoch: [145][000/391]	Time 1.1614 Data 0.9621 Loss 0.0117 (0.0117)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [145][100/391]	Time 0.1870 Data 0.0020 Loss 0.0153 (0.0167)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [145][200/391]	Time 0.1874 Data 0.0028 Loss 0.0161 (0.0164)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [145][300/391]	Time 0.1872 Data 0.0019 Loss 0.0181 (0.0165)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9339, Prec@1: 76.52, Prec@5: 92.82
Epoch time: 81s
Saving models
Epoch: 146  lr: 0.010
Epoch: [146][000/391]	Time 1.2000 Data 0.9532 Loss 0.0195 (0.0195)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [146][100/391]	Time 0.1882 Data 0.0019 Loss 0.0153 (0.0160)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [146][200/391]	Time 0.1878 Data 0.0020 Loss 0.0181 (0.0167)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [146][300/391]	Time 0.1869 Data 0.0020 Loss 0.0147 (0.0167)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9325, Prec@1: 76.45, Prec@5: 92.98
Epoch time: 81s
Epoch: 147  lr: 0.010
Epoch: [147][000/391]	Time 1.0914 Data 0.8904 Loss 0.0223 (0.0223)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [147][100/391]	Time 0.1871 Data 0.0021 Loss 0.0129 (0.0165)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [147][200/391]	Time 0.1988 Data 0.0024 Loss 0.0214 (0.0164)	Acc@1 100.000 (99.953)	Acc@5 100.000 (100.000)
Epoch: [147][300/391]	Time 0.1876 Data 0.0019 Loss 0.0203 (0.0167)	Acc@1 100.000 (99.940)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9366, Prec@1: 76.29, Prec@5: 93.02
Epoch time: 81s
Epoch: 148  lr: 0.010
Epoch: [148][000/391]	Time 1.4269 Data 1.2039 Loss 0.0136 (0.0136)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [148][100/391]	Time 0.1918 Data 0.0020 Loss 0.0169 (0.0164)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [148][200/391]	Time 0.1920 Data 0.0020 Loss 0.0163 (0.0164)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [148][300/391]	Time 0.1874 Data 0.0020 Loss 0.0168 (0.0163)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9354, Prec@1: 76.39, Prec@5: 92.91
Epoch time: 81s
Epoch: 149  lr: 0.010
Epoch: [149][000/391]	Time 1.1505 Data 0.9642 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [149][100/391]	Time 0.1872 Data 0.0020 Loss 0.0144 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [149][200/391]	Time 0.1869 Data 0.0019 Loss 0.0143 (0.0161)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [149][300/391]	Time 0.1867 Data 0.0021 Loss 0.0178 (0.0162)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9349, Prec@1: 76.35, Prec@5: 92.99
Epoch time: 80s
Epoch: 150  lr: 0.001
Epoch: [150][000/391]	Time 1.2977 Data 1.1292 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [150][100/391]	Time 0.1900 Data 0.0020 Loss 0.0221 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [150][200/391]	Time 0.1883 Data 0.0020 Loss 0.0155 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [150][300/391]	Time 0.1877 Data 0.0020 Loss 0.0174 (0.0157)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9380, Prec@1: 76.20, Prec@5: 92.87
Epoch time: 81s
Epoch: 151  lr: 0.001
Epoch: [151][000/391]	Time 1.0934 Data 0.8675 Loss 0.0222 (0.0222)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [151][100/391]	Time 0.1878 Data 0.0020 Loss 0.0221 (0.0163)	Acc@1 99.219 (99.946)	Acc@5 100.000 (100.000)
Epoch: [151][200/391]	Time 0.1868 Data 0.0020 Loss 0.0157 (0.0161)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [151][300/391]	Time 0.1867 Data 0.0019 Loss 0.0340 (0.0161)	Acc@1 99.219 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9362, Prec@1: 76.34, Prec@5: 92.94
Epoch time: 81s
Epoch: 152  lr: 0.001
Epoch: [152][000/391]	Time 1.1505 Data 0.9399 Loss 0.0156 (0.0156)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [152][100/391]	Time 0.1876 Data 0.0021 Loss 0.0165 (0.0154)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [152][200/391]	Time 0.1885 Data 0.0019 Loss 0.0102 (0.0154)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [152][300/391]	Time 0.1872 Data 0.0020 Loss 0.0236 (0.0156)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9330, Prec@1: 76.44, Prec@5: 92.93
Epoch time: 80s
Epoch: 153  lr: 0.001
Epoch: [153][000/391]	Time 1.1198 Data 0.8550 Loss 0.0140 (0.0140)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [153][100/391]	Time 0.1894 Data 0.0021 Loss 0.0191 (0.0162)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [153][200/391]	Time 0.1876 Data 0.0019 Loss 0.0130 (0.0162)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [153][300/391]	Time 0.1873 Data 0.0024 Loss 0.0190 (0.0161)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9363, Prec@1: 76.45, Prec@5: 92.96
Epoch time: 80s
Epoch: 154  lr: 0.001
Epoch: [154][000/391]	Time 1.3588 Data 1.1783 Loss 0.0155 (0.0155)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [154][100/391]	Time 0.1878 Data 0.0020 Loss 0.0233 (0.0157)	Acc@1 99.219 (99.954)	Acc@5 100.000 (100.000)
Epoch: [154][200/391]	Time 0.1870 Data 0.0022 Loss 0.0116 (0.0158)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [154][300/391]	Time 0.1870 Data 0.0020 Loss 0.0137 (0.0157)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9367, Prec@1: 76.32, Prec@5: 92.92
Epoch time: 81s
Epoch: 155  lr: 0.001
Epoch: [155][000/391]	Time 1.0905 Data 0.8610 Loss 0.0124 (0.0124)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [155][100/391]	Time 0.1874 Data 0.0020 Loss 0.0164 (0.0159)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [155][200/391]	Time 0.1871 Data 0.0026 Loss 0.0148 (0.0156)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [155][300/391]	Time 0.1869 Data 0.0020 Loss 0.0125 (0.0156)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9350, Prec@1: 76.40, Prec@5: 92.92
Epoch time: 80s
Epoch: 156  lr: 0.001
Epoch: [156][000/391]	Time 1.1463 Data 0.9291 Loss 0.0232 (0.0232)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [156][100/391]	Time 0.1875 Data 0.0020 Loss 0.0103 (0.0156)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [156][200/391]	Time 0.1876 Data 0.0021 Loss 0.0124 (0.0157)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [156][300/391]	Time 0.1886 Data 0.0020 Loss 0.0089 (0.0157)	Acc@1 100.000 (99.951)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9348, Prec@1: 76.37, Prec@5: 92.84
Epoch time: 80s
Epoch: 157  lr: 0.001
Epoch: [157][000/391]	Time 1.1488 Data 0.8667 Loss 0.0134 (0.0134)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [157][100/391]	Time 0.1865 Data 0.0020 Loss 0.0150 (0.0158)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [157][200/391]	Time 0.1877 Data 0.0019 Loss 0.0150 (0.0156)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [157][300/391]	Time 0.1912 Data 0.0020 Loss 0.0171 (0.0154)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9345, Prec@1: 76.47, Prec@5: 92.99
Epoch time: 80s
Epoch: 158  lr: 0.001
Epoch: [158][000/391]	Time 1.1465 Data 0.9552 Loss 0.0176 (0.0176)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [158][100/391]	Time 0.1872 Data 0.0020 Loss 0.0200 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [158][200/391]	Time 0.1875 Data 0.0020 Loss 0.0152 (0.0154)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [158][300/391]	Time 0.1871 Data 0.0021 Loss 0.0137 (0.0156)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9335, Prec@1: 76.40, Prec@5: 92.95
Epoch time: 81s
Epoch: 159  lr: 0.001
Epoch: [159][000/391]	Time 1.3196 Data 1.1597 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [159][100/391]	Time 0.1899 Data 0.0025 Loss 0.0121 (0.0158)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [159][200/391]	Time 0.1873 Data 0.0020 Loss 0.0123 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [159][300/391]	Time 0.1874 Data 0.0021 Loss 0.0174 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9348, Prec@1: 76.31, Prec@5: 92.85
Epoch time: 81s
Epoch: 160  lr: 0.001
Epoch: [160][000/391]	Time 1.1274 Data 0.8641 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [160][100/391]	Time 0.1876 Data 0.0030 Loss 0.0131 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [160][200/391]	Time 0.1881 Data 0.0020 Loss 0.0141 (0.0156)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [160][300/391]	Time 0.1876 Data 0.0019 Loss 0.0212 (0.0156)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9336, Prec@1: 76.36, Prec@5: 92.85
Epoch time: 81s
Epoch: 161  lr: 0.001
Epoch: [161][000/391]	Time 1.1428 Data 0.9442 Loss 0.0159 (0.0159)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [161][100/391]	Time 0.1892 Data 0.0020 Loss 0.0152 (0.0159)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [161][200/391]	Time 0.1874 Data 0.0020 Loss 0.0121 (0.0160)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [161][300/391]	Time 0.1894 Data 0.0024 Loss 0.0168 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9336, Prec@1: 76.34, Prec@5: 93.01
Epoch time: 81s
Epoch: 162  lr: 0.001
Epoch: [162][000/391]	Time 1.0859 Data 0.8261 Loss 0.0093 (0.0093)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [162][100/391]	Time 0.1874 Data 0.0019 Loss 0.0127 (0.0157)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [162][200/391]	Time 0.1912 Data 0.0020 Loss 0.0120 (0.0157)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [162][300/391]	Time 0.1878 Data 0.0020 Loss 0.0138 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9332, Prec@1: 76.42, Prec@5: 92.80
Epoch time: 81s
Epoch: 163  lr: 0.001
Epoch: [163][000/391]	Time 1.1263 Data 0.9417 Loss 0.0140 (0.0140)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [163][100/391]	Time 0.1878 Data 0.0020 Loss 0.0133 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [163][200/391]	Time 0.1931 Data 0.0020 Loss 0.0189 (0.0158)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [163][300/391]	Time 0.1873 Data 0.0019 Loss 0.0217 (0.0157)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9350, Prec@1: 76.37, Prec@5: 92.90
Epoch time: 81s
Epoch: 164  lr: 0.001
Epoch: [164][000/391]	Time 1.1079 Data 0.8448 Loss 0.0209 (0.0209)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [164][100/391]	Time 0.1879 Data 0.0019 Loss 0.0196 (0.0159)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [164][200/391]	Time 0.1876 Data 0.0019 Loss 0.0145 (0.0155)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [164][300/391]	Time 0.1875 Data 0.0020 Loss 0.0120 (0.0154)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9355, Prec@1: 76.41, Prec@5: 92.87
Epoch time: 80s
Epoch: 165  lr: 0.001
Epoch: [165][000/391]	Time 1.1381 Data 0.8690 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [165][100/391]	Time 0.1872 Data 0.0019 Loss 0.0136 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [165][200/391]	Time 0.1877 Data 0.0020 Loss 0.0155 (0.0154)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [165][300/391]	Time 0.1874 Data 0.0019 Loss 0.0168 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9322, Prec@1: 76.52, Prec@5: 92.88
Epoch time: 81s
Epoch: 166  lr: 0.001
Epoch: [166][000/391]	Time 1.0974 Data 0.8929 Loss 0.0119 (0.0119)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [166][100/391]	Time 0.1882 Data 0.0024 Loss 0.0136 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [166][200/391]	Time 0.1875 Data 0.0019 Loss 0.0149 (0.0152)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [166][300/391]	Time 0.1871 Data 0.0020 Loss 0.0133 (0.0154)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9362, Prec@1: 76.35, Prec@5: 92.96
Epoch time: 80s
Epoch: 167  lr: 0.001
Epoch: [167][000/391]	Time 1.1232 Data 0.9376 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [167][100/391]	Time 0.1886 Data 0.0025 Loss 0.0142 (0.0157)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [167][200/391]	Time 0.1873 Data 0.0020 Loss 0.0141 (0.0156)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [167][300/391]	Time 0.1877 Data 0.0020 Loss 0.0120 (0.0158)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9371, Prec@1: 76.37, Prec@5: 92.82
Epoch time: 80s
Epoch: 168  lr: 0.001
Epoch: [168][000/391]	Time 1.1528 Data 0.8801 Loss 0.0174 (0.0174)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [168][100/391]	Time 0.1870 Data 0.0019 Loss 0.0134 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [168][200/391]	Time 0.1875 Data 0.0022 Loss 0.0145 (0.0152)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [168][300/391]	Time 0.1891 Data 0.0021 Loss 0.0120 (0.0154)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9326, Prec@1: 76.42, Prec@5: 92.90
Epoch time: 81s
Epoch: 169  lr: 0.001
Epoch: [169][000/391]	Time 1.1021 Data 0.9337 Loss 0.0132 (0.0132)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [169][100/391]	Time 0.1877 Data 0.0019 Loss 0.0204 (0.0156)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [169][200/391]	Time 0.1882 Data 0.0025 Loss 0.0147 (0.0156)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [169][300/391]	Time 0.1915 Data 0.0022 Loss 0.0185 (0.0155)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9370, Prec@1: 76.27, Prec@5: 92.96
Epoch time: 81s
Epoch: 170  lr: 0.001
Epoch: [170][000/391]	Time 1.1380 Data 0.9751 Loss 0.0116 (0.0116)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [170][100/391]	Time 0.1893 Data 0.0019 Loss 0.0149 (0.0153)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [170][200/391]	Time 0.1885 Data 0.0019 Loss 0.0152 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [170][300/391]	Time 0.1875 Data 0.0021 Loss 0.0143 (0.0153)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9344, Prec@1: 76.35, Prec@5: 92.87
Epoch time: 81s
Epoch: 171  lr: 0.001
Epoch: [171][000/391]	Time 1.0756 Data 0.8737 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [171][100/391]	Time 0.1876 Data 0.0019 Loss 0.0147 (0.0158)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [171][200/391]	Time 0.1902 Data 0.0021 Loss 0.0247 (0.0157)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [171][300/391]	Time 0.1870 Data 0.0020 Loss 0.0183 (0.0154)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9309, Prec@1: 76.55, Prec@5: 93.01
Epoch time: 80s
Saving models
Epoch: 172  lr: 0.001
Epoch: [172][000/391]	Time 1.3728 Data 1.1766 Loss 0.0236 (0.0236)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [172][100/391]	Time 0.1874 Data 0.0025 Loss 0.0120 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [172][200/391]	Time 0.1870 Data 0.0019 Loss 0.0130 (0.0157)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [172][300/391]	Time 0.1871 Data 0.0020 Loss 0.0119 (0.0155)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9350, Prec@1: 76.42, Prec@5: 92.83
Epoch time: 81s
Epoch: 173  lr: 0.001
Epoch: [173][000/391]	Time 1.1356 Data 0.8733 Loss 0.0180 (0.0180)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [173][100/391]	Time 0.1871 Data 0.0026 Loss 0.0247 (0.0157)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [173][200/391]	Time 0.1874 Data 0.0021 Loss 0.0144 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [173][300/391]	Time 0.1870 Data 0.0025 Loss 0.0127 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9339, Prec@1: 76.36, Prec@5: 92.88
Epoch time: 80s
Epoch: 174  lr: 0.001
Epoch: [174][000/391]	Time 1.1978 Data 0.9269 Loss 0.0184 (0.0184)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [174][100/391]	Time 0.1874 Data 0.0024 Loss 0.0161 (0.0153)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [174][200/391]	Time 0.1925 Data 0.0019 Loss 0.0115 (0.0152)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [174][300/391]	Time 0.1876 Data 0.0021 Loss 0.0183 (0.0155)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9336, Prec@1: 76.52, Prec@5: 92.87
Epoch time: 81s
Epoch: 175  lr: 0.001
Epoch: [175][000/391]	Time 1.0931 Data 0.8278 Loss 0.0102 (0.0102)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [175][100/391]	Time 0.1885 Data 0.0020 Loss 0.0170 (0.0155)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [175][200/391]	Time 0.1875 Data 0.0019 Loss 0.0110 (0.0154)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [175][300/391]	Time 0.1873 Data 0.0020 Loss 0.0231 (0.0157)	Acc@1 99.219 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9312, Prec@1: 76.45, Prec@5: 92.92
Epoch time: 80s
Epoch: 176  lr: 0.001
Epoch: [176][000/391]	Time 1.0503 Data 0.8412 Loss 0.0126 (0.0126)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [176][100/391]	Time 0.1874 Data 0.0020 Loss 0.0190 (0.0150)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [176][200/391]	Time 0.1878 Data 0.0019 Loss 0.0141 (0.0151)	Acc@1 100.000 (99.988)	Acc@5 100.000 (100.000)
Epoch: [176][300/391]	Time 0.1872 Data 0.0020 Loss 0.0151 (0.0153)	Acc@1 100.000 (99.987)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9325, Prec@1: 76.38, Prec@5: 92.96
Epoch time: 80s
Epoch: 177  lr: 0.001
Epoch: [177][000/391]	Time 1.0713 Data 0.8538 Loss 0.0170 (0.0170)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [177][100/391]	Time 0.1874 Data 0.0026 Loss 0.0177 (0.0161)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [177][200/391]	Time 0.1888 Data 0.0024 Loss 0.0134 (0.0157)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [177][300/391]	Time 0.1875 Data 0.0020 Loss 0.0137 (0.0155)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9344, Prec@1: 76.34, Prec@5: 92.82
Epoch time: 80s
Epoch: 178  lr: 0.001
Epoch: [178][000/391]	Time 1.1347 Data 0.8628 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [178][100/391]	Time 0.1874 Data 0.0020 Loss 0.0118 (0.0156)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [178][200/391]	Time 0.1872 Data 0.0020 Loss 0.0152 (0.0154)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [178][300/391]	Time 0.1872 Data 0.0022 Loss 0.0127 (0.0155)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9333, Prec@1: 76.27, Prec@5: 92.97
Epoch time: 80s
Epoch: 179  lr: 0.001
Epoch: [179][000/391]	Time 1.0349 Data 0.8142 Loss 0.0101 (0.0101)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [179][100/391]	Time 0.1874 Data 0.0029 Loss 0.0190 (0.0152)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [179][200/391]	Time 0.1864 Data 0.0021 Loss 0.0125 (0.0151)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [179][300/391]	Time 0.1870 Data 0.0025 Loss 0.0113 (0.0153)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9355, Prec@1: 76.43, Prec@5: 92.92
Epoch time: 80s
Epoch: 180  lr: 0.001
Epoch: [180][000/391]	Time 1.1447 Data 0.9347 Loss 0.0162 (0.0162)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [180][100/391]	Time 0.1870 Data 0.0021 Loss 0.0130 (0.0159)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [180][200/391]	Time 0.1899 Data 0.0023 Loss 0.0206 (0.0157)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [180][300/391]	Time 0.1871 Data 0.0020 Loss 0.0112 (0.0157)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9326, Prec@1: 76.44, Prec@5: 92.91
Epoch time: 81s
Epoch: 181  lr: 0.001
Epoch: [181][000/391]	Time 1.1221 Data 0.8562 Loss 0.0172 (0.0172)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [181][100/391]	Time 0.1940 Data 0.0020 Loss 0.0122 (0.0149)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [181][200/391]	Time 0.1874 Data 0.0021 Loss 0.0164 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [181][300/391]	Time 0.1871 Data 0.0020 Loss 0.0161 (0.0156)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9331, Prec@1: 76.35, Prec@5: 92.91
Epoch time: 81s
Epoch: 182  lr: 0.001
Epoch: [182][000/391]	Time 1.1116 Data 0.9143 Loss 0.0121 (0.0121)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [182][100/391]	Time 0.1877 Data 0.0019 Loss 0.0163 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [182][200/391]	Time 0.1877 Data 0.0020 Loss 0.0127 (0.0151)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [182][300/391]	Time 0.1880 Data 0.0021 Loss 0.0139 (0.0152)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.28, Prec@5: 92.81
Epoch time: 81s
Epoch: 183  lr: 0.001
Epoch: [183][000/391]	Time 1.1026 Data 0.8346 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [183][100/391]	Time 0.1880 Data 0.0020 Loss 0.0151 (0.0160)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [183][200/391]	Time 0.1874 Data 0.0020 Loss 0.0149 (0.0157)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [183][300/391]	Time 0.1879 Data 0.0020 Loss 0.0138 (0.0156)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9330, Prec@1: 76.25, Prec@5: 92.93
Epoch time: 81s
Epoch: 184  lr: 0.001
Epoch: [184][000/391]	Time 1.2946 Data 1.1278 Loss 0.0254 (0.0254)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [184][100/391]	Time 0.1893 Data 0.0026 Loss 0.0163 (0.0152)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [184][200/391]	Time 0.1918 Data 0.0021 Loss 0.0298 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [184][300/391]	Time 0.1893 Data 0.0023 Loss 0.0174 (0.0155)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9348, Prec@1: 76.28, Prec@5: 92.93
Epoch time: 81s
Epoch: 185  lr: 0.001
Epoch: [185][000/391]	Time 1.0413 Data 0.8347 Loss 0.0196 (0.0196)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [185][100/391]	Time 0.1883 Data 0.0023 Loss 0.0135 (0.0158)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [185][200/391]	Time 0.1890 Data 0.0024 Loss 0.0112 (0.0161)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [185][300/391]	Time 0.1884 Data 0.0024 Loss 0.0136 (0.0157)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9319, Prec@1: 76.36, Prec@5: 92.87
Epoch time: 81s
Epoch: 186  lr: 0.001
Epoch: [186][000/391]	Time 1.3701 Data 1.0998 Loss 0.0287 (0.0287)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [186][100/391]	Time 0.1905 Data 0.0024 Loss 0.0141 (0.0158)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [186][200/391]	Time 0.1880 Data 0.0024 Loss 0.0128 (0.0154)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [186][300/391]	Time 0.1880 Data 0.0021 Loss 0.0161 (0.0152)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9317, Prec@1: 76.43, Prec@5: 92.96
Epoch time: 81s
Epoch: 187  lr: 0.001
Epoch: [187][000/391]	Time 1.2127 Data 0.9969 Loss 0.0148 (0.0148)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [187][100/391]	Time 0.1908 Data 0.0024 Loss 0.0135 (0.0152)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [187][200/391]	Time 0.1895 Data 0.0023 Loss 0.0140 (0.0154)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [187][300/391]	Time 0.1906 Data 0.0026 Loss 0.0138 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9324, Prec@1: 76.49, Prec@5: 92.88
Epoch time: 81s
Epoch: 188  lr: 0.001
Epoch: [188][000/391]	Time 1.3986 Data 1.1803 Loss 0.0136 (0.0136)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [188][100/391]	Time 0.1895 Data 0.0023 Loss 0.0111 (0.0156)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [188][200/391]	Time 0.1923 Data 0.0021 Loss 0.0127 (0.0155)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [188][300/391]	Time 0.1880 Data 0.0019 Loss 0.0161 (0.0154)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9324, Prec@1: 76.32, Prec@5: 92.88
Epoch time: 81s
Epoch: 189  lr: 0.001
Epoch: [189][000/391]	Time 1.3863 Data 1.1794 Loss 0.0125 (0.0125)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [189][100/391]	Time 0.1904 Data 0.0029 Loss 0.0171 (0.0155)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [189][200/391]	Time 0.1921 Data 0.0023 Loss 0.0178 (0.0155)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [189][300/391]	Time 0.1876 Data 0.0021 Loss 0.0117 (0.0156)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9332, Prec@1: 76.43, Prec@5: 92.84
Epoch time: 81s
Epoch: 190  lr: 0.001
Epoch: [190][000/391]	Time 1.1102 Data 0.9178 Loss 0.0222 (0.0222)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [190][100/391]	Time 0.1880 Data 0.0021 Loss 0.0211 (0.0161)	Acc@1 99.219 (99.930)	Acc@5 100.000 (100.000)
Epoch: [190][200/391]	Time 0.1876 Data 0.0020 Loss 0.0133 (0.0158)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [190][300/391]	Time 0.1883 Data 0.0020 Loss 0.0163 (0.0158)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9350, Prec@1: 76.38, Prec@5: 92.94
Epoch time: 81s
Epoch: 191  lr: 0.001
Epoch: [191][000/391]	Time 1.3441 Data 1.1264 Loss 0.0161 (0.0161)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [191][100/391]	Time 0.1900 Data 0.0024 Loss 0.0152 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [191][200/391]	Time 0.1878 Data 0.0020 Loss 0.0196 (0.0152)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [191][300/391]	Time 0.1887 Data 0.0024 Loss 0.0177 (0.0153)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9313, Prec@1: 76.43, Prec@5: 92.91
Epoch time: 81s
Epoch: 192  lr: 0.001
Epoch: [192][000/391]	Time 1.1739 Data 0.9823 Loss 0.0166 (0.0166)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [192][100/391]	Time 0.1885 Data 0.0021 Loss 0.0145 (0.0153)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [192][200/391]	Time 0.1882 Data 0.0025 Loss 0.0149 (0.0150)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [192][300/391]	Time 0.1880 Data 0.0020 Loss 0.0203 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9349, Prec@1: 76.40, Prec@5: 92.91
Epoch time: 81s
Epoch: 193  lr: 0.001
Epoch: [193][000/391]	Time 1.0761 Data 0.8802 Loss 0.0146 (0.0146)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [193][100/391]	Time 0.1919 Data 0.0024 Loss 0.0163 (0.0152)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [193][200/391]	Time 0.1872 Data 0.0021 Loss 0.0159 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [193][300/391]	Time 0.1944 Data 0.0026 Loss 0.0163 (0.0152)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9316, Prec@1: 76.46, Prec@5: 92.89
Epoch time: 81s
Epoch: 194  lr: 0.001
Epoch: [194][000/391]	Time 1.2511 Data 1.0529 Loss 0.0129 (0.0129)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [194][100/391]	Time 0.1916 Data 0.0025 Loss 0.0153 (0.0146)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [194][200/391]	Time 0.1870 Data 0.0020 Loss 0.0163 (0.0152)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [194][300/391]	Time 0.1881 Data 0.0023 Loss 0.0139 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9348, Prec@1: 76.37, Prec@5: 92.97
Epoch time: 81s
Epoch: 195  lr: 0.001
Epoch: [195][000/391]	Time 1.0705 Data 0.8491 Loss 0.0150 (0.0150)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [195][100/391]	Time 0.1891 Data 0.0033 Loss 0.0200 (0.0155)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [195][200/391]	Time 0.1887 Data 0.0024 Loss 0.0112 (0.0155)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [195][300/391]	Time 0.1873 Data 0.0020 Loss 0.0105 (0.0154)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.44, Prec@5: 92.92
Epoch time: 81s
Epoch: 196  lr: 0.001
Epoch: [196][000/391]	Time 1.1766 Data 0.9829 Loss 0.0098 (0.0098)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [196][100/391]	Time 0.1898 Data 0.0024 Loss 0.0151 (0.0152)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [196][200/391]	Time 0.1869 Data 0.0020 Loss 0.0182 (0.0150)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [196][300/391]	Time 0.1897 Data 0.0020 Loss 0.0148 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9342, Prec@1: 76.43, Prec@5: 92.93
Epoch time: 81s
Epoch: 197  lr: 0.001
Epoch: [197][000/391]	Time 1.0836 Data 0.9319 Loss 0.0235 (0.0235)	Acc@1 99.219 (99.219)	Acc@5 100.000 (100.000)
Epoch: [197][100/391]	Time 0.1906 Data 0.0024 Loss 0.0253 (0.0153)	Acc@1 99.219 (99.930)	Acc@5 100.000 (100.000)
Epoch: [197][200/391]	Time 0.1873 Data 0.0019 Loss 0.0156 (0.0156)	Acc@1 100.000 (99.949)	Acc@5 100.000 (100.000)
Epoch: [197][300/391]	Time 0.1875 Data 0.0020 Loss 0.0111 (0.0157)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9330, Prec@1: 76.33, Prec@5: 92.99
Epoch time: 81s
Epoch: 198  lr: 0.001
Epoch: [198][000/391]	Time 1.1764 Data 0.9507 Loss 0.0161 (0.0161)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [198][100/391]	Time 0.1897 Data 0.0028 Loss 0.0187 (0.0152)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [198][200/391]	Time 0.1871 Data 0.0019 Loss 0.0224 (0.0153)	Acc@1 99.219 (99.965)	Acc@5 100.000 (100.000)
Epoch: [198][300/391]	Time 0.1873 Data 0.0020 Loss 0.0104 (0.0151)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9307, Prec@1: 76.47, Prec@5: 92.88
Epoch time: 81s
Epoch: 199  lr: 0.001
Epoch: [199][000/391]	Time 1.3649 Data 1.1907 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [199][100/391]	Time 0.1893 Data 0.0030 Loss 0.0135 (0.0155)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [199][200/391]	Time 0.1874 Data 0.0021 Loss 0.0151 (0.0154)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [199][300/391]	Time 0.1872 Data 0.0021 Loss 0.0108 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9344, Prec@1: 76.39, Prec@5: 92.87
Epoch time: 81s
Epoch: 200  lr: 0.001
Epoch: [200][000/391]	Time 1.3756 Data 1.1726 Loss 0.0105 (0.0105)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [200][100/391]	Time 0.1886 Data 0.0025 Loss 0.0147 (0.0158)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [200][200/391]	Time 0.1904 Data 0.0025 Loss 0.0131 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [200][300/391]	Time 0.1887 Data 0.0025 Loss 0.0115 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9305, Prec@1: 76.41, Prec@5: 92.98
Epoch time: 81s
Epoch: 201  lr: 0.001
Epoch: [201][000/391]	Time 1.4466 Data 1.2904 Loss 0.0170 (0.0170)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [201][100/391]	Time 0.1908 Data 0.0024 Loss 0.0201 (0.0152)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [201][200/391]	Time 0.1898 Data 0.0022 Loss 0.0140 (0.0152)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [201][300/391]	Time 0.1885 Data 0.0029 Loss 0.0135 (0.0153)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9318, Prec@1: 76.49, Prec@5: 92.95
Epoch time: 81s
Epoch: 202  lr: 0.001
Epoch: [202][000/391]	Time 1.3907 Data 1.2357 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [202][100/391]	Time 0.1914 Data 0.0030 Loss 0.0157 (0.0151)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [202][200/391]	Time 0.1889 Data 0.0023 Loss 0.0139 (0.0154)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [202][300/391]	Time 0.1871 Data 0.0020 Loss 0.0165 (0.0155)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9331, Prec@1: 76.54, Prec@5: 93.00
Epoch time: 81s
Epoch: 203  lr: 0.001
Epoch: [203][000/391]	Time 1.1353 Data 0.9369 Loss 0.0106 (0.0106)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [203][100/391]	Time 0.1872 Data 0.0021 Loss 0.0130 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [203][200/391]	Time 0.1905 Data 0.0020 Loss 0.0121 (0.0149)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [203][300/391]	Time 0.1876 Data 0.0021 Loss 0.0098 (0.0152)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9345, Prec@1: 76.55, Prec@5: 92.94
Epoch time: 81s
Epoch: 204  lr: 0.001
Epoch: [204][000/391]	Time 1.1259 Data 0.9274 Loss 0.0130 (0.0130)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [204][100/391]	Time 0.1894 Data 0.0020 Loss 0.0125 (0.0149)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [204][200/391]	Time 0.1892 Data 0.0025 Loss 0.0120 (0.0149)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [204][300/391]	Time 0.1881 Data 0.0023 Loss 0.0133 (0.0152)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9315, Prec@1: 76.53, Prec@5: 92.83
Epoch time: 81s
Epoch: 205  lr: 0.001
Epoch: [205][000/391]	Time 1.3316 Data 1.1350 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [205][100/391]	Time 0.1888 Data 0.0022 Loss 0.0118 (0.0149)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [205][200/391]	Time 0.1877 Data 0.0021 Loss 0.0146 (0.0150)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [205][300/391]	Time 0.1885 Data 0.0021 Loss 0.0141 (0.0150)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9300, Prec@1: 76.58, Prec@5: 92.99
Epoch time: 81s
Saving models
Epoch: 206  lr: 0.001
Epoch: [206][000/391]	Time 1.3625 Data 1.1701 Loss 0.0127 (0.0127)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [206][100/391]	Time 0.1873 Data 0.0020 Loss 0.0182 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [206][200/391]	Time 0.1914 Data 0.0024 Loss 0.0115 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [206][300/391]	Time 0.1867 Data 0.0019 Loss 0.0140 (0.0151)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9332, Prec@1: 76.50, Prec@5: 92.91
Epoch time: 81s
Epoch: 207  lr: 0.001
Epoch: [207][000/391]	Time 1.3947 Data 1.2315 Loss 0.0160 (0.0160)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [207][100/391]	Time 0.1889 Data 0.0023 Loss 0.0152 (0.0155)	Acc@1 100.000 (99.946)	Acc@5 100.000 (100.000)
Epoch: [207][200/391]	Time 0.1878 Data 0.0019 Loss 0.0165 (0.0153)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [207][300/391]	Time 0.1884 Data 0.0021 Loss 0.0170 (0.0154)	Acc@1 100.000 (99.956)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9316, Prec@1: 76.48, Prec@5: 93.02
Epoch time: 81s
Epoch: 208  lr: 0.001
Epoch: [208][000/391]	Time 1.1377 Data 0.9153 Loss 0.0117 (0.0117)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [208][100/391]	Time 0.1883 Data 0.0029 Loss 0.0157 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [208][200/391]	Time 0.1893 Data 0.0024 Loss 0.0170 (0.0150)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [208][300/391]	Time 0.1874 Data 0.0019 Loss 0.0159 (0.0152)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9307, Prec@1: 76.50, Prec@5: 92.93
Epoch time: 81s
Epoch: 209  lr: 0.001
Epoch: [209][000/391]	Time 1.1294 Data 0.8617 Loss 0.0181 (0.0181)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [209][100/391]	Time 0.1887 Data 0.0024 Loss 0.0175 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [209][200/391]	Time 0.1873 Data 0.0024 Loss 0.0170 (0.0153)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [209][300/391]	Time 0.1888 Data 0.0029 Loss 0.0109 (0.0153)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9331, Prec@1: 76.39, Prec@5: 92.91
Epoch time: 81s
Epoch: 210  lr: 0.001
Epoch: [210][000/391]	Time 1.0295 Data 0.8297 Loss 0.0151 (0.0151)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [210][100/391]	Time 0.1908 Data 0.0024 Loss 0.0170 (0.0152)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [210][200/391]	Time 0.1876 Data 0.0019 Loss 0.0106 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [210][300/391]	Time 0.1911 Data 0.0023 Loss 0.0183 (0.0152)	Acc@1 100.000 (99.979)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9334, Prec@1: 76.47, Prec@5: 92.86
Epoch time: 81s
Epoch: 211  lr: 0.001
Epoch: [211][000/391]	Time 1.0353 Data 0.8798 Loss 0.0147 (0.0147)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [211][100/391]	Time 0.1927 Data 0.0025 Loss 0.0179 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [211][200/391]	Time 0.1870 Data 0.0021 Loss 0.0164 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [211][300/391]	Time 0.1886 Data 0.0019 Loss 0.0127 (0.0153)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.40, Prec@5: 92.90
Epoch time: 81s
Epoch: 212  lr: 0.001
Epoch: [212][000/391]	Time 1.0694 Data 0.8514 Loss 0.0161 (0.0161)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [212][100/391]	Time 0.1875 Data 0.0021 Loss 0.0149 (0.0151)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [212][200/391]	Time 0.1886 Data 0.0020 Loss 0.0111 (0.0150)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [212][300/391]	Time 0.1921 Data 0.0019 Loss 0.0179 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9318, Prec@1: 76.40, Prec@5: 92.91
Epoch time: 81s
Epoch: 213  lr: 0.001
Epoch: [213][000/391]	Time 1.1019 Data 0.8783 Loss 0.0145 (0.0145)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [213][100/391]	Time 0.1882 Data 0.0023 Loss 0.0159 (0.0155)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [213][200/391]	Time 0.1873 Data 0.0020 Loss 0.0140 (0.0157)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [213][300/391]	Time 0.1875 Data 0.0020 Loss 0.0153 (0.0155)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9344, Prec@1: 76.46, Prec@5: 92.95
Epoch time: 81s
Epoch: 214  lr: 0.001
Epoch: [214][000/391]	Time 1.1008 Data 0.8278 Loss 0.0154 (0.0154)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [214][100/391]	Time 0.1905 Data 0.0023 Loss 0.0150 (0.0149)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [214][200/391]	Time 0.1886 Data 0.0032 Loss 0.0151 (0.0149)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [214][300/391]	Time 0.1872 Data 0.0020 Loss 0.0111 (0.0150)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.44, Prec@5: 92.86
Epoch time: 81s
Epoch: 215  lr: 0.001
Epoch: [215][000/391]	Time 1.2497 Data 1.0340 Loss 0.0105 (0.0105)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [215][100/391]	Time 0.1886 Data 0.0024 Loss 0.0119 (0.0151)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [215][200/391]	Time 0.1875 Data 0.0020 Loss 0.0255 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [215][300/391]	Time 0.1883 Data 0.0029 Loss 0.0194 (0.0153)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9374, Prec@1: 76.35, Prec@5: 92.92
Epoch time: 81s
Epoch: 216  lr: 0.001
Epoch: [216][000/391]	Time 1.1278 Data 0.9228 Loss 0.0113 (0.0113)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [216][100/391]	Time 0.1888 Data 0.0023 Loss 0.0109 (0.0149)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [216][200/391]	Time 0.1907 Data 0.0024 Loss 0.0268 (0.0151)	Acc@1 99.219 (99.969)	Acc@5 100.000 (100.000)
Epoch: [216][300/391]	Time 0.1901 Data 0.0019 Loss 0.0159 (0.0151)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9338, Prec@1: 76.49, Prec@5: 92.86
Epoch time: 81s
Epoch: 217  lr: 0.001
Epoch: [217][000/391]	Time 1.1426 Data 0.9460 Loss 0.0139 (0.0139)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [217][100/391]	Time 0.1909 Data 0.0024 Loss 0.0145 (0.0143)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [217][200/391]	Time 0.1876 Data 0.0023 Loss 0.0136 (0.0147)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [217][300/391]	Time 0.1883 Data 0.0028 Loss 0.0136 (0.0148)	Acc@1 100.000 (99.982)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9316, Prec@1: 76.47, Prec@5: 92.88
Epoch time: 81s
Epoch: 218  lr: 0.001
Epoch: [218][000/391]	Time 1.0591 Data 0.8275 Loss 0.0130 (0.0130)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [218][100/391]	Time 0.1879 Data 0.0024 Loss 0.0208 (0.0153)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [218][200/391]	Time 0.1869 Data 0.0019 Loss 0.0118 (0.0153)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [218][300/391]	Time 0.1871 Data 0.0019 Loss 0.0171 (0.0152)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9377, Prec@1: 76.50, Prec@5: 92.85
Epoch time: 81s
Epoch: 219  lr: 0.001
Epoch: [219][000/391]	Time 0.9818 Data 0.7878 Loss 0.0128 (0.0128)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [219][100/391]	Time 0.1877 Data 0.0020 Loss 0.0114 (0.0157)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [219][200/391]	Time 0.1874 Data 0.0023 Loss 0.0146 (0.0153)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [219][300/391]	Time 0.1878 Data 0.0020 Loss 0.0141 (0.0151)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9303, Prec@1: 76.52, Prec@5: 92.90
Epoch time: 81s
Epoch: 220  lr: 0.001
Epoch: [220][000/391]	Time 1.1126 Data 0.9037 Loss 0.0141 (0.0141)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [220][100/391]	Time 0.1911 Data 0.0023 Loss 0.0164 (0.0154)	Acc@1 100.000 (99.954)	Acc@5 100.000 (100.000)
Epoch: [220][200/391]	Time 0.1877 Data 0.0020 Loss 0.0138 (0.0155)	Acc@1 100.000 (99.957)	Acc@5 100.000 (100.000)
Epoch: [220][300/391]	Time 0.1872 Data 0.0020 Loss 0.0168 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.42, Prec@5: 92.92
Epoch time: 81s
Epoch: 221  lr: 0.001
Epoch: [221][000/391]	Time 1.1313 Data 0.8614 Loss 0.0175 (0.0175)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [221][100/391]	Time 0.1912 Data 0.0024 Loss 0.0210 (0.0157)	Acc@1 99.219 (99.938)	Acc@5 100.000 (100.000)
Epoch: [221][200/391]	Time 0.1884 Data 0.0022 Loss 0.0113 (0.0153)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [221][300/391]	Time 0.1871 Data 0.0021 Loss 0.0169 (0.0152)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9328, Prec@1: 76.54, Prec@5: 92.99
Epoch time: 81s
Epoch: 222  lr: 0.001
Epoch: [222][000/391]	Time 1.1174 Data 0.9177 Loss 0.0164 (0.0164)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [222][100/391]	Time 0.1883 Data 0.0023 Loss 0.0165 (0.0151)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [222][200/391]	Time 0.1875 Data 0.0020 Loss 0.0159 (0.0150)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [222][300/391]	Time 0.1872 Data 0.0020 Loss 0.0127 (0.0149)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9338, Prec@1: 76.37, Prec@5: 92.94
Epoch time: 81s
Epoch: 223  lr: 0.001
Epoch: [223][000/391]	Time 1.3050 Data 1.1093 Loss 0.0128 (0.0128)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [223][100/391]	Time 0.1934 Data 0.0024 Loss 0.0132 (0.0153)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [223][200/391]	Time 0.1884 Data 0.0024 Loss 0.0114 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [223][300/391]	Time 0.1929 Data 0.0023 Loss 0.0149 (0.0154)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9312, Prec@1: 76.46, Prec@5: 92.96
Epoch time: 81s
Epoch: 224  lr: 0.001
Epoch: [224][000/391]	Time 1.0959 Data 0.8498 Loss 0.0128 (0.0128)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [224][100/391]	Time 0.1876 Data 0.0019 Loss 0.0176 (0.0150)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [224][200/391]	Time 0.1877 Data 0.0019 Loss 0.0139 (0.0153)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [224][300/391]	Time 0.1878 Data 0.0019 Loss 0.0306 (0.0151)	Acc@1 99.219 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9327, Prec@1: 76.57, Prec@5: 92.96
Epoch time: 81s
Epoch: 225  lr: 0.001
Epoch: [225][000/391]	Time 1.4191 Data 1.2347 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [225][100/391]	Time 0.1886 Data 0.0022 Loss 0.0133 (0.0149)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [225][200/391]	Time 0.1906 Data 0.0025 Loss 0.0167 (0.0147)	Acc@1 100.000 (99.981)	Acc@5 100.000 (100.000)
Epoch: [225][300/391]	Time 0.1890 Data 0.0021 Loss 0.0108 (0.0149)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9346, Prec@1: 76.67, Prec@5: 92.89
Epoch time: 82s
Saving models
Epoch: 226  lr: 0.001
Epoch: [226][000/391]	Time 1.1182 Data 0.8507 Loss 0.0205 (0.0205)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [226][100/391]	Time 0.1892 Data 0.0020 Loss 0.0156 (0.0149)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [226][200/391]	Time 0.1881 Data 0.0020 Loss 0.0141 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [226][300/391]	Time 0.1939 Data 0.0020 Loss 0.0154 (0.0151)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9335, Prec@1: 76.59, Prec@5: 92.87
Epoch time: 81s
Epoch: 227  lr: 0.001
Epoch: [227][000/391]	Time 1.0538 Data 0.8405 Loss 0.0137 (0.0137)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [227][100/391]	Time 0.1878 Data 0.0020 Loss 0.0116 (0.0146)	Acc@1 100.000 (99.992)	Acc@5 100.000 (100.000)
Epoch: [227][200/391]	Time 0.1876 Data 0.0020 Loss 0.0126 (0.0151)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [227][300/391]	Time 0.1919 Data 0.0020 Loss 0.0152 (0.0150)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9352, Prec@1: 76.50, Prec@5: 92.87
Epoch time: 81s
Epoch: 228  lr: 0.001
Epoch: [228][000/391]	Time 1.0916 Data 0.8712 Loss 0.0097 (0.0097)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [228][100/391]	Time 0.1885 Data 0.0021 Loss 0.0133 (0.0149)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [228][200/391]	Time 0.1877 Data 0.0020 Loss 0.0122 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [228][300/391]	Time 0.1885 Data 0.0026 Loss 0.0194 (0.0151)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9330, Prec@1: 76.55, Prec@5: 92.91
Epoch time: 81s
Epoch: 229  lr: 0.001
Epoch: [229][000/391]	Time 1.3934 Data 1.1397 Loss 0.0197 (0.0197)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [229][100/391]	Time 0.1903 Data 0.0029 Loss 0.0115 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [229][200/391]	Time 0.1872 Data 0.0019 Loss 0.0122 (0.0149)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [229][300/391]	Time 0.1884 Data 0.0020 Loss 0.0122 (0.0150)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9322, Prec@1: 76.53, Prec@5: 92.95
Epoch time: 81s
Epoch: 230  lr: 0.001
Epoch: [230][000/391]	Time 1.1132 Data 0.9119 Loss 0.0194 (0.0194)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [230][100/391]	Time 0.1886 Data 0.0022 Loss 0.0129 (0.0153)	Acc@1 100.000 (99.938)	Acc@5 100.000 (100.000)
Epoch: [230][200/391]	Time 0.1914 Data 0.0021 Loss 0.0111 (0.0151)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [230][300/391]	Time 0.1941 Data 0.0020 Loss 0.0131 (0.0152)	Acc@1 100.000 (99.964)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9310, Prec@1: 76.50, Prec@5: 92.92
Epoch time: 81s
Epoch: 231  lr: 0.001
Epoch: [231][000/391]	Time 1.1689 Data 0.8763 Loss 0.0154 (0.0154)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [231][100/391]	Time 0.1877 Data 0.0021 Loss 0.0157 (0.0148)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [231][200/391]	Time 0.1920 Data 0.0025 Loss 0.0092 (0.0149)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [231][300/391]	Time 0.1879 Data 0.0020 Loss 0.0118 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9328, Prec@1: 76.51, Prec@5: 92.95
Epoch time: 81s
Epoch: 232  lr: 0.001
Epoch: [232][000/391]	Time 1.2708 Data 1.0464 Loss 0.0153 (0.0153)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [232][100/391]	Time 0.1881 Data 0.0025 Loss 0.0199 (0.0154)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [232][200/391]	Time 0.1876 Data 0.0020 Loss 0.0130 (0.0153)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [232][300/391]	Time 0.1881 Data 0.0028 Loss 0.0144 (0.0154)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9332, Prec@1: 76.46, Prec@5: 92.89
Epoch time: 81s
Epoch: 233  lr: 0.001
Epoch: [233][000/391]	Time 1.0978 Data 0.9040 Loss 0.0116 (0.0116)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [233][100/391]	Time 0.1878 Data 0.0021 Loss 0.0156 (0.0150)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [233][200/391]	Time 0.1877 Data 0.0020 Loss 0.0130 (0.0150)	Acc@1 100.000 (99.984)	Acc@5 100.000 (100.000)
Epoch: [233][300/391]	Time 0.1874 Data 0.0020 Loss 0.0143 (0.0150)	Acc@1 100.000 (99.987)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9360, Prec@1: 76.46, Prec@5: 92.78
Epoch time: 81s
Epoch: 234  lr: 0.001
Epoch: [234][000/391]	Time 1.1535 Data 0.9874 Loss 0.0188 (0.0188)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [234][100/391]	Time 0.1888 Data 0.0026 Loss 0.0120 (0.0153)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Epoch: [234][200/391]	Time 0.1886 Data 0.0020 Loss 0.0104 (0.0148)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [234][300/391]	Time 0.1941 Data 0.0024 Loss 0.0163 (0.0150)	Acc@1 100.000 (99.966)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9324, Prec@1: 76.52, Prec@5: 92.88
Epoch time: 81s
Epoch: 235  lr: 0.001
Epoch: [235][000/391]	Time 1.1645 Data 0.9696 Loss 0.0152 (0.0152)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [235][100/391]	Time 0.1873 Data 0.0019 Loss 0.0135 (0.0147)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [235][200/391]	Time 0.1919 Data 0.0020 Loss 0.0131 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [235][300/391]	Time 0.1871 Data 0.0020 Loss 0.0181 (0.0153)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9353, Prec@1: 76.48, Prec@5: 92.74
Epoch time: 81s
Epoch: 236  lr: 0.001
Epoch: [236][000/391]	Time 1.1691 Data 0.9523 Loss 0.0191 (0.0191)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [236][100/391]	Time 0.1872 Data 0.0021 Loss 0.0213 (0.0152)	Acc@1 100.000 (99.985)	Acc@5 100.000 (100.000)
Epoch: [236][200/391]	Time 0.1880 Data 0.0021 Loss 0.0160 (0.0152)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [236][300/391]	Time 0.1872 Data 0.0020 Loss 0.0172 (0.0151)	Acc@1 100.000 (99.961)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9318, Prec@1: 76.36, Prec@5: 92.88
Epoch time: 81s
Epoch: 237  lr: 0.001
Epoch: [237][000/391]	Time 1.0400 Data 0.8885 Loss 0.0164 (0.0164)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [237][100/391]	Time 0.1883 Data 0.0024 Loss 0.0163 (0.0151)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [237][200/391]	Time 0.1873 Data 0.0019 Loss 0.0115 (0.0152)	Acc@1 100.000 (99.965)	Acc@5 100.000 (100.000)
Epoch: [237][300/391]	Time 0.1880 Data 0.0029 Loss 0.0129 (0.0154)	Acc@1 100.000 (99.958)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9319, Prec@1: 76.49, Prec@5: 92.93
Epoch time: 81s
Epoch: 238  lr: 0.001
Epoch: [238][000/391]	Time 1.1415 Data 0.8508 Loss 0.0126 (0.0126)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [238][100/391]	Time 0.1877 Data 0.0020 Loss 0.0171 (0.0148)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [238][200/391]	Time 0.1866 Data 0.0019 Loss 0.0154 (0.0148)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [238][300/391]	Time 0.1878 Data 0.0020 Loss 0.0101 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9320, Prec@1: 76.59, Prec@5: 92.83
Epoch time: 81s
Epoch: 239  lr: 0.001
Epoch: [239][000/391]	Time 1.1554 Data 0.9613 Loss 0.0135 (0.0135)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [239][100/391]	Time 0.1876 Data 0.0025 Loss 0.0130 (0.0146)	Acc@1 100.000 (99.969)	Acc@5 100.000 (100.000)
Epoch: [239][200/391]	Time 0.1881 Data 0.0021 Loss 0.0120 (0.0150)	Acc@1 100.000 (99.973)	Acc@5 100.000 (100.000)
Epoch: [239][300/391]	Time 0.1871 Data 0.0021 Loss 0.0145 (0.0151)	Acc@1 100.000 (99.971)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9320, Prec@1: 76.65, Prec@5: 92.82
Epoch time: 81s
Epoch: 240  lr: 0.001
Epoch: [240][000/391]	Time 1.3985 Data 1.1803 Loss 0.0131 (0.0131)	Acc@1 100.000 (100.000)	Acc@5 100.000 (100.000)
Epoch: [240][100/391]	Time 0.1883 Data 0.0024 Loss 0.0179 (0.0147)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [240][200/391]	Time 0.1850 Data 0.0020 Loss 0.0139 (0.0148)	Acc@1 100.000 (99.977)	Acc@5 100.000 (100.000)
Epoch: [240][300/391]	Time 0.1871 Data 0.0019 Loss 0.0145 (0.0149)	Acc@1 100.000 (99.974)	Acc@5 100.000 (100.000)
Testing the models......
Loss: 0.9328, Prec@1: 76.46, Prec@5: 92.94
Epoch time: 81s
